[{"title":"Linux 常用基础操作","url":"/Linux-%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/","content":"前言SELinux\nSELinux是Linux2.6以上版本捆绑的一个安全模块\nSELinux配置复杂，容易跟其他程序冲突，所以建议关闭\n\n\n关闭SELinux\n\nvim /etc/selinux/config# 设置SELINUX=disabled，重启系统\n\n\n\n\n\n\n\nyum\n替换yum源\n\ncurl -o /etc/yum.repos.d/CentOS-Base.repo mirrors.163.com/.help/CentOS7-Base-163.repo# 更新缓存yum clean allyum makecache\n\n\n\n\n\n\n\nLinux防火墙\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["Linux"],"tags":["Linux"]},{"title":"Mybatis Study Notes（1）：Mybatis Introduction","url":"/Mybatis-Study-Notes%EF%BC%881%EF%BC%89%EF%BC%9AMybatis-Introduction/","content":"framework\nJava常⽤框架\nSSM三⼤框架：Spring + SpringMVC + MyBatis\nSpringBoot\nSpringCloud\n……\n\n\n框架其实就是对通⽤代码的封装，提前写好了⼀堆接⼝和类，我们可以在做项⽬的时候直接引⼊这些接⼝和类（引⼊框架），基于这些现有的接⼝和类进⾏开发，可以⼤⼤提⾼开发效率。\n框架⼀般都以jar包的形式存在。(jar包中有class⽂件以及各种配置⽂件等。)\n\n\n\n\n\n\n\n三层架构介绍\n表现层（UI）：直接跟前端打交互（⼀是接收前端ajax请求，⼆是返回json数据给前端）\n业务逻辑层（BLL）：⼀是处理表现层转发过来的前端请求（也就是具体业务），⼆是将从持久层获取的数据返回到表现层。\n数据访问层（DAL）：直接操作数据库完成CRUD，并将获得的数据返回到上⼀层（也就是业务逻辑层）。\n\n\n\n\n\n\n\nJDBC 的不⾜\n示例代码1：\n\n// ......// sql语句写死在java程序中String sql = &quot;insert into t_user(id,idCard,username,password,birth,gender,email,city,street,zipcode,phone,grade) values(?,?,?,?,?,?,?,?,?,?,?,?)&quot;;PreparedStatement ps = conn.prepareStatement(sql);// 繁琐的赋值：思考⼀下，这种有规律的代码能不能通过反射机制来做⾃动化。ps.setString(1, &quot;1&quot;);ps.setString(2, &quot;123456789&quot;);ps.setString(3, &quot;zhangsan&quot;);ps.setString(4, &quot;123456&quot;);ps.setString(5, &quot;1980-10-11&quot;);ps.setString(6, &quot;男&quot;);ps.setString(7, &quot;zhangsan@126.com&quot;);ps.setString(8, &quot;北京&quot;);ps.setString(9, &quot;⼤兴区凉⽔河⼆街&quot;);ps.setString(10, &quot;1000000&quot;);ps.setString(11, &quot;16398574152&quot;);ps.setString(12, &quot;A&quot;);// 执⾏SQLint count = ps.executeUpdate();// ......\n\n\n\n\n示例代码2：\n\n// ......// sql语句写死在java程序中String sql = &quot;select id,idCard,username,password,birth,gender,email,city,street,zipcode,phone,grade from t_user&quot;;PreparedStatement ps = conn.prepareStatement(sql);ResultSet rs = ps.executeQuery();List&lt;User&gt; userList = new ArrayList&lt;&gt;();// 思考以下循环中的所有代码是否可以使⽤反射进⾏⾃动化封装。while(rs.next())&#123;// 获取数据String id = rs.getString(&quot;id&quot;);String idCard = rs.getString(&quot;idCard&quot;);String username = rs.getString(&quot;username&quot;);String password = rs.getString(&quot;password&quot;);String birth = rs.getString(&quot;birth&quot;);String gender = rs.getString(&quot;gender&quot;);String email = rs.getString(&quot;email&quot;);String city = rs.getString(&quot;city&quot;);String street = rs.getString(&quot;street&quot;);String zipcode = rs.getString(&quot;zipcode&quot;);String phone = rs.getString(&quot;phone&quot;);String grade = rs.getString(&quot;grade&quot;);// 创建对象User user = new User();// 给对象属性赋值user.setId(id);user.setIdCard(idCard);user.setUsername(username);user.setPassword(password);user.setBirth(birth);user.setGender(gender);user.setEmail(email);user.setCity(city);user.setStreet(street);user.setZipcode(zipcode);user.setPhone(phone);user.setGrade(grade);// 添加到集合userList.add(user);&#125;// ......\n\n\n\n\nJDBC的不足\nSQL语句写死在Java程序中，不灵活。改SQL的话就要改Java代码。违背开闭原则OCP。\n给?传值是繁琐的。能不能⾃动化？？？\n将结果集封装成Java对象是繁琐的。能不能⾃动化？？？\n\n\n\n\n\n\n\n\n\n了解 MyBatis简介\nMyBatis 是一款优秀的持久层框架，它支持自定义 SQL、存储过程以及高级映射。MyBatis 免除了几乎所有的 JDBC 代码以及设置参数和获取结果集的工作。MyBatis 可以通过简单的 XML 或注解来配置和映射原始类型、接口和 Java POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。\n\nMyBatis本质上就是对JDBC的封装，通过MyBatis完成CRUD。\n\n\n\n\nMyBatis 历史\nMyBatis最初是Apache的一个开源项目iBatis, 2010年6月这个项目由Apache Software Foundation迁移到了Google Code。随着开发团队转投Google Code旗下， iBatis3.x正式更名为MyBatis。代码于2013年11月迁移到Github。\niBatis一词来源于“internet”和“abatis”的组合，是一个基于Java的持久层框架。 iBatis提供的持久层框架包括SQL Maps和Data Access Objects（DAO）。\n\n\n\nORM：对象关系映射\nO（Object）：Java虚拟机中的Java对象\nR（Relational）：关系型数据库\nM（Mapping）：将Java虚拟机中的Java对象映射到数据库表中⼀⾏记录，或是将数据库表中⼀⾏记录映射成Java虚拟机中的⼀个Java对象。\n\n\n\nMyBatis框架特点\nMyBatis 是一个 半自动的ORM（Object Relation Mapping）框架\n\n⽀持定制化 SQL、存储过程、基本映射以及⾼级映射\n\n避免了⼏乎所有的 JDBC 代码中⼿动设置参数以及获取结果集\n\n⽀持XML开发，也⽀持注解式开发。【为了保证sql语句的灵活，所以mybatis⼤部分是采⽤XML⽅式开发。】\n\n将接⼝和 Java 的 POJOs(Plain Ordinary Java Object，简单普通的Java对象)映射成数据库中的记录\n\n体积⼩好学：两个jar包，两个XML配置⽂件。\n\n完全做到sql解耦合。\n\n提供了基本映射标签。\n\n提供了⾼级映射标签。\n\n提供了XML标签，⽀持动态SQL的编写。\n\n……\n\n\n\n\nMybatis 和其它持久化层技术对比JDBC\nSQL 夹杂在Java代码中耦合度高，导致硬编码内伤\n维护不易且实际开发需求中 SQL 有变化，频繁修改的情况多见\n代码冗长，开发效率低\n\n\n\nHibernate 和 JPA\n操作简便，开发效率高\n程序中的长难复杂 SQL 需要绕过框架\n内部自动生产的 SQL，不容易做特殊优化\n基于全映射的全自动框架，大量字段的 POJO 进行部分映射时比较困难。\n反射操作太多，导致数据库性能下降\nHibernate属于全⾃动化的ORM框架。（使用Hibernate框架的时候，不需要程序员手动编写SQL语句，SQL语句可以自动生成。所以Hibernate是一个完全的全自动化的ORM框架）\n\n\n\nMyBatis\n轻量级，性能出色\nSQL 和 Java 编码分开，功能边界清晰。Java代码专注业务、SQL语句专注数据\n开发效率稍逊于HIbernate，但是完全能够接受\n\n\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["framework","mybatis"],"tags":["mybatis","ORM","framework"]},{"title":"Redis study notes","url":"/Redis-study-notes/","content":"NoSQL 简介\nNoSQL（“non-relational”， “Not Only SQL”），泛指非关系型的数据库。随着互联网 web2.0网站的兴起，传统的关系数据库在处理 web2.0 网站，特别是超大规模和高并发的 SNS 类型的 web2.0 纯动态网站已经显得力不从心，出现了很多难以克服的问题，而非关系型的数据库则由于其本身的特点得到了非常迅速的发展。NoSQL 数据库的产生就是为了解决大规模数据集合多重数据种类带来的挑战，特别是大数据应用难题。\n\n\n\n键值存储数据库\n就像 Map 一样的 key-value 对。典型代表就是 Redis。\n\n\n\n列存储数据库\n关系型数据库是典型的行存储数据库。其存在的问题是，按行存储的数据在物理层面占用的是连续存储空间，不适合海量数据存储。而按列存储则可实现分布式存储，适合海量存储。典型代表是 HBase。\n\n\n\n文档型数据库\n NoSQL 与关系型数据的结合，最像关系型数据库的 NoSQL。典型代表是 MongoDB。\n\n\n\n图形(Graph) 数据库\n用于存放一个节点关系的数据库，例如描述不同人间的关系。典型代表是 Neo4J。\n\n\n\n\n\n\n\nNoSQL VS 关系型数据库\n\n\n\n\n\n\n\n\nRedis 概述Redis 简介\nRedis，Remote Dictionary Server，远程字典服务，由意大利人 Salvatore Sanfilippo（又名 Antirez）开发，是一个使用 ANSI C 语言编写、支持网络、可基于内存亦可持久化的日志型、NoSQL 开源内存数据库，其提供多种语言的 API。从 2010 年 3 月 15 日起，Redis 的开发工作由 VMware 主持。从2013 年 5 月开始，Redis 的开发由 Pivotal 赞助。\n2008 年时 Salvatore Sanfilippo 自己开发一个叫 LLOOGG 的网站。\nRedis之所以称之为字典服务，是因为 Redis 是一个 key-value存储系统。支持存储的 value类型很多，包括 String(字符串)、List(链表)、Set(集合)、Zset(sorted set –有序集合)和 Hash（哈希类型）等。\nRedis 的国际知名用户有，Twitter、GitHub、Facebook 等，国内知名用户有，阿里巴巴、腾讯、百度、搜狐、优酷、美团、小米等。熟练使用和运维 Redis 已经成为开发运维人员的一个必备技能。\n\n\n\nRedis 的用途数据缓存\n客户端从 DBMS（Database Management System） 中查询出的数据首先写入到 Redis 中，后续无论哪个客户端再需要访问该数据，直接读取 Redis 中的即可，不仅减小了 RT（response time 简称RT，响应时间：从系统接收请求开始到返回响应之间的时间跨度），而且降低了 DBMS 的压力。\n\n\n\n\n\n\n根据 Redis 缓存的数据与 DBMS 中数据的同步性划分，缓存一般可划分为两类：实时同步缓存，与阶段性同步缓存。\n实时同步缓存是指，DBMS 中数据更新后，Redis 缓存中的存放的相关数据会被立即清除，以促使再有对该数据的访问请求到来时，必须先从 DBMS 中查询获取到最新数据，然后再写入到 Redis。\n阶段性同步缓存是指，Redis 缓存中的数据允许在一段时间内与 DBMS 中的数据不完全一致。而这个时间段就是这个缓存数据的过期时间。\n\n\n\nRedis 的特性\n能够做缓存的技术、中间件很多，例如，MyBatis 自带的二级缓存、Memched 等。之所以在生产中做缓存的产品几乎无一例外的会选择 Redis，是因为它有很多其它产品所不具备的特性。\n\n\n性能极高：Redis 读的速度可以达到 11w 次/s，写的速度可以达到 8w 次/s。\n\n\n之所以具有这么高的性能，因为以下几点原因：\n（1）Redis 的所有操作都是在内存中发生的。\n（2）Redis 是用 C 语言开发的。\n（3）Redis 源码非常精细（集性能与优雅于一身）。\n\n\n简单稳定：Redis 源码很少。早期版本只有 2w 行左右。从 3.0 版本开始，增加了集群功能，代码变为了 5w 行左右。\n持久化：Redis 内存中的数据可以进行持久化，其有两种方式：RDB 与 AOF。\n高可用集群：Redis 提供了高可用的主从集群功能，可以确保系统的安全性。\n丰富的数据类型：Redis 是一个 key-value 存储系统。支持存储的 value 类型很多，包括String(字符串)、List(链表)、Set(集合)、Zset(sorted set –有序集合)和 Hash（哈希类型）等，还有 BitMap、HyperLogLog、Geospatial 类型。\nBitMap：一般用于大数据量的二值性统计\nHyperLogLog：其是 Hyperlog Log，用于对数据量超级庞大的日志做去重统计\nGeospatial：地理空间，其主要用于地理位置相关的计算\n\n\n强大的功能：Redis 提供了数据过期功能、发布/订阅功能、简单事务功能，还支持 Lua脚本扩展功能。\n客户端语言广泛：Redis提供了简单的TCP通信协议，编程语言可以方便地的接入Redis。所以，有很多的开源社区、大公司等开发出了很多语言的 Redis 客户端。\n支持 ACL 权限控制：之前的权限控制非常笨拙。从 Redis6 开始引入了 ACL 模块，可以为不同用户定制不同的用户权限。\n\n\n\nACL，Access Control List，访问控制列表，是一种细粒度的权限管理策略，可以针对任意用户与组进行权限控制。目前大多数 Unix 系统与 Linux 2.6 版本已经支持 ACL 了。\nZookeeper 早已支持 ACL 了。\nUnix 与 Linux 系统默认使用是 UGO（User、Group、Other）权限控制策略，其是一种粗粒度的权限管理策略。\n\n\n\n支持多线程 IO 模型：Redis 之前版本采用的是单线程模型，从 6.0 版本开始支持了多线程模型。\n\n\n\n\nRedis 的IO模型\nRedis 客户端提交的各种请求是如何最终被 Redis 处理的？Redis 处理客户端请求所采用的处理架构，称为 Redis 的 IO 模型。不同版本的 Redis 采用的 IO 模型是不同的\n\n单线程模型\n对于 Redis 3.0 及其以前版本，Redis 的 IO 模型采用的是纯粹的单线程模型。即所有客户端的请求全部由一个线程处理。\n\n\n\n\n\n\nRedis 的单线程模型采用了多路复用技术。\n\n\n\n对于多路复用器的多路选择算法常见的有三种：select 模型、poll 模型、epoll 模型。\npoll 模型的选择算法：采用的是轮询算法。该模型对客户端的就绪处理是有延迟的\nepoll 模型的选择算法：采用的是回调方式。根据就绪事件发生后的处理方式的不同，又可分为 LT 模型与 ET 模型。\n\n\n\n\n\n每个客户端若要向 Redis 提交请求，都需要与 Redis 建立一个 socket 连接，并向事件分发器注册一个事件。一旦该事件发生就表明该连接已经就绪。而一旦连接就绪，事件分发器就会感知到，然后获取客户端通过该连接发送的请求，并将由该事件分发器所绑定的这个唯一的线程来处理。如果该线程还在处理多个任务，则将该任务写入到任务队列等待线程处理。\n\n之所以称为事件分发器，是因为它会根据不同的就绪事件，将任务交由不同的事件处理器去处理。\n\n\n混合线程模型\n从 Redis 4.0 版本开始，Redis 中就开始加入了多线程元素。处理客户端请求的仍是单线程模型，但对于一些比较耗时但又不影响对客户端的响应的操作，就由后台其它线程来处理。例如，持久化、对 AOF 的 rewrite、对失效连接的清理等。\n\n多线程模型\nRedis 6.0 版本，才是真正意义上的多线程模型。因为其对于客户端请求的处理采用的是多线程模型。\n\n\n\n\n\n\n多线程 IO 模型中的“多线程”仅用于接受、解析客户端的请求，然后将解析出的请求写入到任务队列。而对具体任务（命令）的处理，仍是由主线程处理。这样做使得用户无需考虑线程安全问题，无需考虑事务控制，无需考虑像 LPUSH/LPOP 等命令的执行顺序问题。\n\nRedis 的 IO 模型优缺点总结\n\n\n\n优点\n缺点\n\n\n\n单线程模型\n可维护性高，性能高。不存在并发读写情况，所以也就不存在执行顺序的不确定性，不存在线程切换开销，不存在死锁问题，不存在为了数据安全而进行的加锁/解锁开销。\n性能会受到影响，且由于单线程只能使用一个处理器，所以会形成处理器浪费。\n\n\n多线程模型\n其结合了多线程与单线程的优点，避开了它们的所有不足\n该模型没有显示不足。如果非要找其不足的话就是，其并非是一个真正意义上的“多线程”，因为真正处理“任务”的线程仍是单线程。所以，其对性能也是有些影响的。\n\n\n\n\n\n\n\n\nRedis 的安装与配置Redis 的安装安装前的准备工作\n服务器选择CentOS 7.x，需要安装 gcc、gcc-c++\n\n\n由于 Redis 是由 C/C++语言编写的，而从官网下载的 Redis 安装包是需要编译后才可安装的，所以对其进行编译就必须要使用相关编译器。对于 C/C++语言的编译器，使用最多的是gcc与gcc-c++，而这两款编译器在CentOS7中是没有安装的，所以首先要安装这两款编译器。\nGCC，GNU Compiler Collection，GNU 编译器集合。\n\nyum -y install gcc gcc-c++\n\n\n\n下载/上传 Redis 安装包cd /opt/wget https://github.com/redis/redis/archive/7.0.8.tar.gztar -zxvf 7.0.8.tar.gz[root@localhost opt]# ls7.0.8.tar.gz  redis-7.0.8\n\n\n\n编译\n编译过程是根据 Makefile 文件进行的，而 Redis 解压包中已经存在该文件了。所以可以直接进行编译了。\n\n[root@localhost /]# cd /opt/redis-7.0.8/[root@localhost redis-7.0.8]# lltotal 264-rw-rw-r--  1 root root  40942 Jan 17 00:40 00-RELEASENOTES-rw-rw-r--  1 root root     51 Jan 17 00:40 BUGS-rw-rw-r--  1 root root   5027 Jan 17 00:40 CODE_OF_CONDUCT.md-rw-rw-r--  1 root root   2634 Jan 17 00:40 CONTRIBUTING.md-rw-rw-r--  1 root root   1487 Jan 17 00:40 COPYINGdrwxrwxr-x  7 root root    119 Jan 17 00:40 deps-rw-rw-r--  1 root root     11 Jan 17 00:40 INSTALL-rw-rw-r--  1 root root    151 Jan 17 00:40 Makefile-rw-rw-r--  1 root root   6888 Jan 17 00:40 MANIFESTO-rw-rw-r--  1 root root  22441 Jan 17 00:40 README.md-rw-rw-r--  1 root root 106545 Jan 17 00:40 redis.conf-rwxrwxr-x  1 root root    279 Jan 17 00:40 runtest-rwxrwxr-x  1 root root    283 Jan 17 00:40 runtest-cluster-rwxrwxr-x  1 root root   1613 Jan 17 00:40 runtest-moduleapi-rwxrwxr-x  1 root root    285 Jan 17 00:40 runtest-sentinel-rw-rw-r--  1 root root   1695 Jan 17 00:40 SECURITY.md-rw-rw-r--  1 root root  14005 Jan 17 00:40 sentinel.confdrwxrwxr-x  4 root root   8192 Jan 17 00:40 srcdrwxrwxr-x 11 root root    199 Jan 17 00:40 tests-rw-rw-r--  1 root root   3055 Jan 17 00:40 TLS.mddrwxrwxr-x  8 root root   4096 Jan 17 00:40 utils\n\n[root@localhost redis-7.0.8]# make......    LINK redis-server    INSTALL redis-sentinel    CC redis-cli.o    CC redisassert.o    CC cli_common.o    LINK redis-cli    CC redis-benchmark.o    LINK redis-benchmark    INSTALL redis-check-rdb    INSTALL redis-check-aofHint: It&#x27;s a good idea to run &#x27;make test&#x27; ;)make[1]: Leaving directory `/opt/redis-7.0.8/src&#x27;[root@localhost redis-7.0.8]#\n\n\n\n安装\n在 Linux 中对于编译过的安装包执行 make install 进行安装\n\n[root@localhost redis-7.0.8]# make installcd src &amp;&amp; make installwhich: no python3 in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)make[1]: Entering directory `/opt/redis-7.0.8/src&#x27;    CC Makefile.depmake[1]: Leaving directory `/opt/redis-7.0.8/src&#x27;which: no python3 in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)make[1]: Entering directory `/opt/redis-7.0.8/src&#x27;Hint: It&#x27;s a good idea to run &#x27;make test&#x27; ;)    INSTALL redis-server    INSTALL redis-benchmark    INSTALL redis-climake[1]: Leaving directory `/opt/redis-7.0.8/src&#x27;[root@localhost redis-7.0.8]#\n\n\n至此，Redis安装完成。可以看到，共安装了三个组件：redis 服务器、客户端与一个性能测试工具 benchmark。\n\n查看 bin 目录\n安装完成后，打开/usr/local/bin 目录，可以看到出现了很多的文件。\n\n[root@localhost bin]# cd /usr/local/bin/[root@localhost bin]# lltotal 21560-rwxr-xr-x 1 root root    32592 Mar 26  2021 earlyoom-rwxr-xr-x 1 root root  5198152 Feb 24 07:07 redis-benchmarklrwxrwxrwx 1 root root       12 Feb 24 07:07 redis-check-aof -&gt; redis-serverlrwxrwxrwx 1 root root       12 Feb 24 07:07 redis-check-rdb -&gt; redis-server-rwxr-xr-x 1 root root  5411488 Feb 24 07:07 redis-clilrwxrwxrwx 1 root root       12 Feb 24 07:07 redis-sentinel -&gt; redis-server-rwxr-xr-x 1 root root 11427160 Feb 24 07:07 redis-server\n\n\n通过 echo $PATH 可以看到，/usr/local/bin 目录是存在于该系统变量中的，这样这些命令就可以在任意目录中执行了。\n\n[root@localhost bin]# echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin\n\n\n\nRedis 启动与停止前台启动\n在任意目录执行redis-server命令即可启动Redis。这种启动方式会占用当前命令行窗口。\n\n[root@localhost bin]# redis-server6717:C 24 Feb 2023 07:13:54.221 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo6717:C 24 Feb 2023 07:13:54.221 # Redis version=7.0.8, bits=64, commit=00000000, modified=0, pid=6717, just started6717:C 24 Feb 2023 07:13:54.221 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf6717:M 24 Feb 2023 07:13:54.221 * monotonic clock: POSIX clock_gettime                _._           _.-``__ &#x27;&#x27;-._      _.-``    `.  `_.  &#x27;&#x27;-._           Redis 7.0.8 (00000000/0) 64 bit  .-`` .-```.  ```\\/    _.,_ &#x27;&#x27;-._ (    &#x27;      ,       .-`  | `,    )     Running in standalone mode |`-._`-...-` __...-.``-._|&#x27;` _.-&#x27;|     Port: 6379 |    `-._   `._    /     _.-&#x27;    |     PID: 6717  `-._    `-._  `-./  _.-&#x27;    _.-&#x27; |`-._`-._    `-.__.-&#x27;    _.-&#x27;_.-&#x27;| |    `-._`-._        _.-&#x27;_.-&#x27;    |           https://redis.io  `-._    `-._`-.__.-&#x27;_.-&#x27;    _.-&#x27; |`-._`-._    `-.__.-&#x27;    _.-&#x27;_.-&#x27;| |    `-._`-._        _.-&#x27;_.-&#x27;    |  `-._    `-._`-.__.-&#x27;_.-&#x27;    _.-&#x27;      `-._    `-.__.-&#x27;    _.-&#x27;          `-._        _.-&#x27;              `-.__.-&#x27;6717:M 24 Feb 2023 07:13:54.221 # Server initialized6717:M 24 Feb 2023 07:13:54.221 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add &#x27;vm.overcommit_memory = 1&#x27; to /etc/sysctl.conf and then reboot or run the command &#x27;sysctl vm.overcommit_memory=1&#x27; for this to take effect.6717:M 24 Feb 2023 07:13:54.222 * Ready to accept connections\n\n\n再开启一个会话窗口，可以查看到当前的 Redis 进程，默认端口号为 6379。\n\n[root@localhost ~]# ps -ef |grep redisroot      6717  2057  0 07:13 pts/2    00:00:00 redis-server *:6379root      6755  6726  0 07:14 pts/3    00:00:00 grep --color=auto redis\n\n\n\n命令式后台启动\n使用 nohub 命令，最后再添加一个&amp;符，可以使要启动的程序在后台以守护进程方式运行。这样的好处是，进程启动后不会占用一个会话窗口，且其还会在当前目录，即运行启动命令的当前目录中创建一个 nohup.out 文件用于记录 Redis 的操作日志。\n\nnohup redis-server &amp;\n\n\n\n配置式后台启动\n使用 nohup 命令可以使 Redis 后台启动，但每次都要键入 nohup 与&amp;符，比较麻烦。可以通过修改 Linux 中 Redis 的核心配置文件 redis.conf 达到后台启动的目的。redis.conf 文件在Redis 的安装目录根下。\n\nRedis 连接前配置绑定客户端 IP\nRedis 可以通过修改配置文件来限定可以访问自己的客户端 IP\n\n# bind 127.0.0.1 -::1# 以上设置（默认设置,未注释），只允许当前主机访问当前的 Redis，其它主机均不可访问。所以，如果不想限定访问的客户端，只需要将该行注释掉即可。\n\n\n\n关闭保护模式\n默认保护模式是开启的。其只允许本机的客户端访问，即只允许自己访问自己。但生产中应该关闭，以确保其它客户端可以连接 Redis。\n\nprotected-mode no\n\n\n\n设置访问密码\n为 Redis 设置访问密码，可以对要读/写 Redis 的用户进行身份验证。没有密码的用户可以登录 Redis，但无法访问。\n\nrequirepass redis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n学习备注\n\n用途写的太单薄了，需要重构\n缓存划分\n\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["DataBase","NoSQL","Redis"],"tags":["Redis","NoSQL","DataBase"]},{"title":"Good Learning Method","url":"/Good-Learning-Method/","content":"学习方法\n学习方法\n\n如何戒掉手机去认真学习？\n不得不说，我们绝大多数人，没有那么强烈的渴望改变，渴望有钱，渴望有地位，渴望有尊严，学习对我们来说，也没有那么重要的意义。所以，手机就成了学习的障碍，麻将成了学习的障碍，任何一件事都成为学习的障碍。\n\n\n第一阶段：向钱看齐，激发对金钱的渴望\n如果你没有动力，就把赚钱作为第一目的。\n\n\n第二阶段：逼自己，死读书（学习）\n当你有了一个明确的目标时，你还静不下心学习时，这时候就需要死磕自己。死读书，我用的办法就是抄书，边读边抄书，就像小时候写家庭作业。\n\n\n第三阶段：向前看齐，寻找榜样的力量\n在你的领域寻找一个榜样。先模仿学习，然后在寻求超越。\n在心理学上有个专业的名词，叫“知识的诅咒”，说的是当我们知道一件事的时，很难想象不知道这件事的人，是怎样一种心理状态。其实就是默认，我们知道这件事，所以人也应该知道这件事。反过来就是说，如果我们不知道一件事，也很难想象出知道这件事对我们的好处。\n为了打破这种知识诅咒，提高自己竞争力，也是为学习这件事加上催化剂。需要找到你所在领域里的一个标杆，也就是大家共识的牛人。以此为标准，去学习，向前看齐。\n\n\n第四阶段：组队学习，或找一个私人教练\n在学习之前压上赌注，也就是先付出一部分，你就想要得到回报，而继续坚持下去。\n你只有逼自己一次，达到顶峰体验过这种巅峰的感觉，你就不会允许自己失败，而有足够的动力，去克服学习障碍。包括玩手机、玩麻将、玩大烟枪等等。\n\n\n\n\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["Learning","Method"],"tags":["Learning","Method"]},{"title":"Redis Study Notes（4）：Redis Persistence","url":"/Redis-Study-Notes%EF%BC%884%EF%BC%89%EF%BC%9ARedis-Persistence/","content":"概述\nRedis 具有持久化功能，其会按照设置以快照（RDB）或操作日志（AOF）的形式将数据持久化到磁盘。\n\n\n\n\n\n\n\nRedis 持久化基本原理\n\n\n\n\nRedis 持久化也称为钝化，是指将内存中数据库的状态描述信息保存到磁盘中。只不过是不同的持久化技术，对数据的状态描述信息是不同的，生成的持久化文件也是不同的。但它们的作用都是相同的：避免数据意外丢失。\n通过手动方式，或自动定时方式，或自动条件触发方式，将内存中数据库的状态描述信息写入到指定的持久化文件中。当系统重新启动时，自动加载持久化文件，并根据文件中数据库状态描述信息将数据恢复到内存中，这个数据恢复过程也称为激活。这个钝化与激活的过程就是 Redis 持久化的基本原理。\n对于 Redis 单机状态下，无论是手动方式，还是定时方式或条件触发方式，都存在数据丢失问题：在尚未手动/自动保存时发生了 Redis 宕机状况，那么从上次保存到宕机期间产生的数据就会丢失。不同的持久化方式，其数据的丢失率也是不同的。\nRDB 是默认持久化方式，但 Redis 允许 RDB 与 AOF 两种持久化技术同时开启，此时系统会使用 AOF 方式做持久化，即 AOF 持久化技术的优先级要更高。同样的道理，两种技术同时开启状态下，系统启动时若两种持久化文件同时存在，则优先加载 AOF持久化文件。\n\n\n\n\n\n\n\nRDB 持久化概述\nRDB，Redis DataBase，是指将内存中某一时刻的数据快照全量写入到指定的 rdb 文件的持久化技术。\nRDB 持久化默认是开启的。当 Redis 启动时会自动读取 RDB 快照文件，将数据从硬盘载入到内存，以恢复 Redis 关机前的数据库状态。\n\n\n\n持久化的执行\nRDB 持久化的执行有三种方式：手动 save 命令、手动 bgsave 命令，与自动条件触发。\n\n\n\n手动 save  命令\n通过在 redis-cli 客户端中执行 save 命令可立即进行一次持久化保存。\nsave 命令在执行期间会阻塞 redis-server 进程，直至持久化过程完毕。而在 redis-server 进程阻塞期间，Redis不能处理任何读写请求，无法对外提供服务。\n\n\n\n手动 bgsave  命令\n通过在 redis-cli 客户端中执行 bgsave 命令可立即进行一次持久化保存。\nbgsave 命令会使服务器进程 redis-server 生成一个子进程，由该子进程负责完成保存过程。在子进程进行保存过程中，不会阻塞 redis-server 进程对客户端读写请求的处理。\n\n\n\n自动条件触发\n自动条件触发的本质仍是 bgsave 命令的执行。只不过是用户通过在配置文件中做相应的设置后，Redis 会根据设置信息自动调用 bgsave 命令执行。具体配置方式，参考 RDB 优化配置 - save\n\n\n\n查看持久化时间\n通过 lastsave 命令可以查看最近一次执行持久化的时间，其返回的是一个 Unix 时间戳。\n\n127.0.0.1:6379&gt; lastsave(integer) 1677689127127.0.0.1:6379&gt; exit[root@localhost ~]# date -d @1677689127Thu Mar  2 00:45:27 CST 2023\n\n\n\nRDB 优化配置\nDB 相关的配置在 redis.conf 文件的 SNAPSHOTTING 部分\n\n\n\nsavesave 3600 1 300 100 60 10000# 该配置用于设置快照的自动保存触发条件，即 save point，保存点。该触发条件是在指定时间段内发生了指定次数的写操作。除非另有规定，默认情况下持久化条件为 save 3600 1 300 100 60 10000。（跟redis6的默认值比，条件更宽松）其等价于以下三条：save 3600 1 # 在 3600 秒(1 小时)内发生 1 次写操作save 300 100 # 在 300 秒(5 分钟)内发生 100 次写操作save 60 10000 # 在 60 秒(1 分钟)内发生 1 万次写操作# 如果不启用 RDB 持久化，只需设置 save 的参数为空串即可：save “”。\n\n\n\nstop-write-on-bgsave-errorstop-writes-on-bgsave-error yes# 默认情况下，如果 RDB 快照已启用（至少一个保存点），且最近的 bgsave 命令失败，Redis将停止接受写入。这样设置是为了让用户意识到数据没有正确地保存到磁盘上，否则很可能没有人会注意到，并会发生一些灾难。当然，如果 bgsave 命令后来可以正常工作了，Redis将自动允许再次写入。\n\n\n\nrdbcompressionrdbcompression yes# 当进行持久化时启用 LZF 压缩字符串对象。虽然压缩 RDB 文件会消耗系统资源，降低性能，但可大幅降低文件的大小，方便保存到磁盘，加速主从集群中从节点的数据同步。\n\n\n\nrdbchecksumrdbchecksum yes# 从 RDB5 开始，RDB 文件的 CRC64 校验和就被放置在了文件末尾。这使格式更能抵抗 RDB文件的损坏，但在保存和加载 RDB 文件时，性能会受到影响（约 10%），因此可以设置为 no禁用校验和以获得最大性能。在禁用校验和的情况下创建的 RDB 文件的校验和为零，这将告诉加载代码跳过校验检查。默认为 yes，开启了校验功能。\n\n\n\nsanitize-dump-payloadsanitize-dump-payload no# 该配置用于设置在加载 RDB 文件或进行持久化时是否开启对 zipList、listPack 等数据的全面安全检测。该检测可以降低命令处理时发生系统崩溃的可能。其可设置的值有三种选择：# no：不检测# yes：总是检测# clients：只有当客户端连接时检测。排除了加载 RDB 文件与进行持久化时的检测。# 默认值本应该是 clients，但其会影响 Redis 集群的工作，所以默认值为 no，不检测\n\n\n\ndbfilenamedbfilename dump.rdb# 指定 RDB 文件的默认名称，默认为 dump.rdb。\n\n\n\nrdb-del-sync-filesrdb-del-sync-files no# 主从复制时，是否删除用于同步的从机上的 RDB 文件。默认是 no，不删除。不过需要注意，只有当从机的 RDB 和 AOF 持久化功能都未开启时才生效。\n\n\n\ndirdir ./# 指定 RDB 与 AOF 文件的生成目录。默认为 Redis 安装根目录。\n\n\n\nRDB 文件结构\nRDB 持久化文件 dump.rdb 整体上有五部分构成：\n\n\n\n\n\nSOF\nSOF 是一个常量，一个字符串 REDIS，仅包含这五个字符，其长度为 5。于标识 RDB文件的开始，以便在加载 RDB 文件时可以迅速判断出文件是否是 RDB 文件。\n\n\n\nrdb_version\n一个整数，长度为 4 字节，表示 RDB 文件的版本号。\n\n\n\nEOF\nEOF 是一个常量，占 1 个字节，用于标识 RDB 数据的结束，校验和的开始\n\n\n\ncheck_sum\n校验和 check_sum 用于判断 RDB 文件中的内容是否出现数据异常。其采用的是 CRC 校验算法。\n\n\nCRC 校验算法：\n\n在持久化时，先将 SOF、rdb_version 及内存数据库中的数据快照这三者的二进制数据拼接起来，形成一个二进制数（假设称为数 a），然后再使用这个 a 除以校验和 check_sum，此时可获取到一个余数 b，然后再将这个 b 拼接到 a 的后面，形成 databases。\n在加载时，需要先使用 check_sum 对 RDB 文件进行数据损坏验证。验证过程：只需将RDB 文件中除 EOF 与 check_sum 外的数据除以 check_sum。只要除得的余数不是 0，就说明文件发生损坏。当然，如果余数是 0，也不能肯定文件没有损坏。\n这种验证算法，是数据损坏校验，而不是数据没有损坏的校验。\n\n\n\n\ndatabases\n\n\n\n\ndatabases 部分是 RDB 文件中最重要的数据部分，其可以包含任意多个非空数据库。而每个 database 又是由三部分构成：\nSODB：是一个常量，占 1 个字节，用于标识一个数据库的开始。\ndb_number：数据库编号\nkey_value_pairs：当前数据库中的键值对数据。每个 key_value_pairs 又由很多个用于描述键值对的数据构成。\nVALUE_TYPE：是一个常量，占 1 个字节，用于标识该键值对中 value 的类型。\nEXPIRETIME_UNIT：是一个常量，占 1 个字节，用于标识过期时间的单位是秒还是毫秒。\ntime：当前 key-value 的过期时间\n\n\n\n\n\n\n\n\n\n*RDB 持久化过程\n\n\n\n\n对于 Redis 默认的 RDB 持久化，在进行 bgsave 持久化时，redis-server 进程会 fork 出一个 bgsave 子进程，由该子进程以异步方式负责完成持久化。而在持久化过程中，redis-server进程不会阻塞，其会继续接收并处理用户的读写请求。\nbgsave 子进程的详细工作原理如下：\n由于子进程可以继承父进程的所有资源，且父进程不能拒绝子进程的继承权。所以，bgsave 子进程有权读取到 redis-server 进程写入到内存中的用户数据，使得将内存数据持久化到 dump.rdb 成为可能。\nbgsave 子进程在持久化时首先会将内存中的全量数据 copy 到磁盘中的一个 RDB 临时文件，copy 结束后，再将该文件 rename 为 dump.rdb，替换掉原来的同名文件。\n不过，在进行持久化过程中，如果 redis-server 进程接收到了用户写请求，则系统会将\n内存中发生数据修改的物理块 copy 出一个副本。等内存中的全量数据 copy 结束后，会再将副本中的数据 copy 到 RDB 临时文件。这个副本的生成是由于 Linux 系统的写时复制技术（Copy-On-Write）实现的。\n\n\n\n\n\n\n\n*写时复制技术（Copy-On-Write）\n原本在 Unix 系统中，当一个主进程通过 fork()系统调用创建子进程后，内核进程会复制主进程的整个内存空间中的数据，然后分配给子进程。这种方式存在的问题有以下几点：\n这个过程非常耗时\n这个过程降低了系统性能\n如果主进程修改了其内存数据，子进程副本中的数据是没有修改的。即出现了数据冗余，而冗余数据最大的问题是数据一致性无法保证。\n\n\n\n\n现代的 Linux 则采用了更为有效的方式：\n写时复制。子进程会继承父进程的所有资源，其中就包括主进程的内存空间。即子进程与父进程共享内存。只要内存被共享，那么该内存就是只读的（写保护的）。而写时复制则是在任何一方需要写入数据到共享内存时都会出现异常，此时内核进程就会将需要写入的数据 copy 出一个副本写入到另外一块非共享内存区域。\n\n\n\n\n\n\n\n\n\nAOF 持久化概述\nAOF，Append Only File，是指 Redis 将每一次的写操作都以日志的形式记录到一个 AOF文件中的持久化技术。当需要恢复内存数据时，将这些写操作重新执行一次，便会恢复到之前的内存数据状态。\n\n\n\nAOF 基础配置AOF 的开启appendonly yes# 默认情况下 AOF 持久化是没有开启的，通过修改配置文件中的 appendonly 属性为 yes可以开启。\n\n\n\n文件名配置appendfilename &quot;appendonly.aof&quot;\n\n\nRedis 7 在这里发生了重大变化。原来只有一个 appendonly.aof 文件，现在具有了三类多个文件：\n基本文件：可以是 RDF 格式也可以是 AOF 格式。其存放的内容是由 RDB 转为 AOF 当时内存的快照数据。该文件可以有多个。\n增量文件：以操作日志形式记录转为 AOF 后的写入操作。该文件可以有多个。\n清单文件：用于维护 AOF 文件的创建顺序，保障激活时的应用顺序。该文件只有一个。\n\n\n\n\n\n混合式持久化开启aof-use-rdb-preamble yes# 对于基本文件可以是 RDF 格式也可以是 AOF 格式。通过 aof-use-rdb-preamble 属性可以选择。其默认值为 yes，即默认 AOF 持久化的基本文件为 rdb 格式文件，也就是默认采用混合式持久化。\n\n\n\nAOF 文件目录配置appenddirname &quot;appendonlydir&quot;# 为了方便管理，可以专门为 AOF 持久化文件指定存放目录。目录名由 appenddirname属性指定，存放在 redis.conf 配置文件的 dir 属性指定的目录，默认为 Redis 安装目录。\n\n\n\nAOF 文件格式\nAOF 文件包含三类文件：基本文件、增量文件与清单文件。其中基本文件一般为 rdb 格式\n\n\n\nRedis 协议\n增量文件扩展名为.aof，采用 AOF 格式。AOF 格式其实就是 Redis 通讯协议格式，AOF持久化文件的本质就是基于 Redis 通讯协议的文本，将命令以纯文本的方式写入到文件中。\nRedis 协议规定，Redis 文本是以行来划分，每行以\\r\\n 行结束。每一行都有一个消息头，以表示消息类型。消息头由六种不同的符号表示，其意义如下：\n(+) 表示一个正确的状态信息\n(-) 表示一个错误信息\n(*) 表示消息体总共有多少行，不包括当前行\n($) 表示下一行消息数据的长度，不包括换行符长度\\r\\n\n(空) 表示一个消息数据\n(:) 表示返回一个数值\n\n\n\n\n\n查看 AOF 文件\n\n\n\n\n\nRDB 与 AOF 的取舍和选择RDB 与 AOF 的对比\n\n\n-\n优势\n不足\n\n\n\nRDB\nRDB 文件较小数据恢复较快\n数据安全性较差写时复制会降低性能RDB 文件可读性较差\n\n\nAOF\n数据安全性高AOF 文件可读性强\nAOF 文件较大写操作会影响性能数据恢复较慢\n\n\n\n\nRedis 持久化的取舍和选择\n官方推荐使用 RDB 与 AOF 混合式持久化。\n若对数据安全性要求不高，则推荐使用纯 RDB 持久化方式。\n不推荐使用纯 AOF 持久化方式。\n若 Redis 仅用于缓存，则无需使用任何持久化技术。\n\n\n\n\n\n\n\n学习备注\n\nRDB文件格式这块还有点模糊\n后续再参考其它教程看看情况\n\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["Database","Redis"],"tags":["Redis","Cache","Database"]},{"title":"《Java分布式系统解决方案 掌握企业级分布式项目方案》study notes","url":"/%E3%80%8AJava%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-%E6%8E%8C%E6%8F%A1%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%88%86%E5%B8%83%E5%BC%8F%E9%A1%B9%E7%9B%AE%E6%96%B9%E6%A1%88%E3%80%8Bstudy-notes/","content":"玩转N种企业级解决方案，笑傲分布式开发\n分布式场景下解决方案和技术选型\n\n\n\n\n\n\n\n\n\n\nSpringCloud和分布式解决方案\nSpringCloud是分布式架构，一定需要分布式解决方案\n\n\n\n\n目标：掌握常见分布式场景中的解决方案\n\n\n\n\n\n\n\n分布式ID\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["distributed"],"tags":["distributed"]},{"title":"Spring 注解驱动开发","url":"/Spring-%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/","content":"\n\n组件注册@Configuration\n告诉Spring这是一个配置类\n配置类 等价于 配置文件（springContext.xml）\n\n\n\n@Bean\n给容器中注册一个Bean;类型为返回值的类型，id默认是用方法名作为id\n也可以指定id\n\n\n\n@ComponentScan\n开启注解扫描；可以指定要扫描的包或规则\n\n\n\n@ComponentScans\n可以包含多个 @ComponentScan\n\n@ComponentScans(\t\tvalue = &#123;\t\t\t\t@ComponentScan(value=&quot;com.stu&quot;,includeFilters = &#123;/*\t\t\t\t\t\t@Filter(type=FilterType.ANNOTATION,classes=&#123;Controller.class&#125;),\t\t\t\t\t\t@Filter(type=FilterType.ASSIGNABLE_TYPE,classes=&#123;BookService.class&#125;),*/\t\t\t\t\t\t@Filter(type=FilterType.CUSTOM,classes=&#123;MyTypeFilter.class&#125;)\t\t\t\t&#125;,useDefaultFilters = false)\t\t\t&#125;\t\t)//@ComponentScan  value:指定要扫描的包//excludeFilters = Filter[] ：指定扫描的时候按照什么规则排除那些组件//includeFilters = Filter[] ：指定扫描的时候只需要包含哪些组件//useDefaultFilters = false 禁用默认过滤规则//FilterType.ANNOTATION：按照注解//FilterType.ASSIGNABLE_TYPE：按照给定的类型；//FilterType.ASPECTJ：使用ASPECTJ表达式//FilterType.REGEX：使用正则指定//FilterType.CUSTOM：使用自定义规则\n\npublic class MyTypeFilter implements TypeFilter&#123;\t@Override\tpublic boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory)\t\t\tthrows IOException &#123;\t\t//获取当前类注解的信息\t\tAnnotationMetadata annotationMetadata = metadataReader.getAnnotationMetadata();\t\t//获取当前正在扫描的类的类信息\t\tClassMetadata classMetadata = metadataReader.getClassMetadata();\t\t//获取当前类资源（类的路径）\t\tResource resource = metadataReader.getResource();\t\t\t\tString className = classMetadata.getClassName();\t\tSystem.out.println(&quot;---&gt;&quot;+className);\t\tif(className.contains(&quot;er&quot;))&#123;\t\t\treturn true;\t\t&#125;\t\treturn true;\t&#125;&#125;\n\n\n\n@Scope\n@Scope 调整（设置）组件作用域\nsingleton：单实例的（默认值）：ioc容器启动会调用方法创建对象放到ioc容器中。以后每次获取就是直接从容器（map.get()）中拿\nprototype：多实例的；ioc容器启动并不会去调用方法创建对象放在容器中，每次获取的时候才会调用方法创建对象；\nrequest：同一次请求创建一个实例\nsession：同一个session创建一个实例\n\n\n\n@Scope(&quot;prototype&quot;)@Bean(&quot;person&quot;)public Person person()&#123;\tSystem.out.println(&quot;给容器中添加Person....&quot;);\treturn new Person(&quot;张三&quot;, 25);&#125;\n\n\n\n@Lazy\n懒加载\n单实例bean：默认在容器启动的时候创建对象；\n懒加载：容器启动不创建对象。第一次使用(获取)Bean创建对象，并初始化；\n\n\n\n@Conditional\n类中组件统一设置。满足当前条件，这个类中配置的所有bean注册才能生效；\n可以加在配置类上，也可以加在具体某个bean上\n\npublic class LinuxCondition implements Condition&#123;\t/**\t * ConditionContext：判断条件能使用的上下文（环境）\t * AnnotatedTypeMetadata：注释信息\t */\t@Override\tpublic boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123;\t\t// TODO是否linux系统\t\t//1、能获取到ioc使用的beanfactory\t\tConfigurableListableBeanFactory beanFactory = context.getBeanFactory();\t\t//2、获取类加载器\t\tClassLoader classLoader = context.getClassLoader();\t\t//3、获取当前环境信息\t\tEnvironment environment = context.getEnvironment();\t\t//4、获取到bean定义的注册类\t\tBeanDefinitionRegistry registry = context.getRegistry();\t\t\t\tString property = environment.getProperty(&quot;os.name&quot;);\t\t\t\t//可以判断容器中的bean注册情况，也可以给容器中注册bean\t\tboolean definition = registry.containsBeanDefinition(&quot;person&quot;);\t\tif(property.contains(&quot;linux&quot;))&#123;\t\t\treturn true;\t\t&#125;\t\t\t\treturn false;\t&#125;&#125;\n\n\n\n@Import\n导入组件，id默认是组件的全类名\n\n\n\n给容器中注册组件的方式\n1）、包扫描+组件标注注解（@Controller/@Service/@Repository/@Component）[自己写的类]\n2）、@Bean[导入的第三方包里面的组件]\n3）、@Import[快速给容器中导入一个组件]\n1）、@Import(要导入到容器中的组件)；容器中就会自动注册这个组件，id默认是全类名\n2）、ImportSelector:返回需要导入的组件的全类名数组；\n3）、ImportBeanDefinitionRegistrar:手动注册bean到容器中\n\n\n4）、使用Spring提供的 FactoryBean（工厂Bean）;\n1）、默认获取到的是工厂bean调用getObject创建的对象\n2）、要获取工厂Bean本身，我们需要给id前面加一个&amp;\n\n\n\n@Import(&#123;Red.class,Color.class,MyImportSelector.class,MyImportBeanDefinitionRegistrar.class&#125;)\n\n//自定义逻辑返回需要导入的组件public class MyImportSelector implements ImportSelector&#123;\t//返回值，就是到导入到容器中的组件全类名\t//AnnotationMetadata:当前标注@Import注解的类的所有注解信息\t@Override\tpublic String[] selectImports(AnnotationMetadata importingClassMetadata) &#123;\t\t//importingClassMetadata\t\t//方法不要返回null值\t\treturn new String[] &#123;&quot;com.stu.pojo.Yellow&quot;,&quot;com.stu.pojo.Pink&quot;&#125;;\t&#125;&#125;\n\npublic class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar&#123;\t/**\t * AnnotationMetadata：当前类的注解信息\t * BeanDefinitionRegistry:BeanDefinition注册类；\t * \t\t把所有需要添加到容器中的bean；调用\t * \t\tBeanDefinitionRegistry.registerBeanDefinition手工注册进来\t */\t@Override\tpublic void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123;\t\t//指定Bean定义信息；（Bean的类型，Bean。。。）\t\tRootBeanDefinition beanDefinition  = new RootBeanDefinition(RainBow.class);\t\tif (registry.containsBeanDefinition(&quot;com.stu.pojo.Red&quot;) &amp;&amp; registry.containsBeanDefinition(&quot;com.stu.pojo.Yellow&quot;)) &#123;\t\t\tregistry.registerBeanDefinition(&quot;rainBow&quot;, beanDefinition);\t\t&#125;\t\t\t&#125;&#125;\n\n@Beanpublic ColorFactoryBean colorFactoryBean() &#123;\treturn new ColorFactoryBean();&#125;\n\nObject obj = ac.getBean(&quot;&amp;colorFactoryBean&quot;);System.out.println(obj.getClass());\n\n\n\n\n\n\n\n组件（Bean）生命周期bean的生命周期\nbean的生命周期：bean创建—初始化—-销毁的过程\n\n容器管理bean的生命周期：我们可以自定义初始化和销毁方法；容器在bean进行到当前生命周期的时候来调用我们自定义的初始化和销毁方法\n\n构造（对象创建）\n\n单实例：在容器启动的时候创建对象\n多实例：在每次获取的时候创建对象\n\n\n\n自定义Bean生命周期\n1）、指定初始化和销毁方法；\n\n通过@Bean指定init-method和destroy-method；\n\n\n2）、通过让Bean实现InitializingBean（定义初始化逻辑），DisposableBean（定义销毁逻辑）;\n\n可以使用JSR250；\n\n@PostConstruct：在bean创建完成并且属性赋值完成；来执行初始化方法\n@PreDestroy：在容器销毁bean之前通知我们进行清理工作\n\n\n4）、BeanPostProcessor【interface】：bean的后置处理器，在bean初始化前后进行一些处理工作；\n\npostProcessBeforeInitialization:在初始化之前工作\npostProcessAfterInitialization:在初始化之后工作\n\n\n\nBean 指定初始化和销毁方法@Bean(initMethod=&quot;init&quot;,destroyMethod=&quot;detory&quot;)public Car car()&#123;    return new Car();&#125;\n\n@Componentpublic class Car &#123;\t\tpublic Car()&#123;\t\tSystem.out.println(&quot;car constructor...&quot;);\t&#125;\t\tpublic void init()&#123;\t\tSystem.out.println(&quot;car ... init...&quot;);\t&#125;\t\tpublic void detory()&#123;\t\tSystem.out.println(&quot;car ... detory...&quot;);\t&#125;&#125;\n\n\n\n属性赋值使用@Value赋值\n基本数值\n可以写SpEL； #{}\n可以写${}；取出配置文件【properties】中的值（在运行环境变量里面的值）\n\n\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["Spring"],"tags":["Spring"]},{"title":"《Java设计模式精讲 Debug方式+内存分析》study notes","url":"/%E3%80%8AJava%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%B2%BE%E8%AE%B2-Debug%E6%96%B9%E5%BC%8F-%E5%86%85%E5%AD%98%E5%88%86%E6%9E%90%E3%80%8Bstudy-notes/","content":"简单工厂类型与定义\n定义:由一个工厂对象决定创建出哪一种产品类的实例\n类型:创建型，但不属于GOF23种设计模式\n\n\n\n适用场景\n工厂类负责创建的对象比较少\n客户端(应用层)只知道传入工厂类的参数，对于如何创建对象(逻辑)不关心\n\n\n\n优点\n只需要传入一个正确的参数，就可以获取你所需要的对象而无须知道其创建细节\n\n\n\n缺点\n工厂类的职责相对过重，如果增加新的产品需要修改工厂类的判断逻辑，违背开闭原则\n\n\n\nCodingpublic abstract class Coder &#123;    public abstract void coding();&#125;public class Javaer extends Coder&#123;    @Override    public void coding() &#123;        System.out.println(&quot;I&#x27;m a Java programmer，I can use Java programming .&quot;);    &#125;&#125;public class Gopher extends Coder&#123;    @Override    public void coding() &#123;        System.out.println(&quot;I&#x27;m a Go programmer，I can use Go programming .&quot;);    &#125;&#125;public class CoderFactory &#123;    public static Coder createCoder(Class clazz) &#123;        Coder coder = null;        try &#123;            coder = (Coder) Class.forName(clazz.getName()).newInstance();        &#125; catch (InstantiationException e) &#123;            throw new RuntimeException(e);        &#125; catch (IllegalAccessException e) &#123;            throw new RuntimeException(e);        &#125; catch (ClassNotFoundException e) &#123;            throw new RuntimeException(e);        &#125;        return coder;    &#125;&#125;public class Tests &#123;    public static void main(String[] args) &#123;        Coder coder = CoderFactory.createCoder(Javaer.class);        coder.coding();        Coder coder1= CoderFactory.createCoder(Gopher.class);        coder1.coding();    &#125;&#125;\n\n\n\n源码分析java.util.Calendar\n\n\n\nch.qos.logback.classic.LoggerContext\n其中，既使用到了简单工厂又使用到了工厂方法模式\n\n\n\n\n\n\n\n工厂方法模式定义与类型\n定义:定义一个创建对象的接口，但让实现这个接口的类来决定实例化哪个类，工厂方法让类的实例化推迟到子类中进行\n类型:创建型\n\n\n\n适用场景\n创建对象需要大量重复的代码\n客户端(应用层)不依赖于产品类实例如何被创建、实现等细节\n一个类通过其子类来指定创建哪个对象\n\n\n\n优点\n用户只需要关心所需产品对应的工厂，无须关心创建细节\n加入新产品符合开闭原则，提高可扩展性\n\n\n\n缺点\n类的个数容易过多，增加复杂度\n增加了系统的抽象性和理解难度\n\n\n\nCodingpublic abstract class Coder &#123;    public abstract void coding();&#125;public class Gopher extends Coder &#123;    @Override    public void coding() &#123;        System.out.println(&quot;I&#x27;m a Go programmer，I can use Go programming .&quot;);    &#125;&#125;public class Javaer extends Coder &#123;    @Override    public void coding() &#123;        System.out.println(&quot;I&#x27;m a Java programmer，I can use Java programming .&quot;);    &#125;&#125;public abstract class CoderFactory &#123;    public abstract Coder createCoder();&#125;public class GopherFactory extends CoderFactory&#123;    @Override    public Coder createCoder() &#123;        return new Gopher();    &#125;&#125;public class JavaerFactory extends CoderFactory&#123;    @Override    public Coder createCoder() &#123;        return new Javaer();    &#125;&#125;public class Tests &#123;    public static void main(String[] args) &#123;        CoderFactory coderFactory = new JavaerFactory();        Coder coder = coderFactory.createCoder();        coder.coding();        CoderFactory coderFactory2 = new GopherFactory();        Coder coder2 = coderFactory2.createCoder();        coder2.coding();    &#125;&#125;\n\n\n\n源码分析\njdk源码中的 Collection类 Iterator&lt;E&gt; iterator();，就使用了工厂方法，Iterator是抽象产品。ArrayList中有具体实现。\n\npublic Iterator&lt;E&gt; iterator() &#123;    return new Itr();&#125;\n\n\njdk源码Luncher类中\n\nprivate static class Factory implements URLStreamHandlerFactory &#123;    private static String PREFIX = &quot;sun.net.www.protocol&quot;;    private Factory() &#123;    &#125;    public URLStreamHandler createURLStreamHandler(String var1) &#123;        String var2 = PREFIX + &quot;.&quot; + var1 + &quot;.Handler&quot;;        try &#123;            Class var3 = Class.forName(var2);            return (URLStreamHandler)var3.newInstance();        &#125; catch (ReflectiveOperationException var4) &#123;            throw new InternalError(&quot;could not load &quot; + var1 + &quot;system protocol handler&quot;, var4);        &#125;    &#125;&#125;\n\n\n\n\n\n\n\n抽象工厂模式定义与类型\n定义: 抽象工厂模式提供一个创建一系列相关或相互依赖对象的接口\n无须指定它们具体的类\n类型:创建型\n\n\n\n适用场景\n客户端(应用层)不依赖于产品类实例如何被创建、实现等细节\n强调一系列相关的产品对象(属于同一产品族)一起使用创建对象需要大量重复的代码\n提供一个产品类的库，所有的产品以同样的接口出现从而使客户端不依赖于具体实现\n\n\n\n优点\n具体产品在应用层代码隔离，无须关心创建细节\n将一个系列的产品族统一到一起创建\n\n\n\n缺点\n规定了所有可能被创建的产品集合，产品族中扩展新的产品困难需要修改抽象工厂的接口\n增加了系统的抽象性和理解难度\n\n\n\n扩展产品等级结构与产品族\n\n\n\n\n\n\n\nCoding\n\n\n\n源码分析\njava.sql.connection\n\n\n\n\n\n\n\n建造者模式定义与类型\n定义: 将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示\n用户只需指定需要建造的类型就可以得到它们，建造过程及细节不需要知道\n类型:创建型\n\n\n\n适用场景\n如果一个对象有非常复杂的内部结构(很多属性)\n想把复杂对象的创建和使用分离\n\n\n\n优点\n封装性好，创建和使用分离\n扩展性好、建造类之间独立、一定程度上解耦\n\n\n\n缺点\n产生多余的Builder对象\n产品内部发生变化，建造者都要修改，成本较大\n\n\n\nCodingpublic class Computer &#123;    private String cpu;    private String ram;    private String usbCount;    private String keyboard;    private String display;    public Computer(ComputerBuilder computerBuilder) &#123;        this.cpu = computerBuilder.cpu;        this.ram = computerBuilder.ram;        this.usbCount = computerBuilder.usbCount;        this.keyboard = computerBuilder.keyboard;        this.display = computerBuilder.display;    &#125;    @Override    public String toString() &#123;        return &quot;Computer&#123;&quot; +                &quot;cpu=&#x27;&quot; + cpu + &#x27;\\&#x27;&#x27; +                &quot;, ram=&#x27;&quot; + ram + &#x27;\\&#x27;&#x27; +                &quot;, usbCount=&#x27;&quot; + usbCount + &#x27;\\&#x27;&#x27; +                &quot;, keyboard=&#x27;&quot; + keyboard + &#x27;\\&#x27;&#x27; +                &quot;, display=&#x27;&quot; + display + &#x27;\\&#x27;&#x27; +                &#x27;&#125;&#x27;;    &#125;    public static class ComputerBuilder&#123;        private String cpu;        private String ram;        private String usbCount;        private String keyboard;        private String display;        public ComputerBuilder buildCpu(String cpu) &#123;            this.cpu=cpu;            return this;        &#125;        public ComputerBuilder buildRam(String ram) &#123;            this.ram=ram;            return this;        &#125;        public ComputerBuilder buildUsbCount(String usbCount) &#123;            this.usbCount=usbCount;            return this;        &#125;        public ComputerBuilder buildKeyboard(String keyboard) &#123;            this.keyboard=keyboard;            return this;        &#125;        public ComputerBuilder buildDisplay(String display) &#123;            this.display=display;            return this;        &#125;        public Computer build()&#123;            return new Computer(this);        &#125;    &#125;&#125;\n\npublic static void main(String[] args) &#123;    Computer computer = new Computer.ComputerBuilder().buildCpu(&quot;I7处理器&quot;).buildCpu(&quot;三星125&quot;).build();    System.out.println(computer);&#125;\n\n\n\n源码分析\njava.lang.StringBuilder\njava.lang.StringBuffer\norg.apache.ibatis.session.SqlSessionFactoryBuilder\n\n\n\n\n\n\n\n原型模式定义与类型\n定义: 指原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象\n不需要知道任何创建的细节，不调用构造函数\n类型:创建型\n\n\n\n适用场景\n\n\n\n\n优点\n\n\n\n\n缺点\n\n\n\n\nCoding\n\n源码分析\n\n\n\n\n\n\n\n\n单例模式定义与类型\n定义: 保证一个类仅有一个实例，并提供一个全局访问点\n类型:创建型\n\n\n\n适用场景\n想确保任何情况下都绝对只有一个实例\n\n\n\n优点\n在内存里只有一个实例，减少了内存开销\n可以避免对资源的多重占用\n设置全局访问点，严格控制访问\n\n\n\n缺点\n没有接口，扩展困难\n\n\n\n重点\n私有构造器\n线程安全\n延迟加载\n序列化和反序列化安全\n反射\n\n\n\nCoding懒汉式public class LazySingLeton &#123;    private static LazySingLeton lazySingLeton = null;    private LazySingLeton()&#123;    &#125;    public synchronized static LazySingLeton getInstance()&#123;        if (null == lazySingLeton) &#123;            lazySingLeton = new LazySingLeton();        &#125;        return lazySingLeton;    &#125;&#125;\n\n\n同步锁比较消耗资源，加锁解锁消耗资源，同步锁 synchronized 在这里锁的是 整个Class，锁的范围过大，影响性能\n\n懒汉式——DoubleCheck// 兼顾了性能和线程安全public class LazyDoubleCheckSingleton &#123;    // 加上 volatile 关键字，不允许重排序    private volatile static LazyDoubleCheckSingleton lazyDoubleCheckSingleton = null;    private LazyDoubleCheckSingleton()&#123;    &#125;    public static LazyDoubleCheckSingleton getInstance() &#123;        if (null == lazyDoubleCheckSingleton)&#123;            synchronized (LazyDoubleCheckSingleton.class)&#123;                if (null == lazyDoubleCheckSingleton) &#123;                    /*                        这一步做了3个操作                        （1）分配内容给这个对象                        （2）初始化对象                        （3）设置 lazyDoubleCheckSingleton 指向刚分配的内存地址                    但是注意：第（2）步和第（3）步可能会发生重排序，即执行顺序不确定。重排序在单线程下无影响，但是在多线程下可能会发生错误                        解决办法：                            （1）不允许重排序，例如：给实例对象声明的时候加上 volatile 关键字                            （2）允许重排序，但对其它线程不可见。例如：使用静态内部类方式...                     */                    lazyDoubleCheckSingleton = new LazyDoubleCheckSingleton();                &#125;            &#125;        &#125;        return lazyDoubleCheckSingleton;    &#125;&#125;\n\n\n\n扩展 重排序\n多线程下，重排序会导致发生错误\n\n\n\n\n\n懒汉式——静态内部类public class StaticInnerClassSingleton &#123;    private StaticInnerClassSingleton()&#123;    &#125;    private static class InnerClass&#123;        private static StaticInnerClassSingleton staticInnerClassSingleton = new StaticInnerClassSingleton();    &#125;    public static StaticInnerClassSingleton getInstance() &#123;        return InnerClass.staticInnerClassSingleton;    &#125;&#125;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n源码分析\n\n\n\n\n\n\n\n\n外观模式\n\n\n\n\n\n学习备注\n\n源码分析这块是不是需要加强一下 ？\n建造者模式这块还是要好好熟悉手写一下，是否面向对象的知识需要好好补充\n单例模式中的重排序还要深入理解一下***\n\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["Design Pattern"],"tags":["Design Pattern"]},{"title":"《Kafka多维度系统精讲，从入门到实战开发》Study Notes","url":"/%E3%80%8AKafka%E5%A4%9A%E7%BB%B4%E5%BA%A6%E7%B3%BB%E7%BB%9F%E7%B2%BE%E8%AE%B2%EF%BC%8C%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E6%88%98%E5%BC%80%E5%8F%91%E3%80%8BStudy-Notes/","content":"第1章 课程导学与学习指南\n\n\n\n\n\n第2章 Kafka入门——开发环境准备\n\n\n\n\n\n第3章 Kafka入门——Kafka基础操作Kafka介绍\n官方介绍：一个分布式流处理平台\nKafka是基于zookeeper的分布式消息系统\nKafka具有高吞吐率、高性能、实时及高可靠等特点\n\n\n\nKafka安装\n安装准备\njdk-8u181-linux-x64.tar.gz（因为Kafka是scala开发的，scala是基于jdk的，固需需要安装jdk）\napache-zookeeper-3.5.7-bin.tar.gz\nkafka_2.11-2.4.0.tgz\n\n\n\n\n\nstep1 安装jdk# 准备jdk安装包，并解压到 /usr/local/ 目录下tar -zxvf jdk-8u181-linux-x64.tar.gz -C /usr/local/# 创建软连接ln -s jdk-8u181-linux-x64 jdk1.8#配置jdk环境变量vim /etc/profile###################################################### 文档末尾追加如下内容export JAVA_HOME=/usr/local/jdk1.8export PATH=$PATH:$JAVA_HOME/bin#####################################################source /etc/profile# 验证jdk环境java -version\n\n\n\nstep2 安装zookeeper# 准备zookeeper安装包，并解压到 /usr/local/ 目录下tar -zxvf apache-zookeeper-3.5.7-bin.tar.gz -C /usr/local/# 创建软连接ln -s apache-zookeeper-3.5.7-bin zookeeper# 准备配置文件cd /usr/local/zookeeper/conf/cp zoo_sample.cfg zoo.cfgvim zoo.cfg###################################################### 修改 dataDir 然后保存（生产环境应该把dataDir设置成磁盘比较大的目录）dataDir=/usr/local/zookeeper/data###################################################### 创建data目录mkdir -p /usr/local/zookeeper/data# 启动zookeepercd /usr/local/zookeeper/bin/./zkServer.sh start# 使用zookeeper 自带的客户端连接 zookeepercd /usr/local/zookeeper/bin/./zkCli.sh\n\n\n\nstep3 安装Kafka# 准备zookeeper安装包，并解压到 /usr/local/ 目录下tar -zxvf kafka_2.11-2.4.0.tar.gz -C /usr/local/# 创建软连接ln -s kafka_2.11-2.4.0 kafka# 修改配置文件cd /usr/local/kafka/config/vim server.properties#####################################################listeners=PLAINTEXT://192.168.146.135:9092advertised.listeners=PLAINTEXT://192.168.146.135:9092log.dirs=/usr/local/kafka/kafka-logs# 注意生产环境该配置会变化，目前我们就使用如下配置，保持不变zookeeper.connect=localhost:2181###################################################### 创建logs目录mkdir -p /usr/local/kafka/kafka-logs\n\n\n\nKafka常用命令# 注意执行命令需要在kafka的根目录下# 1、启动Kafkabin/kafka-server-start.sh config/server.properties &amp;# 2、停止Kafkabin/kafka-server-stop.sh# 3、创建Topicbin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic jiangzh-topic# 4、查看已经创建的Topic信息bin/kafka-topics.sh --list --zookeeper localhost:2181# 5、发送消息bin/kafka-console-producer.sh --broker-list 192.168.61.130:9092 --topic jiangzh-topic# 6、接收消息bin/kafka-console-consumer.sh --bootstrap-server 192.168.61.130:9092 --topic jiangzh-topic --from-beginning\n\n\n\nKafka基本概念\nTopic：一个虚拟的概念，由1到多个Partitions组成\nPartition：实际消息存储单位\nProducer：消息生产者\nConsumer：消息消费者\n\n\n\n\n\n\n\n第4章 Kafka核心API——Kafka客户端操作五类Kafka客户端 API\nAdminClient API: 允许管理和检测Topicbroker以及其它Kafka对象\nProducer API: 发布消息到1个或多个topic\nConsumer APl: 订阅一个或多个topic，并处理产生的消息\nStreams API:高效地将输入流转换到输出流\nConnector APl: 从一些源系统或应用程序中拉取数据到kafka\n\n\n\n\n\nAdminClient客户端建立\n\n\n\npublic class AdminSimple &#123;    public static void main(String[] args) &#123;        AdminClient adminClient = adminClient();        System.out.println(&quot;adminClient:&quot;+adminClient);    &#125;    public static AdminClient adminClient()&#123;        Properties properties =new Properties();        properties.setProperty(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG,&quot;192.168.146.135:9092&quot;);        AdminClient adminClient = AdminClient.create(properties);        return adminClient;    &#125;&#125;\n\n\n\n创建Topic演示public class AdminSimple &#123;    public static void main(String[] args) &#123;//        AdminClient adminClient = adminClient();//        System.out.println(&quot;adminClient:&quot;+adminClient);        createTopic();    &#125;    public static void createTopic() &#123;        AdminClient adminClient = adminClient();        short rs = 10;        NewTopic newTopic = new NewTopic(&quot;demo_topic&quot;,10,rs);        CreateTopicsResult topics = adminClient.createTopics(Arrays.asList(newTopic));        System.out.println(&quot;CreateTopicsResult :&quot;+topics.toString());    &#125;    public static AdminClient adminClient()&#123;        Properties properties =new Properties();        properties.setProperty(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG,&quot;192.168.146.135:9092&quot;);        AdminClient adminClient = AdminClient.create(properties);        return adminClient;    &#125;&#125;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n学习备注\n1\n\n&amp;emsp;&amp;emsp;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["MQ","Kafka"],"tags":["Kafka","MQ"]},{"title":"《Nacos 核心原理解读+高性能微服务系统实战》Study Notes","url":"/%E3%80%8ANacos-%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E8%A7%A3%E8%AF%BB-%E9%AB%98%E6%80%A7%E8%83%BD%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E3%80%8BStudy-Notes/","content":"初识NacosNacos是什么?\nNacos官方定义:\nNacos 是 Dynamic Naming and Configuration Service的首字母简称\n一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台\n\n\n\nNacos能干什么\n注册微服务，将服务注册到管控中心\n发现微服务，将服务暴露给其他服务\n管理参数，提供配置参数池\n\nNacos由哪几部分组成\n统一服务注册\n统一服务发现\n统一配置管理\n\nNacos发展前景如何\ngithub 活跃\nNacos 应用广泛（很多知名、大公司都在使用Nacos）\n\nEureka的引入\nEureka 2012年左右被引入国内\nEureka是Netflix开发的服务发现框架，本身是一个基于REST的服务，主要用于定位运行在AWS城中的中间层服务，以达到负载均衡和中间层服务故障转移的目的。\nSpringcloud将它集成在其子项目spring-cloud-netflix中，以实现Springcloud的服务发现功能\n\nEureka的盛行\n从2013年开始，被得到广泛使用\n到2015年，几乎国内的互联网大厂均在使用Eureka\n\nEureka的陨落\n2018年，Nacos第一个版本正式对外发布\nEureka的使用范围逐渐缩小\n\nNacos的崛起\n2019年，Nacos第一个成熟版本正式对外发布\n2020年，Nacos逐渐被国内互联网大厂使用\n2021年，Eureka已经被国内互联网大厂停止使用，均移步Nacos\n\nNacos主要版本介绍Nacos 1.4.X版本特性\n支持SpringBoot版本到 2.6.6\n解决并完善Spring权限认证相关问题\n重置JRaft协议集群无Leader操作\n减少 DistroProtocol初始化中的内存成本以避免OutOfMemoryError\n增加NamingProxy.serversFromEndpoint的内存可见性\n修复ServerListManager的迭代器并发问题\n\nNacos 2.1.X版本特性\n支持批量注册服务\n暂时移除离开 nacos 服务器节点API\n添加默认模糊搜索功能\n将TRACE 事件添加到服务器\n在历史列表中添加版本数据比较\n增强默认身份验证插件性能\n\nNacos在Linux系统上单机安装cd /usr/local/src/wget https://github.com/alibaba/nacos/releases/download/1.4.4/nacos-server-1.4.4.tar.gztar -zxvf nacos-server-1.4.4.tar.gzmv nacos /usr/local/cd /usr/local/nacos/bin/./startup.sh -m standalone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["Nacos"],"tags":["Nacos"]},{"title":"《MySQL 必知必会》study notes","url":"/%E3%80%8AMySQL-%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%E3%80%8Bstudy-notes/","content":"课前准备 (2讲)开篇词 | 在实战中学习，是解锁MySQL技能的最佳方法\n\n\n\n\n\n环境准备 | 带你安装MySQL和图形化管理工具Workbench\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["DataBase","MySQL"],"tags":["DataBase","MySQL"]},{"title":"《Spring 编程常见错误 50 例》Study Notes","url":"/%E3%80%8ASpring-%E7%BC%96%E7%A8%8B%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF-50-%E4%BE%8B%E3%80%8BStudy-Notes/","content":"课前必读 (1讲)开篇词｜贴心“保姆”Spring罢工了怎么办？\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["Spring"],"tags":["Spring"]},{"title":"《Java分布式架构设计与开发实战》study notes","url":"/%E3%80%8AJava%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E3%80%8Bstudy-notes/","content":"课程导学与学习指南\n课程内容设计（结合实际应用场景）\n\n\n\n\n\n\n内容兼具深度、广度\n\n\n\n\n\n\n\n\n\n\n\n\n\n硅步千里，分布式理论加强内功修炼本章节目标\n了解大型互联网系统演进\n掌握架构设计思想\n掌握CAP理论\n掌握BASE理论\n\n\n\n\n中国互联网发展历程\n1994 - 2000年:从四大门户到搜索\n2001-2009年:从搜索到社交化网络\n2010- 至今:移动互联网和自媒体\n\n\n\n\n\n单体应用架构到分布式架构的演进\n单体应用架构\nLinux+Apache+MySQL+PHP\n网站刚起步的时候，流量少。用一台服务器就可以满足\n\n\n应用服务与数据服务分离\n访问增加，带来更大压力\n增加配置解决临时问题\n从横向进行扩展，一分为多\n\n\n不同服务器配置要求不同\n\n\n\n\n服务器类型\n不同配置要求\n\n\n\n应用服务器\nCPU配置高\n\n\n数据库服务器\n磁盘IO快和稳，内存足够大\n\n\n文件服务器\n磁盘足够大\n\n\n\n开始引入缓存\n\n大量交易访问数据库压力增大，响应延迟\n给数据库减负，把请求在前面就处理完\n在数据库前面加入缓存\n\n\n应用服务器集群部署\n\n所有的请求直接打到负载均衡组件\n单台服务器 &gt;多台服务器\n软件: Apache / Nginx / HaProxy / LVS\n硬件:F5\n\n\n数据库的读写分离\n\n并非所有请求都操作缓存，且存在缓存失效场景，对数据库访问造成压力\n利用数据库主从复制机制，将读和写操作分开，进一步提升性能\n\n\n数据库访问模块\n\n对接多个数据源、处理读写分离、甚至分库分表等\n独立于应用程序存在的\nApache ShardingSphere\n\n\n内容分发网络 - CDN\n\nCDN服务进行资源加速\n\n把静态资源提前缓存到各地的边缘服务器\n可以有效地降低DDoS攻击\n\n\n全面分布式化\n\n随着规模不断发展产生数据越来越多，单文件件服务器、单数据库服务器也渐渐地达到瓶颈。利用集群化横向扩展解决问题\nHDFS、TFS、FastDFS\nNoSQL &amp; 搜索引擎\nLucene是一个搜索引擎的开发工具包:全文检索\nSolr和Elasticsearch它们是基于Lucene开发的\n常见的NoSQL有Mongodb和ELasticsearch\n\n\n\n\n单体应用面临诸多问题和挑战\n\n单体应用的代码膨胀，研发成本变高，难实现敏捷交付\n代码维护成本变高，开发人员交接困难\n测试成本变高，回归的工作量变大，给测试带来巨大工作量\n可扩展性差，技术升级时需考虑整体，无法单独调整\n\n\n“大而全的单体”拆分为多个“独立的应用”\n\n应用拆分和解耦\n\n对应用模块进行拆分之后，通过消息中间件进行交互\n此外还有异步处理应用解耦、流量削峰等作用\n\n\n常见的消息中间件\n\n\n\n\n\n消息中间件特性\n\n\n\n\nActiveMQ\n历史悠久，使用Java语言编写的，功能全面，基本上MQ的功能它都有，因此也比较复杂。\n\n\nRabbitMQ\n目前主流之一，跟Spring框架师出同门，因此Spring对RabbitMQ的支持最好\n\n\nKafka\n高性能方面比较有优势。但一开始是基于大吞吐量数据场景设计，在消息可靠性方面比较弱\n\n\nRocketMQ\n它相对前面几个，有后发优势，结合了各方优点综合能力比较好。\n\n\n\n模块拆分引发的问题\n代码冗余，多处相同的代码维护起来困难\n复杂度扩散\n共用一套数据库资源\n\n\n\n\n\n引入服务化架构SOA与微服务对比\n\n\n\n\n\n\n\nSOA\n微服务\n\n\n\n共同点\n都是在分布式环境下，以服务为中心的松耦合应用架构模式服务之间是通过定义明确的接口和协议来进行相互通信\n都是在分布式环境下，以服务为中心的松耦合应用架构模式服务之间是通过定义明确的接口和协议来进行相互通信\n\n\n目标\n解决的是异构系统的服务化\n解决互联网系统快速交付\n\n\n规模\n相对粗粒度\n细粒度\n\n\n适用性\n跨企业、大企业跨部门的复杂应用系统建设\n适合小型团队的持续化发布\n\n\n为快不破，分布式缓存提升系统性能\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["distributed"],"tags":["distributed"]},{"title":"《ZooKeeper分布式专题与Dubbo微服务入门》Study Notes","url":"/%E3%80%8AZooKeeper%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%93%E9%A2%98%E4%B8%8EDubbo%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A5%E9%97%A8%E3%80%8BStudy-Notes/","content":"第1章 分布式系统概念与ZooKeeper简介ZooKeeper简介\n中间件，提供协调服务\n作用于分布式系统，发挥其优势，可以为大数据服务\n支持Java，提供Java和C语言的客户端API\n\n\n\n什么是分布式系统\n很多台计算机组成一个整体，一个整体一致对外并且处理同一请求\n内部的每台计算机都可以相互通信（rest/rpc）\n客户端到服务端的一次请求到响应结束会经历很多台计算机\n\n\n\nZooKeeper的特性\n一致性：数据一致性，数据按照顺序分批入库\n原子性：事务要么成功要么失败，不会局部化\n单一视图：客户端连接集群中的任一zk节点，数据都是一致的\n可靠性：每次对zk的操作状态都会保存在服务端\n实时性：客户端可以读取到zk服务端的最新数据\n\n\n\n\n\n\n\n第2章 ZooKeeper安装Zookeeper主要目录结构\nbin：主要的一些运行命令\nconf：存放配置文件，其中我们需要修改zk.cfo\ncontrib：附加的一些功能\ndist-maven：mvn编译后的目录\ndocs：文档\nlib：需要依赖的jar包\nrecipes：案例demo代码\nsrc：源码\n\n\n\nZooKeeper单机版安装、配置、启动\n环境要求：安装jdk，并配置环境变量（zookeeper是需要java编译的。所以需要安装jdk）\n下载与准备\n\ncd /usr/local/src/wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.11/zookeeper-3.4.11.tar.gztar -zxvf zookeeper-3.4.11.tar.gzmv /usr/local/src/zookeeper-3.4.11 /usr/local/cd /usr/local/ln -s zookeeper-3.4.11/ zookeeper\n\n\n配置文件调整\n\ncd /usr/local/zookeeper/conf/cp zoo_sample.cfg zoo.cfgvim zoo.cfg\n\n\n配置文件参数说明与修改\ntickTime：用于计算的时间单元。比如如session超时:N* tickTime\ninitLimit：用于集群，允许从节点连接并同步到 master节点的初始化连接时间，以tickTime的倍数来表示\nsyncLimit：用于集群，master主节点与从节点之间发送消息请求和应答时间长度。(心跳机制)\ndataDir：必须配置，数据文件目录\ndataLogDir：日志目录，如果不配置会和dataDir公用\nclientPort：连接服务器的端口，默认 2181\n\n\n\n# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.dataDir=/usr/local/zookeeper/dataDir/dataLogDir=/usr/local/zookeeper/dataLogDir/# the port at which the clients will connectclientPort=2181\n\n\n创建数据目录\n\nmkdir -p /usr/local/zookeeper/dataDir /usr/local/zookeeper/dataLogDir\n\n\n配置ZooKeeper的环境变量后，启动ZooKeeper\n\ncd /usr/local/zookeeper/bin./zkServer.sh start./zkServer.sh status./zkServer.sh stop\n\n\n\n\n\n\n\n第3章 ZooKeeper基本数据模型基本数据模型介绍\nZooKeeper的数据模型是一个树形结构\nZooKeeper 的数据模型也可以理解为linux/unix的文件目录:/usr/local/…\n每一个节点都称之为 znode，它可以有子节点，也可以有数据\n每个节点分为临时节点和永久节点，临时节点在客户端断开后消失\n每个zk节点都各自的版本号，可以通过命令行来显示节点信息\n每当节点数据发生变化，那么该节点的版本号会累加(乐观锁）\n删除/修改过时节点，版本号不匹配则会报错\n每个zk节点存储的数据不宜过大，几K即可\n节点可以设置权限acl，可以通过权限来限制用户的访问\n\n\n\nZookeeper命令行客户端基本操作# 客户端连接cd /usr/local/zookeeper/bin/./zkCli.sh[zk: localhost:2181(CONNECTED) 3] helpZooKeeper -server host:port cmd args        stat path [watch]        set path data [version]        ls path [watch]        delquota [-n|-b] path        ls2 path [watch]        setAcl path acl        setquota -n|-b val path        history        redo cmdno        printwatches on|off        delete path [version]        sync path        listquota path        rmr path        get path [watch]        create [-s] [-e] path data acl        addauth scheme auth        quit        getAcl path        close        connect host:port\n\n\n\nzk的作用体现\nmaster节点选举，主节点挂了以后，从节点就会接手工作并且保证这个节点是唯一的，这也是所谓首脑模式，从而保证我们的集群是高可用的\n统一配置文件管理，即只需要部署一台服务器，则可以把相同的配置文件同步更新到其他所有服务器，此操作在云计算中用的特别多(假设修改了redis统一配置)\n发布与订阅，类似消息队列MQ(amg，rmg…),dubbo发布者把数据存在znode上，订阅者会读取这个数据\n提供分布式锁，分布式环境中不同进程之间争夺资源，类似于多线程中的锁\n集群管理，集群中保证数据的强一致性\n\n\n\n\n\n\n\n第4章 ZK基本特性与基于Linux的ZK客户端命令行学习zk常用命令行操作\n进入zk终端\n\ncd /usr/local/zookeeper/bin./zkCli.sh\n\n[zk: localhost:2181(CONNECTED) 0] helpZooKeeper -server host:port cmd args        stat path [watch]        # 修改/设置，可以用来做分布式锁        set path data [version]        ls path [watch]        delquota [-n|-b] path        ls2 path [watch]        setAcl path acl        setquota -n|-b val path        history        redo cmdno        printwatches on|off        # 删除        delete path [version]        sync path        listquota path        rmr path        # watch 可以设置watcher        get path [watch]        # -s 顺序节点\t-e 临时节点\tpath 路径\tdata 数据\tacl 权限        create [-s] [-e] path data acl        addauth scheme auth        quit        getAcl path        close        connect host:port# 查看某个路径（目录/节点）下的列表ls /# 查看某个路径（目录/节点）下的状态stat /# 相当于 ls + statls2 /# 取出节点数据get /cZxid = 0x0\t# zk为节点分配的idctime = Thu Jan 01 08:00:00 CST 1970\t# 节点创建时间mZxid = 0x0\t# 节点修改后分配的idmtime = Thu Jan 01 08:00:00 CST 1970\t# 节点修改时间pZxid = 0x6\t# 子节点idcversion = 0\t# 子节点versiondataVersion = 0\t# 当前节点数据版本号，如果数据被修改了则会加1aclVersion = 0\t# 权限版本ephemeralOwner = 0x0dataLength = 0\t# 数据长度numChildren = 2\t# 子节点个数\n\n\n\nsession的基本原理\n客户端与服务端之间的连接存在会话\n每个会话都会可以设置一个超时时间\n心跳结束，session则过期\nSession过期，则临时节点znode会被抛弃\n心跳机制:客户端向服务端的ping包请求\n\n\n\nwatcher机制\n针对每个节点的操作，都会有一个监督者&gt; wathcer\n当监控的某个对象(znode)发生了变化，则触发watcher事件\nzk中的watcher是一次性的，触发后立即销毁（可以通过第三方开源客户端来设置成永久的）\n父节点，子节点增删改都能够触发其watcher\n针对不同类型的操作，触发的watcher事件也不同:\n(子)节点创建事件\n(子)节点删除事件\n(子)节点数据变化事件\n\n\n\n\n\nwatcher命令\n通过get path [watch]设置watcher\n父节点增删改操作触发 watcher\n子节点增删改操作触发 watcher\n\n\n\nwatcher事件类型父节点\n创建父节点触发：NodeCreated\n修改父节点数据触发:NodeDataChanged\n删除父节点触发:NodeDeleted\n\n\n\n子节点\nIs 为父节点设置watcher，创建子节点触发：NodeChildrenChanged\nls 为父节点设置watcher，删除子节点触发：NodeChildrenChanged\nls 为父节点设置watcher，修改子节点不触发事件（需要把子节点当成父节点来操作，即：给子节点设置watch ，才可以触发watcher事件）\n\n\n\nwatcher使用场景\n作为触发器，统一资源配置（当主机更新节点为新的配置信息，我们获取监听，可以更新客户端的配置信息）\n\n\n\nACL(access control lists)权限控制概述\n节点可以设置相关读写等权限，目的为了保障数据安全性\n权限permissions可以指定不同的权限范围以及角色\n\n\n\nACL命令行\ngetAcl:获取某个节点的acl权限信息\nsetAcl:设置某个节点的acl权限信息\naddauth: 输入认证授权信息，注册时输入明文密码(登录)但是在zk的系统里，密码是以加密的形式存在的\n\n\n\nACL的构成\nzk的acl通过[scheme:id:permissions]来构成权限列表\nscheme:代表采用的某种权限机制\nworld:world下只有一个id，即只有一个用户，也就是anyone，那么组合的写法就是 world:anyone:[permissions]\nauth:代表认证登录，需要注册用户有权限就可以，形式为auth:user:password:[permissions]\ndigest:需要对密码加密才能访问，组合形式为digest: username:BASE64(SHA(password)) :[permissions]\nsuper:代表超级管理员，拥有所有的权限\n\n\nid:代表允许访问的用户\nip:当设置为ip指定的ip地址，此时限制ip进行访问，比如ip:192.168.1.1:[permissions]\n\n\npermissions:权限组合字符串（权限字符串缩写crdwa）\nCREATE:创建子节点\nREAD:获取节点/子节点\nWRITE:设置节点数据\nDELETE:删除子节点\nADMIN:设置权限\n\n\n\n\n\n\nauth 与 digest的区别就是，前者明文，后者密文\nsetAcl /path auth:lee:lee:cdrwa 与 setAcl /path digest:lee:BASE64(SHA1(password))cdrwa 是等价的，在通过\naddauth digest lee:lee 后都能操作指定节点的权限\n\nworld:anyone:cdrwaworld:anyone:cdrwaauth:user:pwd:cdrwadigest: user:BASE64(SHA1(pwd)) :cdrwaaddauth digest user:pwdip:192.168.1.1: cdrwa# super# 1、修改 zkServer.sh 增加super管理员# 2、重启 zkServer.sh\n\n\n\nACL的常用使用场景\n开发/测试环境分离，开发者无权操作测试库的节点，只能看\n生产环境上控制指定ip的服务可以访问相关节点，防止混乱\n\n\n\nzk四字命今 Four Letter Words概述\nzk可以通过它自身提供的简写命令来和服务器进行交互\n需要使用到nc命令，安装:yum install nc\necho [commond] nc [ip] [port]\n\n\n\nZookeeper 四字命令\n[stat] 查看zk的状态信息，以及是否mode\n[ruok] 查看当前zkserver是否启动，返回imok\n[dump] 列出未经处理的会话和临时节点\n[conf] 查看服务器配置\n[cons] 展示连接到服务器的客户端信息\n[envi] 环境变量\n[mntr]监控zk健康信息\n[wchs] 展示watch的信息\n[wchc] 与 [wchp] session与watch 及 path与watch信息\n\n\n\n\n\n\n\n第5章 选举模式和ZooKeeper的集群安装选举模式\nzk集群，主从节点，心跳机制(选举模式)\n配置数据文件 myid 1/2/3 对应 server.1/2/3\n通过 zkCli.sh -server [ip]:[port] 检测集群是否配置成功\n\n\n\n集群搭建# 首先，保持单机的相关配置，再增加如下内容vim zoo.cfg# 如果搭建三台zk的集群，配置格式如下。 第一个端口表示数据复制（同步）使用的端口，第二端口是zk间选举master使用的端口server.1=192.168.61.211:2888:3888server.2=192.168.61.212:2888:3888server.3=192.168.61.213:2888:3888cd dataDirtouch myidvim myid1\n\n\n\n选举测试\n如果master宕机后，会重新选举出master，如果原宕机恢复后zk重启，此恢复后的zk只能作为flower\n\n\n\n\n\n\n\n第6章 使用ZooKeeper原生Java API进行客户端开发Java客户端与zk服务端建立连接/** * @Title: ZKConnectDemo.java * @Package com.imooc.zk.demo * @Description: zookeeper 连接demo演示 */public class ZKConnect implements Watcher &#123;\t\t\tfinal static Logger log = LoggerFactory.getLogger(ZKConnect.class);//\tpublic static final String zkServerPath = &quot;192.168.1.110:2181&quot;;\tpublic static final String zkServerPath = &quot;192.168.61.211:2181,192.168.61.212:2181,192.168.61.213:2181&quot;;\tpublic static final Integer timeout = 5000;\t\tpublic static void main(String[] args) throws Exception &#123;\t\t/**\t\t * 客户端和zk服务端链接是一个异步的过程\t\t * 当连接成功后后，客户端会收的一个watch通知\t\t * \t\t * 参数：\t\t * connectString：连接服务器的ip字符串，\t\t * \t\t比如: &quot;192.168.1.1:2181,192.168.1.2:2181,192.168.1.3:2181&quot;\t\t * \t\t可以是一个ip，也可以是多个ip，一个ip代表单机，多个ip代表集群\t\t * \t\t也可以在ip后加路径\t\t * sessionTimeout：超时时间，心跳收不到了，那就超时\t\t * watcher：通知事件，如果有对应的事件触发，则会收到一个通知；如果不需要，那就设置为null\t\t * canBeReadOnly：可读，当这个物理机节点断开后，还是可以读到数据的，只是不能写，\t\t * \t\t\t\t\t       此时数据被读取到的可能是旧数据，此处建议设置为false，不推荐使用\t\t * sessionId：会话的id\t\t * sessionPasswd：会话密码\t当会话丢失后，可以依据 sessionId 和 sessionPasswd 重新获取会话\t\t */\t\tZooKeeper zk = new ZooKeeper(zkServerPath, timeout, new ZKConnect());\t\t\t\tlog.warn(&quot;客户端开始连接zookeeper服务器...&quot;);\t\tlog.warn(&quot;连接状态：&#123;&#125;&quot;, zk.getState());\t\t\t\tnew Thread().sleep(2000);\t\t\t\tlog.warn(&quot;连接状态：&#123;&#125;&quot;, zk.getState());\t&#125;\t@Override\tpublic void process(WatchedEvent event) &#123;\t\tlog.warn(&quot;接受到watch通知：&#123;&#125;&quot;, event);\t&#125;&#125;\n\n\n\n\n\n\n\n\n\n\n\n第7章 Apache Curator客户端的使用常用的zk java客户端\nzk原生api\nzkclient\nApache curator\n\nzk原生api的不足之处\n超时重连，不支持自动，需要手动操作\nWatch注册一次后会失效\n不支持递归创建节点\n\nApache curator\nApache的开源项目\n解决watcher的注册一次就失效\nApi更加简单易用\n提供更多解决方案并且实现简单:比如 分布式锁\n提供常用的ZooKeeper工具类\n编程风格更爽\n\n\n\n\n\n\n\n第8章 Dubbo入门到重构服务\n\n\n\n\n\n第9章 分布式锁\n\n\n\n \n\n第10章 课程总结\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["ZooKeeper"],"tags":["ZooKeeper","Dubbo","microservice"]},{"title":"《Redis 核心技术与实战》Study Notes","url":"/%E3%80%8ARedis-%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8BStudy-Notes/","content":"开篇词 (1讲)开篇词 | 这样学Redis，才能技高一筹Redis 的坑\n使用 Redis 遇到的坑总的来说大致是以下四方面：\nCPU使用上的“坑”，例如数据结构的复杂度、跨CPU核的访问；\n内存使用上的“坑”，例如主从同步和AOF的内存竞争；\n存储持久化上的“坑”，例如在SSD上做快照的性能抖动；\n网络通信上的“坑”，例如多实例时的异常网络丢包。\n\n\n\n\n\n为什么懂得了一个个技术点，却依然用不好Redis？\n急于解决这些细微的问题，Redis 使用能力就很难得到质的提升。\n只关注零散的技术点，没有建立起一套完整的知识框架，缺乏系统观，但是，系统观其实是至关重要的。（在解决问题时，拥有了系统观，就意味着能有依据、有章法地定位和解决问题。）\n案例分析，把Redis的长尾延迟维持在一定阈值以下：\n\n\n首先，我对Redis的线程模型做了分析，我发现，对于单线程的Redis而言，任何阻塞性操作都会导致长尾延迟的产生。接着，我又开始寻找可能导致阻塞的关键因素，一开始想到的是网络阻塞，但随着对Redis网络框架的理解，我知道Redis网络IO使用了IO复用机制，并不会阻塞在单个客户端上。\n再后来，我又把目光转向了键值对数据结构、持久化机制下的fork调用、主从库同步时的AOF重写，以及缓冲区溢出等多个方面。绕了一大圈子之后，这条影响长尾延迟的“证据链”才得以形成。这样一来，我也系统地掌握了影响Redis性能的关键因素路径，之后再碰到类似的问题时，我就可以轻松解决了。\n\n\n\n高效地形成系统观？\n抓住主线，在自己的脑海中绘制一幅Redis全景知识图\n\nRedis知识全景图都包括：“两大维度，三大主线\n\n\n\n\n\n\n两大维度\n系统维度：\n\n了解Redis的各项关键技术的设计原理，这些能够为你判断和推理问题打下坚实的基础，而且，你还能从中掌握一些优雅的系统设计规范，例如run-to-complete模型、epoll网络模型，这些可以应用到你后续的系统开发实践中。\n\n\n应用维度\n\n应用场景驱动\n缓存和集群是Redis的两大广泛的应用场景。提到缓存场景，你肯定会想到缓存机制、缓存替换、缓存异常等一连串的问题。\n\n\n典型案例驱动\n只有特定的业务场景下（比如亿级访问压力场景）才会出现，并不是普遍现象。可以用“典型案例驱动”的方式学习了。我们可以重点解读一些对Redis的“三高”特性影响较大的使用案例，例如，多家大厂在万亿级访问量和万亿级数据量的情况下对Redis的深度优化，解读这些优化实践，非常有助于你透彻地理解Redis。而且，你还可以梳理一些方法论，做成Checklist，就像是一个个锦囊，之后当你遇到问题的时候，就可以随时拿出自己的“锦囊妙计”解决问题了。\n\n\n\n\n\n三大主线\n高性能主线，包括线程模型、数据结构、持久化、网络框架；\n高可靠主线，包括主从复制、哨兵机制；\n高可扩展主线，包括数据分片、负载均衡。\n\nRedis 问题画像图\n\n\n\n\n举个例子，如果你遇到了Redis的响应变慢问题，对照着这张图，你就可以发现，这个问题和Redis的性能主线相关，而性能主线又和数据结构、异步机制、RDB、AOF重写相关。找到了影响的因素，解决起来也就很容易了。\n\n\n在学习和使用的过程中，你完全可以根据你自己的方式，完善这张画像图，把你自己实践或掌握到的新知识点，按照“问题 –&gt; 主线 –&gt; 技术点”的方式梳理出来，放到这张图上。这样一来，你的积累越来越多，画像也会越来越丰富。以后在遇到问题的时候，就很容易解决了。\n\n\n\n课程是如何设计的？\n基础篇：打破技术点之间的壁垒，带你建立网状知识结构\n具体讲解数据结构、线程模型、持久化等\n\n\n\n\n实践篇：场景和案例驱动，取人之长，梳理出一套属于你自己的“武林秘籍”\n“案例”层面：介绍数据结构的合理使用、避免请求阻塞和抖动、避免内存竞争和提升内存使用效率\n“场景”层面：\n缓存场景：重点讲解缓存基本原理及淘汰策略，还有雪崩、穿透、污染等异常情况\n集群场景：围绕集群方案优化、数据一致性、高并发访问等问题，聊聊可行的解决方案。\n\n\n\n\n\n\n未来篇：具有前瞻性，解锁新特性\nRedis6 新特性\n以及当前业界对Redis的最新探索，这会让你拥有前瞻性视角，了解Redis的发展路线图，为未来的发展提前做好准备。\n\n\n\n\n\n总结\nRedis是一个非常优秀的系统，它在CPU使用、内存组织、存储持久化和网络通信这四大方面的设计非常经典，而这些，基本涵盖了一个优秀的后端系统工程师需要掌握的核心知识和关键技术。希望你通过这个课程的学习，成长为一名优秀的系统工程师。\n\n\n\n\n\n\n\n基础篇 (10讲)01 | 基本架构：一个键值数据库包含什么？概述\n更好的学习方式就是先建立起“系统观”：想要深入理解和优化Redis，就必须要对它的总体架构和关键模块有一个全局的认知，然后再深入到具体的技术点。\n经过这样一个过程，我们在实践中定位和解决问题时，就会轻松很多，而且你还可以把这个学习方式迁移到其他的学习活动上。彻底掌握这个学习思路，让自己的学习、工作效率更高。\n\n构造简单的键值数据库 SimpleKV\n我们只需要关注整体架构和核心模块。我们通过剖析这个最简单的键值数据库，来迅速抓住学习和调优Redis的关键。\n开始构造SimpleKV时，首先就要考虑里面可以存什么样的数据，对数据可以做什么样的操作，也就是数据模型和操作接口。\n才能明白 Redis，它到底能做什么，不能做什么呢？只有先搞懂它的数据模型和操作接口，我们才能真正把“这块好钢用在刀刃上”。\n\n可以存哪些数据？\n在对键值数据库进行选型时，一个重要的考虑因素是它支持的value类型。（例如，Memcached支持的value类型仅为String类型，而Redis支持的value类型包括了String、哈希表、列表、集合等。Redis能够在实际业务场景中得到广泛的应用，就是得益于支持多样化类型的value。）\n从使用的角度来说，不同value类型的实现，不仅可以支撑不同业务的数据需求，而且也隐含着不同数据结构在性能、空间效率等方面的差异，从而导致不同的value操作之间存在着差异。\n对于键值数据库而言，基本的数据模型是key-value模型\n在SimpleKV中，key是String类型，而value是基本数据类型\n从使用的角度来说，不同value类型的实现，不仅可以支撑不同业务的数据需求，而且也隐含着不同数据结构在性能、空间效率等方面的差异，从而导致不同的value操作之间存在着差异。\n理解了这背后的原理，我们才能在选择Redis value类型和优化Redis性能时，做到游刃有余。\n\n可以对数据做什么操作？\nSimpleKV需要支持的3种基本操作\n\nPUT：新写入或更新一个key-value对；\nGET：根据一个key读取相应的value值；\nDELETE：根据一个key删除整个key-value对。\n\n\n有些键值数据库的新写/更新操作叫SET。新写入和更新虽然是用一个操作接口，但在实际执行时，会根据key是否存在而执行相应的新写或更新流程。\n\n根据一段key的范围返回相应的value值。因此，PUT/GET/DELETE/SCAN是一个键值数据库的基本操作集合。\n\n实际业务场景通常还有更加丰富的需求（可以增加EXISTS操作接口，用于判断某个key是否存在）\n\n当一个键值数据库的value类型多样化时，就需要包含相应的操作接口。（Redis的value有列表类型，因此它的接口就要包括对列表value的操作）\n\n\n键值对保存在内存还是外存？\n\n\n-\n优点\n缺点\n\n\n\n保存在内存\n读写快，内存的访问速度一般都在百ns级别\n潜在的风险是一旦掉电，所有的数据都会丢失。\n\n\n保存在外存\n避免数据丢失\n限于磁盘的慢速读写（通常在几ms级别），键值数据库的整体性能会被拉低。\n\n\n\n如何进行设计选择，我们通常需要考虑键值数据库的主要应用场景。\n缓存场景下的数据需要能快速访问但允许丢失，那么，用于此场景的键值数据库通常采用内存保存键值数据。\n\n\nSimpleKV就采用内存保存键值数据。\nSimpleKV的基本组件（大体来说，一个键值数据库包括了访问框架、索引模块、操作模块和存储模块四部分）\n\n\n\n\n\n采用什么访问模式？常用的两种访问模式\n（1）通过函数库调用的方式供外部应用使用，比如，上图中的libsimplekv.so，就是以动态链接库的形式链接到我们自己的程序中，提供键值存储功能；\n（2）通过网络框架以Socket通信的形式对外提供键值对操作，这种形式可以提供广泛的键值存储服务。在上图中，我们可以看到，网络框架中包括Socket Server和协议解析。\n\n\n不同的键值数据库服务器和客户端交互的协议并不相同，我们在对键值数据库进行二次开发、新增功能时，必须要了解和掌握键值数据库的通信协议，这样才能开发出兼容的客户端。\n\n\n实际的键值数据库也基本采用上述两种方式，例如，RocksDB以动态链接库的形式使用，而Memcached和Redis则是通过网络框架访问。\n\nI/O模型设计\n通过网络框架提供键值存储服务，一方面扩大了键值数据库的受用面，但另一方面，也给键值数据库的性能、运行模型提供了不同的设计选择，带来了一些潜在的问题。\n举个例子，当客户端发送一个如下的命令后，该命令会被封装在网络包中发送给键值数据库：\n\nPUT &quot;hello&quot; &quot;world&quot;\n\n\n键值数据库网络框架接收到网络包，并按照相应的协议进行解析之后，就可以知道，客户端想写入一个键值对，并开始实际的写入流程。此时，我们会遇到一个系统设计上的问题，简单来说，就是网络连接的处理、网络请求的解析，以及数据存取的处理，是用一个线程、多个线程，还是多个进程来交互处理呢？该如何进行设计和取舍呢？我们一般把这个问题称为I/O模型设计。不同的I/O模型对键值数据库的性能和可扩展性会有不同的影响。\n举个例子，如果一个线程既要处理网络连接、解析请求，又要完成数据存取，一旦某一步操作发生阻塞，整个线程就会阻塞住，这就降低了系统响应速度。如果我们采用不同线程处理不同操作，那么，某个线程被阻塞时，其他线程还能正常运行。但是，不同线程间如果需要访问共享资源，那又会产生线程竞争，也会影响系统效率，这又该怎么办呢？所以，这的确是个“两难”选择，需要我们进行精心的设计。\n经常听说Redis是单线程，那么，Redis又是如何做到“单线程，高性能”的呢？\n\n\n\n如何定位键值对的位置？\nSimpleKV 需要查找所要操作的键值对是否存在，这依赖于键值数据库的索引模块。索引的作用是让键值数据库根据key找到相应value的存储位置，进而执行操作。\n索引的类型有很多：常见的有哈希表、B+树、字典树等\nMemcached和Redis采用哈希表作为key-value索引，而RocksDB则采用跳表作为内存中key-value的索引。\n一般而言，内存键值数据库（例如Redis）采用哈希表作为索引：原因在于，其键值数据基本都是保存在内存中的，而内存的高性能随机访问特性可以很好地与哈希表O(1)的操作复杂度相匹配。\nSimpleKV的索引根据key找到value的存储位置即可。\n对于Redis而言，它的value支持多种类型，当我们通过索引找到一个key所对应的value后，仍然需要从value的复杂结构（例如集合和列表）中进一步找到我们实际需要的数据，这个操作的效率本身就依赖于它们的实现结构。\nRedis采用一些常见的高效索引结构作为某些value类型的底层数据结构，这一技术路线为Redis实现高性能访问提供了良好的支撑。\n\n不同操作的具体逻辑是怎样的？\nSimpleKV的操作模块就实现了不同操作的具体逻辑：\n对于GET/SCAN操作而言，此时根据value的存储位置返回value值即可；\n对于PUT一个新的键值对数据而言，SimpleKV需要为该键值对分配内存空间；\n对于DELETE操作，SimpleKV需要删除键值对，并释放相应的内存空间，这个过程由分配器完成。\n\n\n\n如何实现重启后快速提供服务？\nSimpleKV采用了常用的内存分配器glibc的malloc和free，因此，SimpleKV并不需要特别考虑内存空间的管理问题。\n键值数据库的键值对通常大小不一，glibc的分配器在处理随机的大小内存块分配时，表现并不好。一旦保存的键值对数据规模过大，就可能会造成较严重的内存碎片问题。\n分配器是键值数据库中的一个关键因素。对于以内存存储为主的Redis而言，这点尤为重要。Redis的内存分配器提供了多种选择，分配效率也不一样\n\n\nSimpleKV重启后能快速重新提供服务，所以，在SimpleKV的存储模块中增加了持久化功能。\n鉴于磁盘管理要比内存管理复杂，SimpleKV就直接采用了文件形式，将键值数据通过调用本地文件系统的操作接口保存在磁盘上。\nSimpleKV只需要考虑何时将内存中的键值数据保存到文件中\n对于每一个键值对，SimpleKV都对其进行落盘保存（数据更加安全可靠，但性能受影响）\nSimpleKV只是周期性地把内存中的键值数据保存到文件中（避免写盘操作的性能影响，潜在代价是数据有丢失风险）\n\n\n\n小结\n\n\n\n\n从SimpleKV演进到Redis，有以下几个重要变化：\nRedis主要通过网络框架进行访问，而不再是动态库了，这也使得Redis可以作为一个基础性的网络服务进行访问，扩大了Redis的应用范围。\nRedis数据模型中的value类型很丰富，因此也带来了更多的操作接口，例如面向列表的LPUSH/LPOP，面向集合的SADD/SREM等。\nRedis的持久化模块能支持两种方式：日志（AOF）和快照（RDB），这两种持久化方式具有不同的优劣势，影响到Redis的访问性能和可靠性。\nSimpleKV是个简单的单机键值数据库，但是，Redis支持高可靠集群和高可扩展集群，因此，Redis中包含了相应的集群功能支撑模块。\n\n\n\n\n\n\n\n\n\n02 | 数据结构：快速的Redis有哪些慢操作？Redis为什么这么快，快在哪里呢？\n一个重要的表现：它接收到一个键值对操作后，能以微秒级别的速度找到数据，并快速完成操作。\n它是内存数据库，所有操作都在内存上完成，内存的访问速度本身就很快。\nRedis的 键值对是按一定的数据结构来组织的，操作键值对最终就是对数据结构进行增删改查操作，所以高效的数据结构是Redis快速处理数据的基础。\n底层数据结构一共有6种，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。\n\n\n\n\n\n\n有些问题已经值得我们去考虑了：\n这些数据结构都是值的底层实现，键和值本身之间用什么结构组织？\n为什么集合类型有那么多的底层结构，它们都是怎么组织数据的，都很快吗？\n什么是简单动态字符串，和常用的字符串是一回事吗？\n\n\n\n键和值用什么结构组织？\n\n\n\n\n\n03 | 高性能IO模型：为什么单线程Redis能那么快？\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["Database","Redis"],"tags":["Redis","Cache","Database"]},{"title":"《从 0 开始学微服务》Study Notes","url":"/%E3%80%8A%E4%BB%8E-0-%E5%BC%80%E5%A7%8B%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1%E3%80%8BStudy-Notes/","content":"\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n"},{"title":"《构建JVM知识体系 解决Java工程师必会的工作/面试难点》Study Notes","url":"/%E3%80%8A%E6%9E%84%E5%BB%BAJVM%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB-%E8%A7%A3%E5%86%B3Java%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%BF%85%E4%BC%9A%E7%9A%84%E5%B7%A5%E4%BD%9C-%E9%9D%A2%E8%AF%95%E9%9A%BE%E7%82%B9%E3%80%8BStudy-Notes/","content":"\n\n第1章 课程导学与准备工作JVM是什么\nJava Virtual Machine\nJava程序的运行环境\nJava最核心的基础\nJava开发必备技能\n\n\n\n为什么要学JVM\n面试需要\n深入理解Java\n排查解决故障\n性能调优\n\n\n\n学习收获\n快速系统深入掌握JVM\n面试中JVM相关问题通通变成加分项\n应用JVM进行问题排查解决\n应用JVM对应用调优\n得到老师多年经验心得\n\n\n\n\n\n\n\n第2章 认识JVM规范\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["Java","JVM"],"tags":["JVM","Java"]},{"title":"《深度解密Java并发工具，精通JUC，成为并发多面手》Study Notes","url":"/%E3%80%8A%E6%B7%B1%E5%BA%A6%E8%A7%A3%E5%AF%86Java%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%EF%BC%8C%E7%B2%BE%E9%80%9AJUC%EF%BC%8C%E6%88%90%E4%B8%BA%E5%B9%B6%E5%8F%91%E5%A4%9A%E9%9D%A2%E6%89%8B%E3%80%8BStudy-Notes/","content":"\n\n第1章 开宗明义为什么要学习并发编程\n招聘jd要求\n面试常客\n通往大牛必须掌握的内容\n并发是众多框架的核心\nJ.U.C是Doug Lea 的灵魂力作，非常优秀经典\n\n\n\n\n\n\n\n第2章 鸟瞰Java并发【上帝视角建立并发知识框架】并发工具分类\n为了并发安全 : 互斥同步、非互斥同步、无同步方案\n为了线程安全（从底层原理来分）\n为了线程安全（从使用者的角度来分类）\n为了方便线程管理、提高效率\n为了线程之间配合，来满足业务逻辑\n\n\n管理线程、提高效率\n线程协作\n\n\n\n\n\n\n\n第3章 线程池【治理线程的最大法宝】线程池介绍线程池的重要性\n很多问题是没有用好线程池导致的\n线程池是面试高频考点\n\n为什么要使用线程\n如果不使用线程池，每个任务都新开一个线程处理\n\nJava中的线程会对应到操作系统的线程\n线程的生命周期内存开销是很高的\n会导致两个问题：\n反复创建线程开销大\n过多的线程会占用太多内存\n\n\n\n\n但是，这样开销太大，而我们希望有固定数量的线程，来执行这N个线程，这样就避免了反复创建并销毁线程所带来的开销问题\n\n解决上面两个问题的思路：\n\n用少量的线程一避免内存占用过多\n让这部分线程都保持工作，且可以反复执行任务避免生命周期的损耗\n\n\n\n使用线程池的好处\n加快响应速度\n合理利用CPU和内存\n统一管理、统计\n\n线程池适合应用的场合\n服务器接受到大量请求时，使用线程池技术是非常合适的，它可以大大减少线程的创建和销毁次数，提高服务器的工作效率\n实际上，在开发中，如果需要创建5个以上的线程，那么就可以使用线程池来管理\n\n线程池的创建与停止线程池构造函数的参数\n\n\n参数名\n类型\n含义\n\n\n\ncorePoolSize\nint\n核心线程数\n\n\nmaxPoolSize\nint\n最大线程数\n\n\nkeepAliveTime\nlong\n保持存活时间\n\n\nworkQueue\nBlockingQueue\n任务存储队列\n\n\nthreadFactory\nThreadFactory\n当线程池需要新的线程的时候，会使用threadFactory来生成新的线程\n\n\nHandler\nRejectedExecutionHandler\n由于线程池无法接受所提交的任务的拒绝策略\n\n\n\ncorePoolSize：指的是核心线程数:线程池在完成初始化后，默认情况下，线程池中并没有任何线程，线程池会等待有任务到来时再创建新线程去执行任务\nmaxPoolSize：线程池有可能会在核心线程数的基础上，额外增加一些线程，但是这些新增加的线程数有一个上限\n\n添加线程规则\n如果线程数小于corePoolSize，即使其他工作线程处于空闲状态，也会创建一个新线程来运行新任务\n如果线程数等于(或大于)corePoolSize但少于maximumPoolSize，则将任务放入队列\n如果队列已满，并且线程数小于maxPoolSize，则创建个新线程来运行任务\n如果队列已满，并且线程数大于或等于maxPoolSize则拒绝该任务。\n\n\n是否需要增加线程的判断顺序是:\ncorePoolSize\nworkQueue\nmaxPoolSize \n\n\n\n增减线程的特点\n通过设置corePoolSize和maximumPoolSize 相同，就可以创建固定大小的线程池\n线程池希望保持较少的线程数，并且只有在负载变得很大时才增加它\n通过设置maximumPoolSize为很高的值，例如IntegerMAX_VALUE，可以允许线程池容纳任意数量的并发任务\n是只有在队列填满时才创建多于corePoolSize的线程，所以如果你使用的是无界队列(例如LinkedBlockingQueue)，那么线程数就不会超过corePoolSize\n\n线程池应该手动创建还是自动创建线程池里的线程数量设定为多少比较合适?停止线程池的正确方法\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["Java","Concurrency"],"tags":["Java","Concurrency"]},{"title":"《分布式协议与算法实战》Study Notes","url":"/%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE%E4%B8%8E%E7%AE%97%E6%B3%95%E5%AE%9E%E6%88%98%E3%80%8BStudy-Notes/","content":"开篇词 (2讲)开篇词 | 想成为分布式高手？那就先把协议和算法烂熟于心吧\n想真正搞懂分布式技术，开发出一个分布式系统，需要先掌握分布式协议和算法。分布式协议和算法是决定分布式系统如何运行的核心规则和步骤\n分布式算法是分布式技术中的核心\n分布式系统里，最重要的，是如何选择和设计合适的算法。解决一致性和可用性的问题。\nInfluxDB系统：就是以分布式算法为核心的分布式集群能力\n掌握分布式算法，是面试架构师、技术专家等高端岗位的敲门砖\n分布式算法难学的原因：\n算法本身抽象\n资料参差不齐，大多以英文论文出现\n很多资料没有站在用的角度，将理论和实践结合\n\n\n\n\n分布式协议与算法学习方法：\n理论篇：分布式架构设计核心的理论基础、典型分布式问题、特性\n协议算法篇：掌握原理、特点、适用场景、常见误区\n实战篇：知识落地，掌握分布式基础理论和分布式算法在工程实践中的应用\n掌握根据场景特点选择合适的分布式算法\n使用分布式算法的实战技巧\n举一反三\n\n\n剖析Hashicorp Raft的实现，并以一个分布式KV系统的开发实战为例，如何使用Raft算法实际开发一个分布式系统，全面拥有分布式算法的实战能力。\n\n\n\n\n收获\n破除你对分布式协议和算法的困惑，帮助你建立信心；\n可落地的 4 大分布式基础理论；\n8 个最常用的分布式协议和算法；\n3 大实战案例手把手教学；\n以实战为中心的分布式内容体系。\n\n\n\n学习路径 | 分布式协议与算法你应该这么学理论篇 (5讲)01 | 拜占庭将军问题：有叛徒的情况下，如何才能达成共识？\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["distributed"],"tags":["distributed"]},{"title":"《阿里新零售数据库设计与实战》study notes","url":"/%E3%80%8A%E9%98%BF%E9%87%8C%E6%96%B0%E9%9B%B6%E5%94%AE%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8Bstudy-notes/","content":"前言\n从设计到落地，提升数据库“技术&amp;业务”综合能力\n相当于参与了真实项目的数据库设计[开发经验很难得]\n具备设计完整数据库平台的能力[设计思想要跟上]\n驾驭新零售数据库混合式集群[特别牛的技术]\n\n\n\n\n\n\n\n新零售是什么\n雷军：新零售是更高效率的零售，我们要从线上回到线下\n马云：线下与线上零售将深度结合，加上现代物流平台，构成未来的新零售\n商务部：以消费者为中心，以技术创新为驱动的零售模新式\n\n\n新零售线上业务仅是电商吗？\n\n\n线上业务不局限于电商，还包括了在线教育、医疗服务，以及金融业务等等\n\n\n新零售的线下业务\n\n\n利用云计算、大数据，以及人工智能技术，将客户分流到线下门店中，让用户体验到定制化的服务\n\n\n新零售平台构成\n\n\n\n\n\n\n\n\n\n前导知识Linux环境准备关闭SELinux\nSELinux是Linux2.6以上版本捆绑的一个安全模块\nSELinux配置复杂，容易跟其他程序冲突，所以建议关闭\n\nvi /etc/selinux/config# 设置SELINUX=disabled，重启系统\n\n\n\n替换yum源curl -o /etc/yum.repos.d/CentOS-Base.repo mirrors.163.com/.help/CentOS7-Base-163.repo# 更新缓存yum clean allyum makecache\n\n\n\n安装MySQL在线安装MySQL# 下载rpm文件yum localinstall https://repo.mysql.com//mysql80-community-release-el7-1.noarch.rpm# 安装MySQLyum install mysal-community-server -y\n\n\n\n本地安装MySQL\n离线下载安装\n\n# 下载MySQL压缩包文件，并上传到/root/mysql目录mysql-8.0.11-1.el7.x86 64.rpm-bundle.tartar xvf mysgl-8.0.11-1.el7.x86 64.rpm-bundle.tar\n\n# 安装第三方依赖包yum install perl -yyum install net-tools -y\n\n# 卸载系统自带的mariadbrpm -qa |grep mariadbrpm -e mariadb-libs-5.5.68-1.el7.x86_64 --nodeps# 安装MySQL程序包rpm -ivh mysql-community-common-8.0.11-1.el7.x86_64.rpmrpm -ivh mysql-community-libs-8.0.11-1.el7.x86_64.rpmrpm -ivh mysql-community-client-8.0.11-1.el7.x86 64.rpmrpm -ivh mysql-community-server-8.0.11-1.el7.x86 64.rpm# 修改/var/lib/mysql目录访问权限chmod -R 777 /var/lib/mysql/# 初始化，初始化数据目录，生成必要的文件，生成root密码mysqld --initializechmod -R 777 /var/lib/mysql/*\n\n\n启动\n\n# 启动数据库# 在线安装使用：service mysql start# 离线本地安装使用：service mysqld start# 查看初始化密码grep&#x27;temporary password’ /var/log/mysqld.log\n\n\n修改root密码\n\n# 本地登录数据库mysql -u root -p# 修改root密码alter user user)) identified by &quot;abc123456&quot;;\n\n\n允许root远程登录\n\n# 允许远程使用root账户UPDATE user SET host = %&#x27; WHERE user =&#x27;root&#x27;;FLUSH PRIVILEGES;# 修改/etc/my.cnf文件character set server = utf8bind-address = 0.0.0.0\n\n\n系统防火墙开放3306端口\n\nfirewall-cmd--zone=public  --add-port=3306/tcp --permanentfirewall-cmd --reload\n\n\n\n业务数据库设计流程\n需求分析：根据用户的需求，分析出需要记录的数据\n概要设计：根据分析出的数据，设计ER图\n详细设计：将ER图转换成数据库模型图和数据表\n\n\n\n业务数据设计模型\n瀑布模型\n\n\n\n\n\n\n螺旋模型\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["DataBase","MySQL"],"tags":["DataBase","MySQL"]},{"title":"《技术面试官识人手册》Study Notes","url":"/%E3%80%8A%E6%8A%80%E6%9C%AF%E9%9D%A2%E8%AF%95%E5%AE%98%E8%AF%86%E4%BA%BA%E6%89%8B%E5%86%8C%E3%80%8BStudy-Notes/","content":"开篇词 (1讲)开篇词 | 世事洞明皆学问，人情练达即文章：小面试，大道理\n面试就是打造团队的第一道门槛，它可能短暂、直接地影响你一个项目的进度，也可能长期、潜在地左右你整个团队的战斗力。\n\n晋升第一课，招募人才\n首先，去负责技术面试，帮助公司和团队招募人才，就是一个职业上升通道的必攻克项\n面试还是一个预期和限制都很明确的快速学习机会，并且，是一个双向的学习机会\n预期：我们针对软件工程师这个特定岗位对于候选人的期待\n限制：明确了双方需要在每轮短短几十分钟的时间内进行交流与合作，完成话题的讨论，或是问题的解决\n\n\n深度体验换位思考，让自己和市场保持同步\n\n打造优秀团队，严把人才关\n总归要有一个环节把质量严格地把控好，否则就要让某个下游环节买单，下游环节不买单，那就要留给用户买单了\n\n候选人成长空间\n长期看，你可以了解到哪些知识和能力是值得长期投入的；短期看，你可以了解对方的初衷和心态是怎样的。\n我们还可以从中评估和强化自己的认识；面试没通过，你也不至于说挂得不明不白。\n\n你的收获\n面试前：我将介绍为什么要对软件工程师进行技术面试，应当覆盖哪些面试角度，以及我们该怎样去设计面试题\n面试中：专栏的重中之重，我将结合实例探讨怎样主导技术面试。包括怎样把控流程，怎样进行算法和数据结构的考察，系统设计的考察，面向对象和测试能力的考察，基础知识的考察，以及行为面试的操作方法等等。\n面试后：我将针对候选人的评估讨论会如何开展来介绍。包括怎样收集事实、提炼数据，怎样引导争辩、达成共识，以及最终怎样给出客观中肯的评估。\n\n\n\n\n\n\n\n面试准备/计划篇 (5讲)01 | 评估体系：公司和团队到底需要怎样的技术人才？\n胜兵先胜而后求战，败兵先战而后求胜\n\n\n\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["interview"],"tags":["interview"]},{"title":"《深入浅出分布式技术原理》study notes","url":"/%E3%80%8A%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E3%80%8Bstudy-notes/","content":"开篇词 (1讲)开篇词｜掌握好学习路径，分布式系统原来如此简单\n分布式系统，已经是互联网公司 IT 架构的事实标准\n是否能系统性地理解分布式系统是初级工程师和资深工程师之间最显著的差别\n\n学习路径的重要性\n在做架构设计和选型的时候，没有知识系统做支撑，不能系统性地思考，处理问题也没有十足的把握\n先要有分布式技术的一些实践和经验。经历一个分布式系统从小到大，从简单到复杂的完整演进过程。（这样可以对分布式系统有更全面、深刻的认知，熟悉分布式系统中每一个组件的设计原则，能够站在一个全局的角度，去思考分布式系统中各个组件之间的关联与取舍。对分布式系统也有清晰的知识脉络与理解）\n一定要有一条明确的学习路径，从最根本的原因出发\n多问自己为什么\n思考怎么做\n在技术理解与实践中反复横跳，才能由点成线\n在总结中抓住技术实现的关键点和系统脉络，不迷失于细节，才能连线成网\n\n\n\n课程设计\n首先，找到分布式系统中稳定不变的知识、原理和解决思路。比如注册发现的原理、故障处理的思路和 CAP 理论等等（分布式系统技术要点多，但万变不离其宗）\n其次，去繁从简。\n只聚焦于日常工作中接触最频繁的在线业务分布式系统，依据是否有状态将其分为“分布式计算”和“分布式存储”这两大部分，从简单到复杂依次介绍分布式系统的相关知识与原理\n\n\n\n\n\n\n\n学习计划\n专栏将分为四个递进的模块，学习计划如下\n\n概述篇\n学习一个知识应该先理解这个知识的来龙去脉，我们先讨论分布式系统产生的过程：它为什么会产生，产生后解决了什么问题，又带来了哪些新问题，遇到哪些方面的挑战。\n通过“概述篇”的学习，可以比较好地抓到分布式系统的脉络和关键点，有了很强的学习目标和路径，就不会迷失在各种系统和框架实现的细节中了。\n\n分布式计算篇\n从单机系统演进到分布式系统后，引入哪些新问题的角度，在技术原理层面一个一个讨论并解决这些问题。\n学习之后，可以在各种系统和场景中理解和运用它，并且知道在系统设计层面应该如何取舍。\n\n分布式存储篇\n分布式技术篇中的进阶篇，我们对计算进行分布式扩展后，再一起来讨论存储的分布式扩展。这里我们从简单到复杂，一起讨论数据分片、数据复制、分布式事务和一致性等相关的知识。\n掌握之后，再做架构设计时，你会发现思维的深度和广度都得到了提升。\n\n总结篇\n此时，已经对分布式系统的重要原理有了系统性地理解，这个时候，我们再一起来看分布式系统的发展历程和未来趋势。\n我们从分布式计算的角度，一起讨论分布式系统是怎么从单机系统演进到 Service Mesh的；还会从分布式存储的角度，一起讨论分布式系统是怎么从单机系统的 ACID 演进到NewSQL 的。\n\n\n这个专栏最大的价值就是能够系统性地解决你的问题，不需要花费大量的精力再进行一次低效的探索。\n\n参考资料\n[知乎：如何系统性的学习分布式系统?](如何系统性的学习分布式系统? - kylin的回答 - 知乎 https://www.zhihu.com/question/320812569/answer/1386491563)\n\n\n\n\n\n\n\n概述篇 (3讲)01｜导读：以前因后果为脉络，串起网状知识体系\n学习一个知识之前，比较好的方式是先理解它的前因后果：前因就是这个知识产生的过程中，它解决了什么问题，怎么样解决的。后果就是它的出现又带来了哪些新的问题，这样我们才能比较好地抓到它的脉络和关键点，不会一开始就迷失在细节中。\n\n\n\n前因：分布式系统解决了什么问题\n学习分布式之前，要解决的第一个问题就是：分布式系统解决了什么问题，怎么样解决的？\n\n分布式系统解决了单机性能瓶颈导致的成本问题\n解决了用户量和数据量爆炸性地增大导致的成本问题（必须寻找更经济的方案来处理和存储这些数据）\n满足了业务高可用的要求\n分布式系统解决了大规模软件系统的迭代效率和成本的问题\n\n\n在互联网时代，单机系统是无法解决成本、效率和高可用问题的\n\n\n\n分布式系统又是怎么解决单机系统面临的成本、效率和高可用的问题呢？\n分布式系统指的是由一组通过网络进行通信，为了完成共同的任务，而协调工作的计算机节点组成的系统（分布式系统是通过多工作节点，来解决单机系统面临的成本、效率和高可用问题的）\n\n\n\n\n分布式系统的发展是无法阻挡的技术大潮流\n\n\n如何理解分布式系统的出现，以及分布式系统在不同业务场景中的表现形式\n所以我们可以把分布式系统看成是单体系统的平民化和物美价廉的版本\n分布式系统在不同的业务场景中有着不同的表现形式\n流量路由策略加多副本部署（微服务是其中的一种架构形式）是无状态服务的分布式架构方案\nRedis Cluster 和 Codis 等方案实现了缓存的分布式化\nKubernetes 则完成了操作系统的分布式进化\nNoSQL 掀起了数据库分布式化的第一波浪潮，而 NewSQL 则推动着支持 ACID 的关系数据库的分布式化\n\n\n\n\n\n\n\n后果：如何思考和处理分布式系统引入的新问题\n分布式系统的出现也引入了分布式系统内部工作节点的协调问题，主要体现在分布式系统内部组件、实例之间，通过异步网络进行通信和协调的问题上。\n\n\n针对内部工作节点的协调问题，分布式系统是怎么做的？\n对于分布式计算（无状态）的情况，系统内部的协调需要做哪些工作\n怎么找到服务？（服务的注册与发现）\n怎么找到实例？（负载均衡与路由）\n怎么管理配置？（配置中心）\n怎么进行协同？（分布式锁）\n怎么确保请求只执行一次？（重试与幂等）\n怎么避免雪崩？（快速失败和降级机制（熔断、降级、限流等），弹性扩容机制）\n怎么监控告警和故障恢复？（完善分布式系统的监控（比如接口的时延和可用性等信息），分布式追踪 Trace ，模拟故障的混沌工程以及相关的告警等机制。同时做好故障恢复预案，确保在故障发生的时候，能够快速恢复故障。）\n\n\n分布式存储（有状态）的内部协调是怎么做的\n怎么进行协同？\n怎么做数据分片（单机系统是不可能存储所有数据的，所以需要解决怎么将数据按一定的规则，分别存储到不同的机器上这个问题，目前使用较多的方案是：Hash 和 Region 分片的策略，但是要注意了解一下它们的优缺点和各自的应用场景。）\n怎么做数据复制（为了满足系统的高可用要求，需要对数据做冗余处理）\n怎么做分布式事务\n\n\n\n\n\n\n\n系统学习\n从实践出发，研究目前比较常用的分布式系统的设计，HDFS 或者 GFS（分布式文件系统）、Kafka 和 Pulsar（分布式消息队列），Redis Cluster 和 Codis（分布式缓存），MySQL 的分库分表（传统关系型数据库的分布式方案），MongoDB 的 Replica Set 和Sharing 机制集（NoSQL 数据库），TiDB（NewSQL）以及一些微服务框架等\n\n从理论出发，研究分布式相关的论文（《Designing Data-IntensiveApplications》）\n\n\n\n为了更好地理解如何处理分布式系统引入的内部工作节点的协调问题，把它们总结为下面三类问题：\n路由问题\n\n\n分布式系统由单体系统拆分而来，必然会导致分布式系统内部，出现复杂的路由问题。路由问题主要是解决分布式系统内部各服务和实例之间的通信，我们可以将“怎么找到服务”和“怎么找到实例”等服务注册发现和负载均衡的问题，理解为正常情况下的路由问题，将“怎么做数据分片”的问题，理解为带状态的路由问题，将“怎么避免雪崩”涉及的熔断、降级等快速失败和降级机制，理解为异常情况下的路由问题。\n\n\n共识问题\n\n\n分布式系统的各个组件是运行在不同机器上的不同进程，因为程序总是需要按一定的逻辑有序地执行，所以需要一个办法，来协调分布式系统内部，已经各自为政的服务和实例，而共识就是讨论并解决这一类问题的，例如“怎么做数据复制”、“怎么做分布式事务”和“怎么做分布式锁”里，都会涉及共识问题。\n\n\n运维问题\n\n\n分布式系统相对于单体系统是非常碎片化的，如果还依靠人肉运维，在效率上是完全行不通的，所以催生了一系列自动化运维的工具和平台来解决这一类问题，例如“怎么管理配置”和“怎么监控告警和故障恢复”都涉及运维的问题。\n\n\n\n总结\n在学习新知识的时候，只有点、线结合，形成网状的知识体系\n\n\n\n\n\n\n\n\n\n02｜新的挑战：分布式系统是银弹吗？我看未必！\n要从根本上理解分布式系统的设计方法和原则，这就需要时刻谨记单体系统和分布式系统之间的差别\n从本质上来说，单体系统是以单进程的形式运行在一个计算机节点上，而分布式系统是以多进程的形式运行在多个计算机节点上，二者的本质差别导致了分布式系统面临着四个方面的新问题，分别是：故障处理、异步网络、时钟同步和共识协同。\n\n\n\n全部失败与部分失败\n单体服务系统中，在硬件正常的时候，对于一个确定的输入，总会得到一个确定的输出。就算是在内存、磁盘损坏等硬件异常的时候，对于一个确定的输入，计算机也会直接出现无法启动或崩溃的情况，而不是给出一个模棱两可或不正确的结果。\n这种全部失败的处理逻辑，会大大减轻用户使用计算机的心智负担，让我们明确地知道，如果系统内部发生了故障，计算机不会给出错误的结果，而是会全部崩溃。\n分布式系统由多个计算机节点组成，虽然每一个计算机节点都是全部失败的模型，但是如果系统中的某些节点出现宕机或者网络故障，整个分布式系统就会出现部分失败的情况\n在分布式系统中，我们需要接受部分失败。\n在分布式系统中，故障处理是软件设计的一个重要组成部分。我们需要时刻谨记节点宕机、网络分区等各种问题出现时，系统应该怎么正确处理，比如分布式系统在设计的时候，每一个组件都必须是高可用的。\n\n\n\n本地调用与远程调用\n单体系统内部几乎不依赖网络，但是网络却是架构分布式系统的根基。（单体系统和分布式系统对网络的依赖程度有非常明显的差别）\n\n在单机系统中，系统各个组件之间直接本地调用即可。在分布式系统中，不同的组件运行在不同的机器上，只能通过网络来进行调用，即远程调用。\n\n远程调用多依赖了网络这个通道，但是这却给系统带来了非常大的复杂性，其实主要原因还是网络本身的复杂性所导致的。\n\n单机系统的本地调用方式，我们可以理解为只要发起调用，调用操作就一定会执行，并且我们可以忽略调用方和被调用方之间的数据传递时间。\n\n务 A 通过网络远程调用服务 B 可能会出现哪些不确定的情况\n\n\n\n\n\n\n\n\n\n\n\n在这样的情况下，通常的做法是采用超时机制，请求方在发起请求后，设置一个超时时间，这样能确保请求方在超时时间内，一定能得到一个响应。如果在超时时间内，请求方得到了明确的响应，不论这个响应是被调用服务回复的，还是网络地址不可达等网络错误，调用方都可以根据响应结果一一来处理。\n\n如果请求在超时时间内没有收到任何响应，即响应超时，那么调用方将无法区分下面四种情况：\n\n\n\n\n\n\n\n\n\n\n\n在响应超时的情况下，如果调用方想确保这个请求被执行，只能重新发送刚刚的请求。但是，如果之前的请求只是在网络中延迟或者响应丢失了，例如上面 2、3 和 4 中描述的情况，重试操作会导致这个请求被多次执行；如果之前的请求在网络中丢失了，例如上面 1描述的情况，那么调用方不进行重试的话，这个请求就会出现一次都没有被执行过的情况。\n\n\n在分布式系统的设计中，我们要充分考虑通过网络进行远程调用导致的不确定性，比如在响应超时的情况下增加重试机制，确保请求能最少执行一次。在重试的时候增加幂等的机制，确保请求只被精确处理一次，并且对重试机制增加退避策略，确保系统不会因为重试导致雪崩。\n\n\n\n全局时钟与多个时钟\n计算机系统一般是通过石英钟来计算时间的，但是石英钟的振动频率会随着温度等原因变慢或变快，所以在运行时间比较长后，计算机系统的时间可能会发生比较大的误差，所以人们又增加了一组专门的时间服务器。我们可以认为这些时间服务器的时间是准确的，计算机系统通过网络定期获得时间服务器的时间，来调整本地时间，即网络时间协议（NTP）。我们可以通过下面的公式来计算当时的时间：本地时间 = 时间服务器的返回时间 + 时间服务器响应的网络时延\n网络时延是不可预测的，所以通过 NTP 我们依然无法获得准确的时间。\n一般的精度都是在几十毫秒的范围内。不过，这个精度对于单机系统来说是足够的\n计算机系统中，时间主要有两个作用\n第一个是记录事件发生的时间。这是一个绝对时间，是让我们来阅读和理解的\n第二个是记录事件之间的发生顺序，这是一个相对时间。\n\n\n在单机系统中，由于只有一个时钟，先执行的事件一定能获得更小的时间，通过本地时钟就可以确保全局事件之间顺序的正确性，所以单机系统是一个全局时钟的模型。\n\n\n分布式系统是由多台计算机节点组成的，每一个节点都有自己的时钟，并且计算机执行的速度非常快，在一个毫秒内可以做非常多的事情。在这种情况下，如果在每一个节点，都采用本地的时钟来记录事件的发生时间，然后基于多个节点上的事件按发生时间进行排序，就很容易出现时间穿越的问题:\n\n\n\n\n\n\n在多主复制的情况下，客户端 A 在主副本 1 修改了 x = 5，记录时间为 10 ms，但是该副本时间慢了 10 ms，所以实际时间为 20 ms。几乎同一时间，客户端 B 在主副本 2 修改了 x = 10，记录时间为 15 ms，但是该副本时间快了 10 ms，所以实际时间为 5ms。\n一般对于这种情况的处理策略是最后写入获胜（LWW），在数据合并的时候，如果按照主副本 1、2 的记录时间来处理的话，最终 x = 10，会导致主副本 1 的修改丢失。\n\n\n在分布式系统的设计中，我们一定要谨记系统中各个节点的本地时钟是存在误差的，不能依赖各自的时钟对事件进行排序。\n针对上面问题的解决思路:\n一个是回到单机系统的全局时钟的模式，所有节点对于需要排序的事件时间，不使用本地时钟的时间，而是去请求同一个时间服务器获得事件的发生时间，然后依据这个时间进行排序；\n另一个是 Google 在 Spanner 中使用的，通过 GPS 和原子钟实现 TrueTime API 来解决。\n\n\n\n\n\n一言堂与共识\n线程之间的同步操作：在计算机系统中，同时只允许一个线程操作某一个数据，和同时只允许一个线程执行某一个操作，如果不遵守这个规则，就可能会导致数据错误等不可预料的后果\n在单体系统中，需要协同的多个线程是属于同一个进程的，所以同步操作很简单，直接使用进程内的资源来做协同就可以了，比如锁、信号量等。对于这些线程来说，所有的同步操作都以进程的资源为准，就好像进程是一个一言堂的管理员，协同进程内部的所有线程之间的同步。\n分布式系统中各个组件都是独立的进程，运行在不同的机器上。所以，对于分布式系统来说，我们需要处理的是一个跨机器的多进程同步问题。\n方法：我们选择一个服务来做同步操作的管理者（我们称为同步服务），在多个进程间需要同步时，就到同步服务来请求一个锁，获得锁的进程就可以操作，其他的进程就必须等待。\n\n\n在做分布式系统设计的时候，我们必须要考虑到故障的存在，所以同步服务不能只有一个实例，它需要多个实例来保障它的高可用，那么同步服务应该由哪一个实例，来处理其他进程的同步请求呢？\n\n\n你可能会想通过配置直接指定一个，这确实解决了同步服务启动时的问题，但是如果被指定实例宕机了，接下来该由哪一个实例来继续处理同步请求呢？\n\n\n我们通过这些讨论，会发现问题依然没有解决，只是转移了，也就是将分布式系统的多进程同步问题变成了同步服务的选主问题。\n其实，这是一个共识问题，需要分布式系统中参与同步的进程之间能达成共识，目前我们是通过 Paxos 或者 Raft 这样的共识算法来解决问题的\n\n\n\n总结\n\n\n\n\n在不可靠的硬件上通过软件来容错，构建高可用的分布式系统。\n如何确保请求只被精确处理一次成为了分布式场景下新的挑战。\n如何对系统中的事件进行排序，变成分布式场景下新的挑战。\n单体系统的单进程、多线程的同步模型变成了跨机器的多进程同步模型，要解决这个问题，就需要分布式系统中参与同步的进程之间能达成共识。\n\n\n\n\n\n\n\n03｜CAP 理论：分布式场景下我们真的只能三选二吗？\n经过不断地思考，人们在实践分布式系统架构的时候，从系统可用性和数据一致性的权衡中总结出来了 CAP 理论，它是指导人们在面对架构分布式系统时，进行取舍的设计原则。同时，CAP 理论深刻影响着分布式系统的设计与发展，是我们在学习分布式系统时不能绕过的知识。\n\n\n\n什么是 CAP 理论\nCAP 理论是加州理工大学伯克利分校的 Eric Brewer 教授在 2000 年 7 月的 ACM PODC会议上首次提出的，它是 Eric Brewer 在 Inktomi 期间研发搜索引擎、分布式 Web 缓存时得出的关于数据一致性（ C：Consistency ）、服务可用性（ A：Availability ）、分区容错性（ P：Partition-tolerance ）的一个著名猜想：\n\n\nIt is impossible for a web service to provide the three following guarantees : Consistency, Availability and Partition-tolerance.\n\n\n在这个猜想提出的 2 年以后，来自麻省理工学院的 Seth Gilbert 和 Nancy Lynch 从理论上证明了 Eric Brewer 教授的 CAP 猜想是成立的，从此，CAP 理论在学术上正式成为了分布式领域公认的定理，并深刻影响着分布式系统的发展。\n\nCAP 理论告诉我们，一个分布式系统不可能同时满足数据一致性、服务可用性和分区容错性这三个基本需求，最多只能同时满足其中的两个。\n\n\n\n\n一致性（ C ）\nCAP 理论中的一致性是指强一致性（ Strong Consistency ），又叫线性一致性（Linearizable Consistency ），它要求多节点组成的分布式系统，能像单节点一样运作，如果一个写操作返回成功，那么之后的读请求都必须读到这个新数据；如果返回失败，那么所有的读操作都不能读到这个数据。\n其他的一致性级别\n序列一致性（ Sequential Consistency ）\n最终一致性（ Eventual Consistency ）\n……\n\n\n\n\n\n可用性（ A ）\nCAP 理论-可用性的定义：要求系统提供的服务必须处于 100% 可用的状态，对于用户的每一个操作请求，系统总能够在有限的时间内返回结果。\n\n100% 可用\n它说的是系统必须完全可用，不允许任何不可用的情况出现，这是一个非常理想的模型\n\n有限时间内\n对于客户端的一个请求，系统必须在指定的时间内返回对应的请求结果，如果超过了这个时间，系统就被认为是不可用的（一般来说，“有限时间内”是系统在设计的时候，就设定好的系统运行指标）\n\n返回结果\n系统在完成对客户端请求的处理后，必须返回一个正常的响应结果。客户端可以根据这个响应结果，来明确判断这个请求执行成功还是失败，而不是返回一个让用户无法判断的不正常的响应结果。\n\n\n\n分区容错性（ P ）\n分区指的是在整个分布式系统中，因为各种网络原因，系统被分隔成多个单独的部分，它不仅包含我们通常说的网络分区，也包含因为网络丢包导致的网络不通的情况。\n在现实的分布式系统中，我们面对的就是一个不可靠的网络和有一定概率宕机的设备\n分区容错性 P 是一个必须项，而不是可选项。\n\n\n对于分布式系统工程实践来说， CAP 理论更合适的描述是：在满足分区容错的前提下，没有算法能同时满足数据一致性和服务可用性。\n\n\n\nCAP 理论产生的影响\n关于数据一致性和可用性之间的争论由来已久，当时主要表现为 ACID 与 BASE 之间的争论。\n当 CAP 理论提出后，我们明白了在分布式系统中，只能在强一致性和 100% 的可用性之间二选一，不能两个都要。从此 BASE 理论也逐渐被人们所接受，在大规模存储的场景中广泛应用，并且开创了从 2000 年到 2010 年， NoSQL 运动的黄金十年。\n\n\n\nCAP 理论的重新思考与理解\n一个有历史使命的事物，在使命完成后，要么就过时了，人们不再提起它，要么就会对它有新的解释，让它跟随时代一起发展下去。而 CAP 理论显然属于后者，因为直到现在，人们还在对它不断地重新思考与理解。\n在 2000 年的时候，CAP 理论通过一个简单但是精确定义的模型，论证了在一个满足分区容错的分布式系统中，当我们进行系统设计时，只能在数据一致性和服务可用性之间二选一。其中，数据一致性（ C ）指的是数据的强一致性，服务的可用性（ A ）指的是服务100 % 的可用性，这才是 CAP 理论论证模型的关键点。\n\n\n\n对可用性的重新思考与理解\n对于数据的一致性（ C ） ，除了 CAP 理论要求的强一致性外，还有单调一致性、会话一致性和最终一致性等。\n如果我们的系统设计选择了 AP 模型，在数据一致性方面，虽然我们无法实现强一致性，但是我们也不要全部放弃，可以努力去实现更高的一致性级别，为系统的服务提供更好的抽象。\n\n对分区容错性的重新思考与理解\n在网络不出现分区的时候，我们将数据强一致性和 100% 的可用性都选择，等到网络出现分区的时候，系统再选择放弃部分的可用性或者降低数据一致性的级别（可行）。这实际是将 CAP 理论的选择，推迟到出现网络分区的时候，而不是系统一启动就进行 CAP 的选择。这样可以大大提高系统的可用性和数据一致性，并且系统依然能容忍网络分区。\nCAP 理论给我们定义了系统的设计边界，虽然想要设计出超过边界的系统是徒劳的，但是我们却可以无限逼近边界，并且把它作为我们设计系统的目标。\n\n\n\n\n\n\n\n春节加餐 (3讲)春节加餐｜系统性思维，高效学习和工作的利器\n学习和工作是我们人生中非常关键的两个部分，它们占据了我们大部分的时间，并且它们的结果也在很大程度上，决定了我们生活的质量和幸福感。\n在同样的时间里，如何让学习和工作变得更高效，就是我们自我提升的关键。\n\n\n\n对于学习，从深度和广度上运用系统性思维方式\n面临两个问题：\n学习之前，知识太抽象，不好理解\n学习之后容易忘记，记不住知识点\n\n\n问题原因：学习方式不够系统\n\n\n因为我们在学习一个知识时，直接面对的是这一个知识的结论，是高度总结和抽象的结果，所以在我们不了解这个知识相关的时代背景和原因的情况下，直接去进行学习，肯定会一知半解，甚至毫无头绪。\n如果跳过了这个知识产生的时代背景和原因，在深度的学习上就缺乏了系统性。\n正确的学习思路应该是：我们要知道一个知识是为了解决什么问题而产生的，后面又经过了什么样的迭代和优化，最终演变成了什么样子。\n\n\n学习之后，容易忘记，记不住这个知识，是因为在广度的学习上缺乏了系统性。\n我们学习了很多零散的知识，但是却没有将知识点之间建立起联系，形成一个相互依赖的网状知识体系。\n构建网状知识体系\n\n\n\n对于工作，通过系统性思维从根本上解决问题\n如果我们只是见招拆招地解决，就会发现问题永远都解决不过来\n系统性的思维方式是解决它们的根本。我们在每一次面对独立的问题的时候，应该跳过问题表层现象，深度思考这个问题的本质原因，系统性地解决。\n\n\n\n总结\n在学习中，从深度上系统性学习，我们可以了解一个知识的来龙去脉；\n\n在广度上系统性学习，我们可以明白知识之间的关系，并且建立好知识网络；\n\n在工作中，使用系统性思维解决问题，可以让我们找到问题的本源，从根本上解决问题。\n\n有的人觉得学习非常痛苦，是因为学习效率不高，而且没有掌握好方法\n\n\n\n\n\n\n\n\n春节加餐｜深入聊一聊计算机系统的时间\n在计算机系统内部，主要有两种时钟：墙上时钟和单调时钟，它们都可以衡量时间，但却有本质的区别。\n\n\n\n墙上时钟\n在 Linux 系统中，墙上时钟的表示形式为 UTC 时间，记录的是自公元 1970 年 1月 1 日 0 时 0 分 0 秒以来的秒数和毫秒数（不含闰秒）。\n\nLinux 系统需要处理闰秒的逻辑就是因为 Linux 系统使用 UTC 时间，但是系统中记录的UTC 时间是不含闰秒的。\n\n\n\n\n墙上时钟的同步\n计算机内部的计时器为石英钟，但是它不够精确，随着机器的温度波动，会存在过快或者过慢的问题，所以依靠计算机自身，来维持墙上时钟的准确性是不可能的，这就是计算机系统内的时间需要与外部时间进行同步的原因。\n\n\n\n闰秒出现的原因\n因为地球自转速率变慢，所以目前的两种时间计量系统：世界时和原子时，它们之间发生了误差，这就是闰秒出现的根本原因\n为了统一原子时与世界时之间的差距，协调世界时（ UTC ）就产生了。从 1972 年1 月 1 日 0 时起，协调世界时秒长采用原子时秒长，时刻与世界时的时刻之差保持在正负0.9 秒之内，必要时用阶跃 1 整秒的方式来调整。\n这个 1 整秒的调整，叫做闰秒，如果增加 1 秒就是正闰秒，减少 1 秒就是负闰秒。 UTC 从 1972 年 1 月起正式成为国际标准时间，它是原子时和世界时这两种时间尺度的结合。\n\n\n\n闰秒的处理\n因为 Linux 系统记录着，自公元 1970 年 1 月 1 日 0 时 0 分 0 秒以来的秒数和毫秒数，但是不含闰秒这种情况，导致了在 Linux 系统中每分钟有 60 秒，每天有 86400 秒是系统定义死的。\nLinux 系统需要额外的逻辑来处理闰秒。目前处理闰秒的方式主要有两种，一种是在Linux 系统上进行跳跃式调整，另一种是在 NTP 服务上进行渐进式调整的 Slew 模型\n\n\n\n跳跃式调整\n当 UTC 时间插入一个正闰秒后，Linux 系统需要跳过 1 秒，即这一秒时间过去后，在 Linux 的时间管理程序中不应该去计时，因为闰秒的这一秒钟在 Linux 系统中不能被表示。\n当 UTC 时间插入一个负闰秒后，Linux 系统就需要插入 1 秒，即 Linux 的时间管理程序中要增加 1 秒钟的计时。虽然并没有过去 1秒钟的时间，但是闰秒的这一秒钟在Linux 系统中是不存在的。\n\n\n\nSlew 模式\n当 UTC 时间需要插入一个正闰秒时， NTP 服务就会每秒调整一定的 ms 来缓慢修正时间。这样 Linux系统从 NTP 服务同步时间的时候，就不会感知闰秒的存在了，内核也就不需要启动闰秒相关的逻辑了。\n\n\n\n单调时钟\n单调时钟是一个相对时钟，不需要与外部的时钟进行同步，较墙上时钟要简单很多\n\n单调时钟总是保证时间是向前的，不会出现墙上时钟的回拨问题，所以它非常适合用来测量持续时间段\n\n\n\n\n时间的管理\n计算机必须在硬件的帮助下才能计算和管理时间。前面说的石英钟就是用来做计算机的系统定时器的，系统定时器以某种固定的频率自行触发时钟中断。由于时钟中断的频率是编程预定的，所以内核知道连续两次时钟中断的间隔时间，这个间隔时间就叫做节拍。通过时钟中断，内核周期性地更新系统的墙上时钟和单调时钟，从而计算和管理好时间。\n\n处理器在给定的时间内执行指令数，通过 BogoMIPS 值，计算机就可以得到非常小的精度了\n\n\n\n\n\n\n\n\n春节加餐｜技术债如房贷，是否借贷怎样取舍？\n我们一般说的技术债务指的是，将一些技术方案通过简单、粗暴的方式来实现，以减少研发资源和研发时间的投入。\n\n\n\n技术债务是生产力项目快速发展的初期\n内部和外部的环境都在剧烈变化，快速交付是非常重要的，我们需要通过借技术债务来融资，快速完成我们的项目，确保在竞争中不会失败\n\n\n\n项目发展的中期\n在这时，我们经常会碰到一些技术决策，需要思考到底应该很完善、系统地完成，还是借一点技术债务，让实现变得简单一点。\n\n\n\n项目发展的后期\n如果我们还有一些其他的更高投入产出比（ROI）的事情，我们就可以选择借一些技术债务来完成项目的工作，然后将空余的资源投入到更高 ROI 的事情，达到全局最优的效果。\n\n\n技术债务是生产力，合理利用技术债务会大大提高我们的研发效率，提高项目的成功率。\n\n\n\n技术债务应该是深思熟虑的结果\n技术债务影响的范围\n\n\n\n\n\n\n系统的接口和协议是对外提供服务的，就导致它的影响范围非常大，并且还会随着接入方的增加，而自动放大技术债务\n\n系统架构的技术债务的利息一般也是很高的，因为系统的架构会从全局影响系统的设计，它的影响范围会非常大，并且会随着系统的迭代而增加\n\n局部的功能和逻辑之类的实现的利息是比较低的，因为它只会影响到局部的代码实现，比如一个函数的具体实现、写死的配置和策略等影响范围不大的地方\n\n非常边缘的功能和一些尝试型的功能实现的利息是非常低的，因为边缘功能后续的迭代不会很多，它在时间维度上的影响范围是非常小的，而尝试型的功能在后面是有一定的可能性被放弃的。虽然我们希望尝试都成功，但是如果被放弃后，从技术债务的角度来看的话，我们甚至连本金都不需要还。所以，这样的利息债务可以根据需要多借一些。\n\n\n\n\n技术债务是需要不断去偿还的\n在面对技术债务的时候，有可能会迷失。那么如果不重视偿还，会出现什么问题呢？\n这会让我们系统的技术债务恶化，我们每一次的迭代都需要付出不少的利息，这个利息包括迭代的工程效率低、上线的故障等。如果技术债务积累到一定的程度，甚至会影响这个业务的成本\n所有的债务都是需要信用来担保的，在借技术债务的过程中，用来担保的是我们的技术信用，即我们的技术影响力。技术影响力对于我们职业生涯的发展是非常关键的，如果我们在自己负责的项目中，积累了非常多的技术债务，那么在其他人了解这个项目的情况后，将会影响我们的技术影响力。\n\n\n\n\n\n总结\n合理控制技术债务，让技术债务变成我们的杠杆，而不是负担。\n技术债务和贷款买房的思维模式一样，如果借技术债务的收益大于利息的时候，你就大胆地去借吧！\n\n\n\n\n\n\n\n分布式计算篇 (15讲)04｜注册发现： AP 系统和 CP 系统哪个更合适？为什么需要服务注册发现单体服务面临的问题\n\n\n\n成本方面\n我们在做所有的事情时都会考虑投入产出比（ROI），所以成本是我们必须考虑的一个问题。对于单体服务在服务器硬件方面的成本，我们需要特别注意异构工作负载和不同保障级别这两个方面的问题。\n\n异构工作负载方面\n单体服务会包含多种多样的功能模块，有一些是 IO密集型的模块，比如主要对数据库进行 CRUD 的功能模块；另一些则是计算密集型的模块，比如图片、音频和视频转码相关的功能模块。如果能将 IO 密集型和 CPU 密集型的模块拆分成不同的服务，分开部署到更合适的硬件上，将可以节省大量的机器成本。比如 IO密集型的模块，我们可以部署在 CPU 性能相对较低的机器上。\n\n不同的保障级别\n不同业务等级的保障级别也是不一样的：对于账号模块等核心模块，必须确保资源充足；但是对于非核心模块，保障的资源可以相对少一些。而对于一个单体服务来说，是没有办法对不同的模块实施不同的保障级别的。\n\n\n\n研发效率\n研发效率是我们能够高效、舒心工作的基本保障，所以必须要注意单体服务模式导致的串行的编译、测试和发布，以及研发团队只能选择单一的研发语言和生态（一般在进程内跨语言都会有限制）这两个限制。\n\n串行的编译、测试和发布\n多个研发团队会同时开发不同的功能，由于是单体服务，这些功能只能一起编译、测试和发布，非常浪费时间。如果还要进行灰度发布，那么效率将会更低。\n\n单一的语言和生态限制\n不同的业务需求可能会对应不同的编程语言和生态。如果是单体服务，则很难按业务需求来选择编程语言和相关的生态，这会大大影响研发效率。\n\n单体服务引发的稳定性问题\n局部风险会放大到全局，\n业务迭代周期差异大\n\n\n\n\n上面三个方面的本质问题，都是因为我们的业务是一个单体应用，不能按资源类型进行分别扩容，不能按功能或者服务进行小范围的部署，也不能按业务的需求来选择更适合的研发语言和生态等，所以我们决定按资源和业务等维度对单体服务进行拆分。\n\n\n\n服务注册发现的业务场景\n如果服务 A 需要调用服务 B，那么服务 A 怎么获取被调用服务 B 的 IP 和 Port 呢？这个其实就是服务注册发现的业务场景\n\n\n\n服务注册发现的关键问题是什么\n我们可以将配置 IP 和 Port 列表的方式修改为配置域名和 Port\n\n\n\n\n统一的中介存储：调用方在唯一的地方获得被调用服务的所有实例的信息。\n状态更新与通知：服务实例的信息能够及时更新并且通知到服务调用方\n\n\n\n怎么实现服务注册发现如何选择适合的中介存储\n可用性要求非常高：因为服务注册发现是整个分布式系统的基石，如果它出现问题，整个分布式系统将不可用。\n性能要求中等：只要设计得当，整体的性能要求还是可控的，不过需要注意的是性能要求会随分布式系统的实例数量变多而提高\n数据容量要求低：因为主要是存储实例的 IP 和 Port 等元数据，单个实例存储的数据量非常小。\nAPI 友好程度：是否能很好支持服务注册发现场景的“发布 / 订阅”模式，将被调用服务实例的 IP 和 Port 信息同步给调用方。\n\n\n\n\n常见存储系统比较：\n\n\n\n\n\n\n如果你希望在系统出现网络分区的时候，调用方一定不能获取过期的被调用服务实例信息，那么就选择 etcd 和 ZooKeeper\n如果你认为获取过期的实例信息，可能比完全不能获取被调用服务的实例信息要好，那么就选择 Eureka\n\n\n\n怎么做服务状态的更新与通知\n\n\n\n选择 AP 还是 CP\n从服务注册发现的场景来说，我认为 Eureka 之类的 AP 系统更符合要求。因为服务发现是整个分布式系统的基石，所以可用性是最关键的设计目标。\n\n因为服务发现是整个分布式系统的基石，所以可用性是最关键的设计目标。并且上面介绍的服务，在同步自己的状态到中介存储，以及调用方通过中介存储区获得服务的状态，这两个过程中的数据同步都是最终一致性的。既然服务注册发现系统整体是一个 AP系统，那么将中介存储设计为 CP 系统，去放弃部分的可用性是不值得的。\n\n\n\n当我们去研究各种各样服务发现的实现方式时，就会发现其实它们都是在解决“如何选择适合的中介存储”和“怎么做服务状态的更新与通知”的问题。当然由于服务发现是非常基础和重要的功能，所以其中的各种实现都是在高性能、高可用性的基础上解决上面的两个问题，做着各自的优化与权衡。\n\n\n\n小结\n在服务发现的场景里面，高可用性是最应该去考虑的设计指标，所以选择 AP系统做中介存储是一个不错的选择。\n\n\n\n\n\n\n\n\n\n05｜负载均衡：从状态的角度重新思考负载均衡\n每一个被调用服务都会有多个实例，那么服务的调用方应该将请求，发向被调用服务的哪一个服务实例，这就是负载均衡的业务场景。\n\n\n\n负载均衡的关键点负载均衡需要达到的目的是“确保能高效、正确地提供服务”，同时从这个目的中，我们还可以分析出负载均衡的两个关键点。\n\n公平性：负载均衡需要考虑到各个实例性能差异的情况，让每一个实例都能充分发挥它的能力\n正确性：对于有状态的服务来说，负载均衡需要关心请求的状态，将请求调度到能处理它的后端实例上，不要出现不能处理和错误处理的情况\n\n\n在这些不同的业务场景中，我认为对负载均衡策略的设计，影响最大的因素是后端实例是否存在状态，后端实例有状态，负载均衡就需要关心请求的状态\n\n\n\n负载均衡策略轮询\n轮询的负载均衡策略非常简单，只需要将请求按顺序分配给多个实例，不用再做其他的处理。\n轮询在路由时，不利用请求的状态信息，属于无状态的负载均衡策略，所以它不能用于有状态实例的负载均衡器\n因为轮询策略只是按顺序分配请求，所以适用于请求的工作负载和实例的处理能力差异都较小的情况。\n\n\n\n权重轮询\n将每一个后端实例分配一个权重，分配请求的数量和实例的权重成正比轮询。\n权重轮询在路由时，不利用请求的状态信息，属于无状态的负载均衡策略，所以它也不能用于有状态实例的负载均衡器\n因为权重策略会按实例的权重比例来分配请求数，所以，我们可以利用它解决实例的处理能力差异的问题，认为它的公平性比轮询策略要好。\n\n\n\nHash\n将请求的状态信息，按一定的 Hash 算法固定分配到一个实例上\nHash 负载均衡策略，在机器实例数量发生变化的时候，几乎所有请求的分配实例都会发送变化。如果后端实例依赖 Hash 负载均衡策略来保证正确性，那么当实例数发生变化的时候，正确性将会出现问题。\n在不考虑 Hash 算法均匀性的情况下，Hash 策略会按 Hash 值按模等分，它和轮询策略类似，不能解决请求的工作负载和实例的处理能力差异的问题\n\n\n\n一致性 Hash\nHash 的负载均衡策略中，最大的一个问题是基于机器数量求模，如果机器数量发生变化，请求和实例的分配关系机会将全部变化，这会影响它的正确性，而一致性 Hash 就可以用来解决这个问题\n\n\n\n\n\n\n一致性 Hash 和 Hash 策略最大的区别在于，一致性 Hash 是对固定值 求模，不会随着机器数量的变化而变化，所以对于同一个 Request ID ， iRequest 是始终稳定不变的，这样就解决了 Hash 的策略在实例数量发送变化后，几乎所有的分配关系都会发生变化的问题。\n\n一致性 Hash 策略公平性的问题：一致性 Hash 是通过增加虚拟节点的方法来解决。在 Hash 环中路由到虚拟实例的请求，会被路由到它的真实实例上\n\n对于实例数过少导致的公平性问题：一致性 Hash 策略让每一个实例都生成多个虚拟实例，使分配更加均衡\n\n对于实例之间性能差异的问题：一致性 Hash 策略通过让实例生成虚拟实例的数量，与该实例的权重成正比的策略来解决\n\n\n\n\n无状态的负载均衡\n无状态的负载均衡指的是参与负载均衡的后端实例是无状态的，所有的后端实例都是对等的，一个请求不论发向哪一个实例，都会得到相同的并且正确的处理结果，以无状态的负载均衡策略不需要关心请求的状态。\n无状态的负载均衡策略有：\n轮询\n权重轮询\nFAIR \n随机\n权重随机\n最少链接数\n……\n\n\n\n\n\n半状态的负载均衡\n虽然负载均衡策略利用请求的状态信息进行路由，但是仅仅进行简单的规则处理，比如 Hash 运算加求模来路由请求，它不保证路由的正确性，这个正确性由后端实例来保证。\n\n\n一些实例会在内存中缓存一些状态数据，用于提升系统的性能，如果一个请求被路由到错误的实例中，该实例可以立即通过中心存储，读取出所需要的数据，然后在内存中重建并缓存正确的处理请求，不会导致请求出现错误。\n\n\n半状态的负载均衡将请求按一定的策略进行路由，后端实例可以利用路由规则来进行优化。\n\n\n\n全状态的负载均衡\n负载均衡策略不仅利用请求的状态信息进行路由，并且在后端实例有状态的情况下，依然会保证路由的正确性。\n\n全状态的负载均衡一般以路由服务的形式存在，在路由服务里面，都会存储后端实例 ID 和状态信息的索引，在进行请求路由的时候，路由服务从请求的状态信息中获得索引的标识，通过查询索引获得后端实例的 ID，然后再进行路由。\n\n全状态的负载均衡和数据分片是同一件事情\n\n\n\n\n\n\n\n\n06｜配置中心：如何确保配置的强一致性呢？\n\n\n\n\n\n07｜分布式锁：所有的分布式锁都是错误的？\n多个实例在同一时刻只能有一个实例运行，它就是一个典型的分布式锁的场景\n\n\n\n为什么需要分布式锁\n锁的定义：锁是操作系统的基本原语，它是用于并发控制的，能够确保在多 CPU 、多个线程的环境中，某一个时间点上，只能有一个线程进入临界区代码，从而保证临界区中操作数据的一致性。\n分布式锁：锁控制的对象从一个进程内部的多个线程，变成了分布式场景下的多个进程，同时，临界区的资源也从进程内多个线程共享的资源，变成了分布式系统内部共享的中心存储上的资源。锁的定义在本质上没有任何的改变，只有持有锁的线程或进程才能执行临界区的代码。\n\n\n\n怎么实现分布式锁\n锁的三个不同的层次：\n进程内部的锁\n同一台机器上的多进程之间的锁（直接通过操作系统的锁来实现）\n跨进程、跨机器之间的分布式锁（通过一个状态来表示加锁和解锁，只不过要让所有需要锁的服务，都能访问到状态存放的位置）（将锁的状态信息存放在一个存储服务，即锁服务中，其他的服务再通过网络去访问锁服务来修改状态信息，最后进行加锁和解锁。）\n\n\n实现完备的分布式锁需要满足的特性：\n互斥：保证不同节点、不同线程的互斥访问\n超时机制：超时设置，防止死锁，分布式锁才有这个特性\n锁服务和请求锁的服务分散在不同的机器上面，它们之间是通过网络来通信的，所以我们需要用超时机制，来避免获得锁的节点故障或者网络异常，导致它持有的锁不能归还，出现死锁的情况。\n持有锁的节点需要处理的临界区代码非常耗时：可以通过另一个线程或者协程不断延长超时时间，避免出现锁操作还没有处理完，锁就被释放，之后其他的节点再获得锁，导致锁的互斥失败这种情况\n我们可以在每一次成功获得锁的时候，为锁设置一个超时时间，获得锁的节点与锁服务保持心跳，锁服务每一次收到心跳，就延长锁的超时时间\n\n\n完备的锁接口：阻塞接口 Lock 和非阻塞接口 tryLock。\n阻塞 Lock 接口获取锁：如果当前锁已经被其他节点获得了，锁服务将获取锁的请求挂起，直到获得锁为止，才响应获取锁的请求\n通过 tryLock 接口获取锁：如果当前锁已经被其他节点获得了，锁服务直接返回失败，不会挂起当前锁的请求。\n\n\n可重入性：一个节点的一个线程已经获取了锁，那么该节点持有锁的这个线程可以再次成功获取锁\n只需在锁服务处理加锁请求的时候，记录好当前获取锁的节点 + 线程组合的唯一标识，然后在后续的加锁请求时，如果当前请求的节点 + 线程的唯一标识和当前持有锁的相同，那么就直接返回加锁成功，如果不相同，则按正常加锁流程处理。\n\n\n公平性：\n对于被阻塞的加锁请求，我们只要先记录好它们的顺序，在锁被释放后，按顺序颁发就可以了。\n\n\n\n\n\n\n\n分布式锁的挑战\n在分布式系统中，由于部分失败和异步网络的问题，分布式锁会面临正确性、高可用和高性能这三点的权衡问题的挑战。\n\n\n\n分布式锁的正确性\n不论出现怎样的异常情况，都能保证分布式锁互斥语义的正确性呢\n因为整体失败和同步通信这两点，我们可以保证进程内的锁有绝对的正确性。\n\n\n\n\n\n\n对于在共享存储中写入数据等等，完全不能容忍分布式锁互斥语义失败的情况，不应该借助分布式锁从外部来实现，而是应该在共享存储内部来解决。比如，在数据库的实现中，隔离性就是专门来解决这个问题的。分布式锁的设计，应该多关注高可用与性能，以及怎么提高正确性，而不是追求绝对的正确性。\n\n\n\n分布式锁的权衡\n在分布式锁的场景下，没有办法保证100% 的正确性\n我们要避免通过外部分布式锁，来保证需要 100% 正确性的场景。将分布式锁定位为，可以容忍非常小概率互斥语义失效场景下的锁服务\n一般来说，一个分布式锁服务，它的正确性要求越高，性能可能就会越低。\n分布式锁是一个非常底层的服务组件，是整个分布式系统的基石之一\n一般来说，我们可以在成本可接受的范围内，提供性能最好的分布式锁服务\n可用性是设计分布式锁服务非常关键的一个目标\n\n\n\n\n\n\n\n08｜重试幂等：让程序 Exactly-once 很难吗？\n在请求的响应结果为“请求超时”的时候，我们不知道这个请求是否已经被远端的服务执行了。进一步来说就是请求的消息，是否精确一次发送到远端服务的问题，即 Exactly-once。\n\n\n\n为什么不能保证 Exactly-once\n在单机系统中，模块之间的通信都是进程内的本地函数调用，在这个整体失败和同步通信的模型中，要么进程整体崩溃，要么调用完成，不会存在其他的情况\n\n在分布式系统中，程序不能保证 Exactly-once 的原因主要有以下两个：\n\n\n\n\n网络\n在分布式系统中，服务和服务之间都是通过网络来进行通信的，而这个网络是一个异步网络。\n通过超时机制来快速获得一个结果，将无界时延的异步网络模型，通过超时机制转化成了有界时延\n\n\n\n远端服务发生了故障\n当请求方收到“请求超时”的时候，我们无法判断远端服务是否处理过这个请求\n\n\n\n如何保证 Exactly-once\n现消息的 Exactly-once 传递，主要有三种方式：\n\n至少一次消息传递加消息幂等性\n请求重试+接口幂等\n\n分布式快照加状态回滚\n分布式快照加状态回滚：在整个分布式系统运行的过程中，定期对整个系统的状态做快照，在系统运行时，不论系统的哪个地方出现故障，就将整个系统回滚到上一个快照状态，然后再重放上一个快照状态之后的情况，直到所有的消息都被正常处理\n\n分布式快照加状态回滚的方式并不适合在线业务的情况：\n\n要对在线业务的所有状态做快照是非常难的一件事情，因为在线业务的状态一般都是在数据库中，如果要对整个系统的数据库都定期做快照，这将消耗非常大的资源。\n在通过快照进行状态回滚的时候，整个系统不能处理当前的业务请求，当前的业务请求需要进行排队等待，等系统通过快照将状态回滚完，并且重放了上一个快照状态之后的所有请求，才能开始正常处理当前业务。这个过程可能很长，这对于在线业务系统是不能接受的。\n\n\n分布式快照加状态回滚的方式，一般不会应用于在线业务架构中，它的主要应用场景是例如 Flink 之类的流式计算。在流式计算中，系统状态的存储也是系统设计的一部分，我们可以在系统设计的时候，就考虑支持快照和回滚功能。并且，在流式计算中，消息来源一般都是 Kafka 之类的消息系统，这样对消息进行重放就非常方便了。\n\n\n整体重做\n在执行任务的过程中，如果系统出现故障，就将整个任务的状态删除，然后再进行重做。整体重做的方案，一般的使用场景为批处理任务的情况，比如 MapReduce 之类的批处理计算引擎。\n\n\n\nExactly-once 的挑战\n分布式在线业务架构系统中，对于解决 Exactly-once 问题，常用的“最少一次消息传递加消息幂等性机制”面临的挑战\n\n重试面临的挑战\n在执行重试策略的过程中，我们要避免重试导致的系统雪崩的问题。\n在系统快要接近性能瓶颈的时候，某些节点可能会因为负载过高而响应超时，如果这个时候再无限制地重试，就会进一步放大系统的请求量，将一个局部节点的性能问题，放大到整个系统，造成雪崩效应。\n重试策略都会有两个限制\n限制重试的次数\n控制重试的间隔，一般采取指数退避的策略\n\n\n\n幂等面临的挑战\n首先，我们要讨论能否通过对操作进行改写，将一个非幂等操作变成一个幂等操作\n然后，我们再讨论如何将一个非幂等操作变成一个幂等操作\n最后，我们讨论在有外部系统的情况下，如何保证请求的幂等性。\n\n\n\n操作的幂等性讨论如何确保操作的幂等性\n请求中增加唯一 ID ，然后在处理请求时，通过ID 进行去重，确保对相同 ID 的请求只处理一次。将请求处理结果写入数据库的操作，以及标记请求已处理的操作，它们都必须在同一个事务中。让事务来保证这两个操作的原子性\n\n\n\n外部系统的幂等性保障\n如果我们请求的操作会影响到外部系统的状态，要保证请求的幂等性是需要依赖外部系统的支持才能实现的。\n\n\n\n\n\n\n\n09 | 雪崩（一）：熔断，让故障自适应地恢复\n分布式系统中的雪崩场景：在一个分布式系统中，局部故障是不可避免的，但是如果不能将局部故障控制好，导致其演变成一个全局的系统故障，这对我们来说是不可以接受的\n\n为什么会出现雪崩\n雪崩是由于局部故障被正反馈循环，从而导致的不断放大的连锁故障。\n雪崩通常是由于整个系统中，一个很小的部分出现故障，进而导致系统其他部分也出现故障而引发的。\n\n\n实际工作中，出现雪崩一般会经历以下三个阶段\n服务的处理能力开始出现过载\n服务过载是指服务器只能处理一定 QPS 的请求，当发往该服务器的 QPS 超出后，由于资源不够等原因，会出现超时、内存增加等各种异常情况，使服务的请求处理能力进一步降低，过载情况更加严重。\n服务处理能力出现过载有多种原因，比如服务可能由于 Bug 导致性能下降，或者由于崩溃导致过载，也有可能就是突发的流量超过了服务的设计目标，或者是机器宕机导致可提供服务的实例数量减少等原因。\n\n\n服务由于资源耗尽而不可用\n当服务严重过载后，会出现大量请求的积压，这会导致服务消耗更多的内存、 CPU 、线程和文件描述符等资源，待这些资源被消耗尽后，服务将出现严重超时和崩溃等异常情况，最终对外表现为不可用。当服务的某一个实例崩溃后，负载均衡器会将请求发送给其他的实例，导致其他的实例也出现过载的情况，从而造成整个服务过载的故障。\n\n\n由于服务内部出现严重的过载，导致响应严重超时，服务的调用方同样会出现大量请求的积压使资源耗尽，这样正反馈循环就形成了，故障沿着调用链路逆向传播，导致整个系统出现雪崩。\n\n\n\n\n雪崩的根本原因是系统过载，如果在系统过载的情况下，不进行任何控制，异常情况就会急剧扩散，导致雪崩情况出现。所以，想要避免系统雪崩，要么通过快速减少系统负载，即熔断、降级、限流等快速失败和降级机制；要么通过快速增加系统的服务能力来避免雪崩的发生，即弹性扩容机制。\n\n利用熔断机制避免雪崩\n我们将服务由于过载原因导致的错误比例，作为熔断器断开的阈值，当被调用服务出现过载的时候，熔断器通过错误比例感知到被调用服务过载后，就立即将调用请求返回错误，这样可以减少被调用服务的请求数量，也可以减少调用服务由于等待请求响应而积压的请求，完美切断了正反馈循环，确保了雪崩不会发生\n在熔断机制的模式下，服务调用方需要为每一个调用对象，可以是服务、实例和接口，维护一个状态机，在这个状态机中有三种状态。\n\n\n\n\n\n\n闭合状态 ( Closed )。\n在这种状态下，我们需要一个计数器来记录调用失败的次数和总的请求次数，如果在一个时间窗口内，请求的特定错误码的比例达到预设的阈值，就切换到断开状态。\n\n\n断开状态 ( Open )\n在该状态下，发起请求时会立即返回错误，也可以返回一个降级的结果，我们会在后面的课程“降级”中再详细讨论。在断开状态下，会启动一个超时计时器，当计时器超时后，状态切换到半打开状态。\n\n\n半打开状态 ( Half-Open )\n在该状态下，允许应用程序将一定数量的请求发往被调用服务，如果这些调用正常，那么就可以认为被调用服务已经恢复正常，此时熔断器切换到闭合状态，同时需要重置计数。如果这部分仍有调用失败的情况，我们就认为被调用方仍然没有恢复，熔断器会切换到断开状态，然后重置计数器。所以半打开状态能够有效防止正在恢复中的服务，被突然出现的大量请求再次打垮的情况\n\n\n\n熔断机制的关键点\n在熔断机制的具体实现上，还会面临熔断的粒度选择和过载判断等关键的问题\n\n粒度控制\n我们想将监控资源过载的粒度控制在一个什么样的范围内，这个范围可以由服务、实例和接口这三个维度的组合来得到\n\n\n\n\n\n\n更建议你选择“实例的接口”这个熔断粒\n熔断的敏感度高\n熔断的误伤范围小\n设计优良的熔断机制所消耗的资源是非常少的，“实例的接口”粒度的熔断机制所消耗的资源，完全在系统可以承受的范围之内\n\n\n\n错误类型\n系统被动对外表现出来的过载错误\n系统主动对外表现出来的过载错误\n\n过载与存活的区别\n过载更关心服务当前的状态好不好，而存活只关心服务是否能活着，这是一个更低的要求\n在熔断场景中，我们对服务的过载判断进行了简化，直接通过服务接口请求的结果来进行判断。我们执行这个接口的逻辑，如果请求发生错误，并且错误为超时或者限流等错误的比例超过一定的阈值时，我们可以认为该接口是过载的，然后进行熔断。\n\n熔断与重试的关系\n重试是指在一个请求失败后，如果我们认为这次请求失败是因为系统的临时错误导致的，那么为了提高系统的可用性，我们会重新发起请求。\n\n而熔断则认为当前系统的这一个接口已经出现过载的情况，为了确保系统不会出现雪崩，而对当前接口的请求进行快速失败，直接返回失败，而不是真正地发起请求，以此来减少系统当前的过载情况。\n\n我们可以认为熔断和重试是两个层面的操作，它们之间是相互独立的，不需要相互干扰。\n\n\n\n我们在需要重试的业务场景中进行重试操作，来提高系统的可用性，而熔断一般会内置到系统的框架中，并且默认开启，作为系统稳定性的最后一道保险丝，来确保系统不会因为过载而雪崩。至于因为熔断被迫进行快速失败的这个请求，它是首次的还是重试的请求，我们并不关心。\n\n熔断机制的适应范围\n只要是过载问题的场景，我们都可以考虑利用熔断机制来解决，不论是分布式系统中服务之间的调用，还是服务与数据库之间等其他场景的调用。\n\n\n熔断机制的五个关键点总结\n\n\n\n\n\n10 | 雪崩（二）：限流，抛弃超过设计容量的请求为什么需要限流\n熔断的处理方式不够优雅\n熔断机制是被动感知故障，等系统出现故障后，才会介入处理。这样的处理方式会让系统产生不必要的抖动\n\n\n熔断机制是最后底线\n在其他方法用尽之后，如果过载问题依旧存在，这时熔断才会被动触发\n\n\n在快速失败的时候，需要能考虑调用方的重要程度\n熔断是调用方依据响应结果自适应来触发的，在被调用方出现过载的时候，所有的调用方都将受到影响\n\n\n在多租户的情况下，不能让一个租户的问题影响到其他的租户\n我们需要对每一个租户分配一定的配额，谁超过了就对谁进行限流，保证租户之间的隔离性。\n\n\n\n如何实现限流\n限流机制是熔断等其他机制无法替代的，是必须的\n\n限流算法\n限流算法是限流机制的基础和核心，并且后续关于限流机制的讨论，都会涉及相关的限流算法\n\n固定窗口和滑动窗口\n固定窗口就是定义一个“固定”的统计周期，比如 10 秒、30 秒或者 1 分钟，然后在每个周期里，统计当前周期中被接收到的请求数量，经过计数器累加后，如果超过设定的阈值就触发限流，直到进入下一个周期后，计数器清零，流量接收再恢复正常状态\n\n滑动窗口就是固定窗口的优化，它对固定窗口做了进一步切分，将统计周期的粒度切分得更细，比如 1 分钟的固定窗口，切分为 60 个 1 秒的滑动窗口，然后统计的时间范围随着时间的推移同步后移\n\n滑动窗口和固定窗口一样面临抗抖动性差的问题，“漏桶”算法可以进一步改进它们的问题。\n\n\n漏桶和令牌桶\n令牌桶算法的核心是固定“进口”速率，限流器在一个一定容量的桶内，按照一定的速率放入 Token ，然后在处理程序去处理请求的时候，需要拿到 Token才能处理；如果拿不到，就进行限流。\n令牌桶”算法相对于“漏桶”，虽然提高了系统的资源利用率，但是却放弃了一定的流量整形能力，也就是当请求流量突增的时候，上游流量的抖动可能会扩散到下游服务。\n\n\n\n\n\n单节点限流\n限流机制作用的位置是客户端还是服务端，即选择客户端限流还是服务端限流\n如果触发限流后，我们应该直接抛弃请求还是阻塞等待，即否决式限流和阻塞式限流\n\n分布式限流\n进行集中式限流\n将分布式限流进行本地化处理\n\n限流机制的关键问题\n如何确定限流的阈值\n限流可能会引入脆弱性\n\n\n在核心链路和核心服务上，默认启用限流机制，在其他位置上，手动启用限流机制，把它作为处理系统故障的一个手段\n\n11｜雪崩（三）：降级，无奈的丢车保帅之举\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["distributed"],"tags":["distributed"]},{"title":"《面试现场》Study Notes","url":"/%E3%80%8A%E9%9D%A2%E8%AF%95%E7%8E%B0%E5%9C%BA%E3%80%8BStudy-Notes/","content":"开篇词 (1讲)开篇词 | 面试，这样做会功到自然成\n优点发挥得足够强，就可以弥补缺点，除非舞台不合适\n\n面试官需要关注的，应该是应聘者的优点。缺点每个人都有，但是要把工作做好的话，首先凭的是优点。如果优点能发挥到位，缺点能够被其他的因素补足，那这个人就是合适的。\n\n\n面试的核心，对于应聘者，是想方设法让面试官认可自己对职位有用的那些优点。\n\n用真诚的态度，有效地表达自己的能力和价值，建立相互的信任和认可。\n\n\n\n缺少发掘和表达自己能力的能力。\n\n\n竖一面放大镜，带你看清自己的能力结构（而不仅仅只是关注技术层面），明白培养这些能力的关键因素，并且启发你在自身经历中寻找反映这些能力的素材和故事。\n\n\n搭一座桥，一座在面试官和求职者中间，让沟通更直接、更到位的桥。让你能够分析面试问题的意图，用有价值、有亮点的经历或观点去回答，让面试官轻而易举地看出你的能力和价值。\n\n\n在“知彼篇”里，让应聘者明白面试官眼里的人才素质模型，这相当于面试的“考点大纲”；介绍公司整个招聘过程，带你了解面试中考查能力的一般方法，让你更容易理解面试官的意图。\n在“知己篇”里，带你搞清楚什么是工作中决定个人发展的关键因素，进而明确自己该不该换工作；另一方面，明确自己的职业愿景和规划。准备一份详历，挖掘自己的能力、价值和亮点，并浓缩成一份受青睐的简历给面试官看。\n在“问答篇”里，和你分析面试中常见的几类问题，包括如何解释清楚一个技术点，如何体现你在项目中的重要性等等，帮助你回答得更加精准到位。\n在“贯通篇”里，重点分析几种能力：学习能力、精益能力、协作能力、管理和领导能力等等，这些能力都体现为解决问题的能力，目的是让你了解提高这些能力的关键因素，到详历中寻找合适的事例，全面精准地把你真实的能力水平展现给面试官。\n在“综合篇”里，盘点面试官和应聘者的认知偏差，强调双向选择中，帮你明确该如何衡量新团队和新环境，如何处理和老东家的关系，以及从面试中学习，为长远的发展提供动力。\n\n\n一个优秀的人，其职业发展的终极目标，是把自己变得更优秀\n借着面试这个场景，和你聊聊一个优秀的人应该如何规划自己的职业。我希望这个专栏能让你更了解面试、更了解工作、更了解自己，并在自己的职业成熟度上有所启发，走出一条不同寻常的路。\n\n\n\n\n\n\n\n基础：知彼篇 (3讲)01 | 公司到底想要什么样的人？\n公司到底想要什么样的人，面试到底在面什么?\n要想提高自己通过面试的几率，你必须明确面试的内容范围和要求\n\n公司眼中的好员工\n工作结果\n\n个人工作结果质量好，价值高\n赋能别人做出成果\n\n\n看过程\n\n对工作内容、环境因素带来的工作复杂度的衡量，也体现了对个人的技能、态度的衡量\n\n\n面试官还要进一步看应聘者的行为是否可以被预测\n\n信任感使你能预测对方将来的行为\n\n\n应聘者的素质模型\n\n\n\n1. 经验（Experience）\n经验是指工作经历的对象和产出，体现为专业相关的知识和思维结构（Idea），用来指导思考和行为。\n\n2. 技能（Skill）\n技能是做事的能力，体现一个人的专业性。\n产生 idea 的技能：针对问题，基于经验，收集、理解、分析和制定新的方案（idea），涉及理解、思考、沟通等过程。\n执行 idea 的技能：运用工具，把方案（idea）应用到实践，从而解决问题。除了用到理解、思考、沟通，还需要协作团队、管理资源，甚至领导和影响他人。\n\n3. 潜力（Potential）\n增长经验和技能的能力\n学习：从不会到会，掌握一项技能的过程\n创新：针对特定场景创造新事物的技能\n精益：把事情越做越好的技能\n\n\n如果你承认潜力，那么就说明你有成长型思维，有成长思维的人认为：技能是可以通过努力获得的，关键是要保持好奇心，平时爱思考、总结、尝试，愿意接受挑战，不怕错误和失败。因此，要在潜力上为自己的面试效果加分，你就需要注意如何在言谈及简历描述中体现这些特质。\n\n4. 动机（Motivation）\n做事情的内心目标、意愿和态度\n自燃型，也就是自我驱动的员工，他们做事动机强烈，目标明确，明白任务的意义，甚至自己寻找有意义的事，满怀激情地投入，往往超出自己的工作范围，去推动进展，取得成果，然后又奔向下一个目标。\n点燃型，这类员工需要一定的激励，需要他人帮助才能找到目标和意义，一旦“激活”就能像自燃型员工一样奋力工作。\n阻燃型，这类员工当一天和尚撞一天钟，给多少钱，干多少活，按工作的最低标准和最后完成时间递交任务，跟同事合作差，不乐意分享，自我保护。\n\n\n人格品质，比如诚实守信、认真负责、坚毅勇敢等。这些从底层决定我们的做事动机。\n职业价值观，就是在工作中区分是非、明确轻重的观念。比如，有人喜欢轻松安稳的工作，有人喜欢冒险和竞争；有人喜欢照章办事，有人则喜欢灵活自主；有人追求个人利益，有人则喜欢分享和帮助他人。\n职业性格，是长久的思维和行为习惯，受环境影响固化成的心态“定势”\n\n总结\n公司到底想要什么样的人呢？我们从应聘者素质模型可以看出：\n\n动机方面，公司更想要人品好，职业价值观和团队文化一致，职业性格和职位匹配的候选人；\n潜力方面，公司更想要学习、创新和精益能力好的候选人；\n技能和经验方面，公司想要和职位需求匹配的，如果你资历过剩，就要看公司发展需要了，如果你资历不够，那就要看你的潜力和动机了。\n\n\n借助素质模型，对职位描述的理解，理解以下两点：\n\n了解面试官考查的各项内容和期待，做到“知彼”，不打无准备的仗；\n从个人经历中挖掘素材，突出契合职位需要的内容，以满足面试官的预期。\n\n\n搞清楚面试官的考查要素之后，在提高和表现这些能力上受到一些启发，有的放矢地把自己呈现给面试官。\n\n\n\n\n\n\n\n\n02 | 想要成功面试，先要弄懂面试过程\n需要清楚招聘过程，知道各个环节背后：有什么人在主导，目的是什么，要注意什么，该做什么，不该做什么，以及有什么风险\n\n从一个招聘职位出现，到招聘结束，需要清楚整个过程发生了什么？需要注意什么？以面试官的视角，增加认知，充分准备，减少失误，为面试效果加分\n\n\n看懂招聘全流程，不打无准备之仗1. 确定职位空缺，提前预知工作的难度\n填补空缺：因为有前任的工作样板，工作细节清楚、职责明确，确定性高，老板对这个职位的期待也很明确，双方都可以清楚地评价人和工作的匹配度。而且，应聘者完全可以复用前任的经验轻松上手，但是因为有前任的对比，需要超越前任的表现才能获得好评。\n新增职位：工作难度和职责细节往往还不清晰，在团队中还没有和其他职位形成稳定的职责接口，甚至老板对这个职位的期待可能还说不清，新人做起工作来，需要很多的探索和磨合，较难上手。但是因为没有对比，你比较容易校正老板的期待，也容易获得好评。\n\n2. 了解简历收集渠道和筛选过程，有的放矢\n内推\n公司网站\n社交平台\n招聘网站\n线下招聘会\n猎头公司\n\n\n投递简历的注意事项\n简历邮件标题至少要写清应聘职位、姓名\n简历附件尽量用 PDF 格式，保证跨平台阅读的一致性\n用一些稍正式的个人邮箱地址投递简历\n\n\n\n\n不要给自己设限，你认为的，并不一定面试官也这么认为。\n\n3. 面试，是谁决定了你的去留\n谁来决定一个应聘者面试通过与否？\n面试官可能来源于三类角色：HR、部门大牛、部门经理\nhr：重点考查人才的基本面：动机（价值观、职业性格）和潜力\n部门大牛：最清楚工作细节，关注应聘者在这些细节上的经验和技能，也就是解决问题的能力\n部门经理：两方面兼顾，既要保证此人能胜任岗位（或者通过学习能够很快胜任），还要验证他的动机和潜力，确保他能认可公司文化，融入团队，保持稳定长远的发展。\n\n\n部门经理对自己的职位人选负责。在评价应聘者的面试表现时，他会听取 HR 和部门大牛的反馈，结合自己的体会，做出以下几种决定：\n录用\n不录用：不适合本职位（不排除推荐给其他匹配的职位）。\n候选，留待与后面的人作比较：不是非常理想的人选，需要再看看后面有没有更合适的（如果时间允许的话）\n再面试一次：没看清，拿不准。这往往是因为面试中应聘者没能充分表达自己的能力所致\n\n\n\n\n最终，高级经理可能做最后一轮面试，以便确定你确实是符合团队需要的人员。在这一轮对话中，你会得到更多关于公司和团队的信息，这时我建议你多问多了解，以便能够更好地判断这个职位是否满足你的预期，是否符合你的职业发展规划，甚至为你判断是否要加入这个公司提供信息支持。\n\n\n作为应聘者，在面试阶段你的任务就是，充分展示与职位相关的、能力素质模型的要素，同时了解公司团队，建立互信。\n\n4. 签 Offer，定薪水\n这个阶段不能闭口不提薪水\nHR 负责提供公司级别的薪水标准范围，如果部门经理的薪水诉求超过了薪水范围，会被交给上一管理层审批\n\n5. 入职试用期，你还不能放松警惕\n需要尽快地承担起工作职责，用能力说话，持续建立和加强同团队的信任，推动个人和团队的发展。\n\n总结\nHR 负责快速筛选简历，组织面试，确保为职位快速找到合适的人；\n部门经理才是决定你面试结果的人，也是决定这份 Offer 薪资水平的人\n作为应聘者，你需要了解这些“利益干系人”的关注点，从而有针对性地、最大化地展示你的能力。\n\n\n\n\n\n\n\n03 | 面试官的面试逻辑是什么？\n\n\n\n\n\n基础：知己篇 (8讲)\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["interview"],"tags":["interview"]},{"title":"《高并发 高性能 高可用 MySQL 实战》study notes","url":"/%E3%80%8A%E9%AB%98%E5%B9%B6%E5%8F%91-%E9%AB%98%E6%80%A7%E8%83%BD-%E9%AB%98%E5%8F%AF%E7%94%A8-MySQL-%E5%AE%9E%E6%88%98%E3%80%8Bstudy-notes/","content":"第1章 课程介绍问卷调查\n你真的搞懂MySQL底层原理了吗?\n你知道如何改善慢查询性能吗?\n你知道如何架设高性能集群吗?\n你知道未来数据库的发展趋势吗?\n\n\n\n\n以上，这些问题很重要! 因为\n工作中: MySQL高性能集群越来越流行\n面试中:深入考察MySQL原理、性能调优\n职业规划:需要根据技术发展方向选择职业路径\n\n\n\n\n\n精通MySQL，应该怎么学\n\n以技术原理作为坚实基础\n以真实场景作为学习环境\n以架构思维作为学习目标\n\n\n\n下面三点是课程主线：\n\n\n\n（1）从理论到实战\n从数据表逻辑结构，到优化数据表的性能\n从数据查询原理，到改善慢SQL性能\n从事务原理，到优化事务执行效率\n\n\n\n（2）从单点到集群\n从学习单点原理，到掌握集群原理\n从高性能单点，到高性能集群\n从单点快速部署，到集群快速部署\n\n\n\n（3）从现在到未来\n从5.x版本，到8.0版本\n从原生单体数据库，到原生分布式数据库\n从学习技术原理，到理解技术趋势\n\n\n\n什么是“三高”\n高并发：同时处理的事务数高\n高性能：事务/SQL的执行速度高\n高可用：系统可用时间高\n\n\n\n\n“三高”只是目的，不是手段。手段有：复制、扩展、切换\n\n\n\n复制\n目的:数据冗余\n手段: binlog传送\n收获:并发量提升、可用性提升\n问题:占用更多硬件资源\n\n\n\n扩展\n目的:扩展数据库容量\n手段:数据分片分库、分表\n收获:性能、并发量的提升\n问题:可能降低可用性\n\n\n\n切换\n目的:提高可用性\n手段:主从身份切换\n收获:并发量的提升\n问题:丢失切换时期数据\n\n\n\n“三高”的实现\n高并发:通过复制和拓展，将数据分散至多节点\n高性能:复制提升速度，拓展提升容量\n高可用:节点间身份切换保证随时可用\n\n\n\n\n“三高”的集群也是以单点的高性能作为保障的。学习“三高”之前，应该学习如何提高单点性能\n\n\n\n如何提升单点性能\n建表:表结构合理，索引高效\nB+树的数据结构与InnoDB的存储结构\nInnoDB行记录格式的历史与原理\n索引、数据约束、视图的注意事项\n\n\n查询:优化SQL语句，选择正确索引\n覆盖索引、索引下推、松散索引的原理与实战\n排序、随机选取、COUNT的优化方法\n索引失效时的排查方向\n\n\n更新:正确使用锁，合理优化事务\nMySQL和InnoDB日志体系\n全局锁、表锁、元数据锁、行锁、间隙锁\n死锁的原理与优化方法\n事务与MVCC的原理与性能优化\n\n\n\n\n\n未来数据库发展趋势\nMySQL8.0新特性\nNewSQL数据库\n新一代分布式数据库CockroachDB\n\n\n\n\n\n\n\n第2章 环境搭建\n准备CentOS7环境\n\n\n\n安装MySQL 5.7cd /installwget https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.33-1.el7.x86_64.rpm-bundle.tartar -xvf mysql-5.7.33-1.el7.x86_64.rpm-bundle.tarrpm -qa|grep  mariadbrpm -e --nodeps mariadb-libs-5.5.68-1.el7.x86_64rpm -ivh mysql-community-common-5.7.33-1.el7.x86_64.rpmrpm -ivh --force --nodeps  mysql-community-libs-5.7.33-1.el7.x86_64.rpmrpm -ivh mysql-community-client-5.7.33-1.el7.x86_64.rpmrpm -ivh --force --nodeps  mysql-community-server-5.7.33-1.el7.x86_64.rpmwhich mysql\n\n\n\nMySQL的启停systemctl status mysqld.servicesystemctl start mysqld.servicesystemctl stop mysqld.service\n\n\n\n初始化配置# 查询安装后的初始化密码grep &#x27;temporary password&#x27; /var/log/mysqld.log\n\nset password=password(&quot;Happy2023@&quot;);flush privileges;\n\nset global validate_password_policy=LOW;set global validate_password_length=4;set password=password(&quot;root&quot;);\n\n# 永久打开防火墙3306端口firewall-cmd --zone=public --add-port=3306/tcp --permanentfirewall-cmd --reload\n\nGRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;root&#x27; WITH GRANT OPTION;flush privileges;\n\n\n\n\n\n\n\n第3章 一个SQL语句如何执行\n有了电子表格，为什么还要数据库?\n\n\n\n数据库理论上没有行数上限。单机数据库若行数太多遇到性能问题，可以通过分库分表等技术解决\n数据库有完备的结构化查询语言 (SQL)。Excel结构化查询功能不如数据库强大\n数据库面向软件，提供软件接口。（Excel是文件级别的，直接面向终端用户）\n数据库事务是关系型数据库的核心优势。（Excel没有事务，无法做到不同人的工作同时进行）\n分布式 - 数据库的潜力巨大。数据库具有主备复制、高可用、分布式等形态。Excel天生是单体的，面向文件的\n\n\n\n电子表格面向个人，以文件为基础，拓展性差\n数据库面向软件，支持事务、拓展性好\n\n\n\n数据库软件的典型架构是怎样的?常见软件架构MVC 分层架构\n\n\n\n事件驱动架构\n\n\n\n管道-过滤器架构\n\n\n\n微核架构\n\n\n\nMySQL软件架构是怎样的？\nMySQL的软件架构\n\n\n\n\n\n\n以分层架构看MySQL架构\n\n\n\n\n\n\n以管道过滤器-架构看MySQL架构\n\n\n\n\n\n\n以微核-架构看MySQL架构\n\n\n\n\n\n\n软件工程当中有很多经典的架构设计\n大型软件往往不是使用单一的架构设计，而是多种混合\n研究问题要有清晰的视野，分清楚微观和宏观\n理论要灵活实践，不要死读书\n\n\n\n客户端怎样连接MySQL数据库客户端与MySQL的连接方式\nTCP/IP 连接\nTCP/IP 连接是MySQL在任何平台上都提供的连接方法\nTCP/IP是目前互联网最主流的网络连接方式\n\n\n命名管道\n命名管道:同一台服务器通讯 (Windows)\n命名管道开启方式:–enable-named-pipe\n\n\n共享内存\n服务端:配置-shared-memory\n客户端:配置-protocol=memory\n\n\nUNIX套接字\n服务端:配置-socket=/tmp/mysql.sock\n客户端:配置-S =/tmp/mysql.sock\n\n\n\n\n\nMySQL TCP通讯协议\n三次握手建立TCP连接\n认证连接\n服务端-&gt;客户端:发送握手初始化包\n客户端-&gt;服务端:发送验证\n服务端-&gt;客户端:认证结果消息\n\n\n认证通过之后，客户端开始与服务端之间交互\n客户端-&gt;服务端:发送命令包(Command Packet)\n服务端-&gt;客户端:发送回应包\n\n\n断开MySQL连接\n客户端-&gt;服务器:发送退出命令包\n\n\n四次握手断开TCP连接\n\n\n\n\nMySQL TCP 报文格式\n消息头:3字节报文长度、1字节序号\n消息体:1字节指令、其余为参数\n指令举例: 切换数据库(0x02)、查询命令(0x03)\n\n\n\n\n\n\n\n总结\nTCP/IP 连接是MySQL最常用的连接方式\nTCP/IP连接报文可以作为其他C/S架构的参考\n其他连接方式均限于本机连接，使用范围有限\n\n\n\n一个SQL语句是怎样执行的\n\n\n\n查询缓存\n之前执行过的语句会KV的形式缓存在内存中\n查询之前先查找之前执行过的相同语句\n不推荐使用缓存:数据表修改后，会删除所有相关缓存\n\n\n\n分析器\n分析器的作用是知道你要“干什么“\n先做词法分析，识别SQL语句中的关键字\n再做句法分析，判断SQL语句是否符合语法\n\n\n\n优化器\n优化器的作用是要知道“怎么做”\n优化器的主要工作是决定如何使用索引\n\n\n\n执行器\n执行器的主要工作是校验权限、调用存储引擎\n执行器首先校验此用户对目标数据有无权限\n执行器会以行为粒度，调用存储引擎，执行SQL\n在没有索引的情况下，执行器会循环查询所有行\n\n\n\n存储引擎\n存储引擎的任务是将执行器的指令落实在数据文件上\n不同存储引擎的原理和执行方法有很大不同\n\n\n\n总结\nSQL语句执行的过程涉及到了MySQL几乎所有的模块\n一个SQL语句是按照分析-优化-执行-落盘的步骤执行的\nMySQL8.0之后已经停用了缓存功能\n\n\n\n四种常见的MySQL存储引擎\nInnoDB\nMySQL5.5.5之后的默认存储引擎\n支持事务、外键\n支持崩溃修复能力和并发控制\n\n\nMyISAM\nMySQL 5.5.5之前的默认存储引擎\n插入数据快\n空间利用率高\n不支持事务\n\n\nMemory\n所有的数据都在内存中，速度快\n数据安全性差\n\n\nArchive\n数据压缩、空间利用率高\n插入速度快\n不支持索引，查询性能差\n\n\n\n\n\n总结\nInnoDB是目前最主流的存储引擎，适合各种互联网业务\n查询效率要求非常高的可以考虑MyISAM\n日志信息归档可以考虑Archive\n临时表可以考虑MEMORY\n\n\n\n\n\n\n\n第4章 如何建表更符合业务索引组织表(Index Organized Table)\n索引组织表不是一种“组织表“\n索引组织表是由索引“组织起来的”表\nInnoDB中，表都是根据主键顺序组织存放的\n\n\n\n\n\n\n\n学习备注\n\n大多数情况下，都应该举一反三，比如课程中讲的mysql架构，应该好好熟悉。但是还有呢对应的课程专门讲解mysql架构，所以在本门课程中，我们只需要熟悉最核心的知识，或者熟悉本门课程的知识即可，其它重要的知识点在其它课程中好好学习即可。所以学习其它知识、课程亦是如此。（把握每个课程的重点，各个击破。达到系统掌握整体的目的）\n注意识别课程中提到的知识，哪些是特别重要的，比如本门课程中，常见架构很重要，但是本门课并不专门讲解架构，所以应该后续找对应的课程，学习架构知识。\n课程提到的mysql架构、tcp连接，都是很重要的知识，需要再深入理解。（一些底层基础知识很重要）\n\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["DataBase","MySQL"],"tags":["DataBase","MySQL"]},{"title":"《高级Redis进阶课 解决Redis实际问题+掌握Redis6.x特性》Study Notes","url":"/%E3%80%8A%E9%AB%98%E7%BA%A7Redis%E8%BF%9B%E9%98%B6%E8%AF%BE-%E8%A7%A3%E5%86%B3Redis%E5%AE%9E%E9%99%85%E9%97%AE%E9%A2%98-%E6%8E%8C%E6%8F%A1Redis6-x%E7%89%B9%E6%80%A7%E3%80%8BStudy-Notes/","content":"第1章 课程介绍为何Redis经久不衰？\n功能强大、丰富\n丰富的数据结构、主从、集群、持久化、模块化、哨兵\n能够支撑很多的互联网应用场景，比如缓存、分布式锁队列、集合、GEO.BitMap操作等\n\n\n持续改进\n高性能\n底层C语言编写，内存数据库，通讯采用epoll非阻塞I/O多路复用机制\n\n\n线程安全\n单线程-原子操作（高并发下数据安全）\n\n\n\n课程内容课程项目架构\n\n\n\n以问带学\n\n\n\n底层原理\n网络底层\n事务处理\n持久化原理\n主从复制原理\n哨兵机制\n分片存储原理\n\n\n\n底层算法\nSorted Set底层\nBitmap、Geo算法\n数据过期淘汰算法\nLeader选举流程\n槽位定位算法\n备份迁移及其算法\n\n\n\n性能提升方案\nKey与Value设计规范\n避免BigKey\n避免耗时操作\nPipeline管道操作\n连接池性能优化\n子进程的开销与优化\n\n\n\n故障解决方案\n数据延迟\n数据脏读\n数据抖动\n数据一致性\n热点数据存储\nRDB文件损坏\n\n\n\n怎么学\n对Redis有兴趣，但不懂如何和项目深度结合\n了解Redis日常操作，但不懂得Redis底层原理\n遇到Redis故障完全没有思路，不知如何解决\n\n\n\n\n\n\n\n第2章 Redis快速入门章节介绍[学习目标]1、了解Redis为什么能流行这么多年，高性能的原因2、掌握Redis环境安装以及配置3、了解微服务项目的构建以及SpringBoot开发\n\n\n[理论知识]1、缓存相关中间件 (Redis、 Memcache和Ehcache) 的比较2、对Redis的基本理解3、微服务相关概念\n\n\n[实际操作]1、Redis安装、配置以及启动2、Redis的基本命令3、数据库表结构设计4、SpringBoot&amp;SpringCloud项目搭建\n\n\nRedis介绍特点\n内存数据库，速度快，也支持数据的持久化\nRedis不仅仅支持简单的key-value类型的数据，同时还提供Lists、 Hashes、 Sets 、Sorted Sets 等多种数据结构的存储\nRedis支持数据的备份 (master-slave) 与集群 (分片存储)，以及拥有哨兵监控机制.\n支持事务\n\n\n\n优势\n性能极高 - Redis能读的速度是110000次/s，写的速度是81000次/s\n丰富的数据类型 - Redis支持 Strings、 Lists、 Hashes、Sets 、Sorted Sets 等数据类型操作\n原子操作 - Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行 (事务）\n丰富的特性 - Redis还支持 publish/subscribe,通知,key 过期等特性。\n\n\n\nRedis、Memcached、 Ehcache的区别\n这三个中间件都可以应用于缓存，但目前市面上使用Redis的场景会更多，更广泛，其原因是: Redis性能高、原子操作、支持多种数据类型，主从复制与哨兵监控，持久化操作等。\n\n\n\nRedis的高并发\n官方的bench-mark数据: 测试完成了50个并发执行100000个请求。设置和获取的值是一个256字节字符串。结果: 读的速度是110000次/s,写的速度是81000次/s。redis尽量少写多读，符合缓存的适用要求。单机redis支撑万级，如果10万+可以采用主从复制的模式。\n\n\n\n原理\nRedis是纯内存数据库，所以读取速度快。\nRedis使用的是非阻塞10，10多路复用，减少了线程切换时上下文的切换和竞争\nRedis采用了单线程的模型，保证了每个操作的原子性，也减少了线程的上下文切换和竞争\nRedis存储结构多样化，不同的数据结构对数据存储进行了优化加快读取的速度\nRedis采用自己实现的事件分离器，效率比较高，内部采用非阻塞的执行方式，吞吐能力比较大\n\n\n\nRedis的单线程原因\n不需要各种锁的性能消耗\n单线程多进程集群方案\nCPU消耗\n\n优劣\n单进程单线程优势\n代码更清晰，处理逻辑更简单\n不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗\n不存在多进程或者多线程导致的切换而消耗CPU\n\n\n单进程单线程弊端\n无法发挥多核CPU性能，不过可以通过在单机开多个Redis实例来完善\n\n\n\n\n\nI/O多路复用技术\nredis 采用网络I/O多路复用技术来保证在多连接的时候，系统的高吞吐量。\n\n\n\n版本说明\nRedis2.6\n键的过期时间支持毫秒\n从节点支持只读功能\n\n\nRedis2.8\n可以用bind命令绑定多个IP地址\n发布订阅添加了pub/sub\nRedis Sentinel第二版，相比于Redis2.6的Redis Sentinel，此版本已经变成生产可用\n\n\nRedis3.0 (里程碑)\n Redis最大的改动就是添加Redis的分布式实现Redis cluster。\n\n\nRedis3.2\n添加GEO相关功能。\n新的List编码类型: quicklist。\n\n\nRedis4.0 (重大改版)\n提供了模块系统，方便第三方开发者拓展Redis的功能\n提供了新的缓存剔除算法: LFU (Last Frequently Used)，并对已有算法进行了优化\n提供了非阻塞del和flushall/flushdb功能，有效解决删除了bigkey可能造成的Redis阻塞.\n提供了RDB-AOF混合持久化格式，充分利用了AOF和RDB各自优势。\n\n\nRedis5.0\n新的stream数据类型\n客户经常连接和断开连接时性能更好\n\n\nRedis6.0\n多线程I/O。多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程\n\n\n\n\n\nRedis软件安装下载解压wget -P /usr/local/src/ https://download.redis.io/releases/redis-6.0.9.tar.gzcd /usr/local/src/tar -zxvf redis-6.0.9.tar.gz\n\n\n\n确保环境依赖（升级 GCC）\n在编译 Redis 6 之前需要升级 gc 的版本，默认情况 yum 安装的 gcc 版本是 4.8.5，由于版本过低，在编译时会报如下错误。所以我们需要执行以下操作升级 GCC。\n\n# 安装 Sc1 源yum install -y centos-release-scl scl-utils-build# 安装 9 版本的 gcc、gcc-c++、gdb 工具链 (toolchian)yum install -y devtoolset-9-toolchain# 临时覆盖系统原有的 gcc 引用scl enable devtoolset-9 bash# 查看 gcc 当前版本gcc -v\n\n\n\n预编译cd /usr/local/src/redis-6.0.9/make\n\n\n\n安装mkdir -p /usr/local/redis-6.0.9cd /usr/local/src/redis-6.0.9/make PREFIX=/usr/local/redis-6.0.9 install\n\n\n\n创建软连接cd /usr/local/ln -s redis-6.0.9/ redis\n\n\n\nRedis的启动前台启动cd /usr/local/redisbin/redis-server\n\n\n\n后台启动cp /usr/local/src/redis-6.0.9/redis.conf /usr/local/redis/bin/cd /usr/local/redis/bin/vim redis.conf# 修改以守护进程方式启动daemonize yes# 使用配置文件，后台启动cd /usr/local/redis/bin/./redis-server redis.conf\n\n\n\n配置开机启动 (centos7及以上)# 在系统服务目录里创建redis.service文件vim /etc/systemd/system/redis.service# 写入以下内容:[Unit]Description=redis-serverAfter=network.target[Service]Type=forkingExecStart=/usr/local/redis/bin/redis-server /usr/local/redis/bin/redis.confPrivateTmp=true[Install]WantedBy=multi-user.target# 重载系统服务systemctl daemon-reload# 关闭redis-server: systemctl stop redis.servicesystemctl start redis.servicesystemctl status redis.service# 开启成功，将服务加入开机自启systemctl enable redis.service\n\n\n\nRedis 的配置\ndaemonize默认情况下，redis 不是在后台运行的，如果需要在后台运行，把该项的值更改为 yes\nbind指定 Redis 只接收来自于该IP 地址的请求\nport监听端口，默认为 6379\ndatabases设置数据库的个数，默认使用的数据库是0\nsave设置 Redis 进行数据库镜像的频率\ndbfilename镜像备份文件的文件名\ndir数据库镜像备份的文件放置的路径\nrequirepass设置客户端连接后进行任何其他指定前需要使用的密码\nmaxclients限制同时连接的客户数量\nmaxmemory设置redis 能够使用的最大内存\n\n\n\nRedis 的客户端Windows 客户端\n redis-desktop-manager\n\nRedis 自带的客户端./redis-cli -a redis\n\n\n\nJava 客户端\nRedis的Java客户端也有很多: https://redis,io/clients#java，其中比较受欢迎的是Jedis和Lettuce.\nJedis在实现上是直接连接的redis server，如果在多线程环境下是非线程安全的，这个时候只有使用连接池，为每个Jedis实例增加物理连接，官方推荐。\nLettuce的连接是基于Netty的，连接实例 (StatefulRedisConnection)可以在多个线程间并发访问，因为StatefulRedisConnection是线程安全的，所以一个连接实例 (StatefulRedisConnection) 就可以满足多线程环境下的并发访问，当然这个也是可伸缩的设计，一个连接实例不够的情况也可以按需增加连接实例。\n在SpringBoot Data Redis 1.X之前默认使用的是Jedis，但目前最新版的修改成了Lettuce。\n之前公司使用Jedis居多，Letuce近两年在逐步上升，总的来进Jedis的性能会优于Lettuce (因为它是直接操作Redis)\n\nJedis 直连import org.junit.After;import org.junit.Before;import org.junit.Test;import redis.clients.jedis.Jedis;public class JedisTests &#123;    private Jedis jedis = null;    //建立连接    @Before    public void init() &#123;        // 初始化 Jedis 客户端，声明主机和端口        jedis = new Jedis(&quot;117.50.197.120&quot;,6379);        // 心跳机制检测是否连接成功        jedis.auth(&quot;redis&quot;);        String pong = jedis.ping();        System.out.println(pong);    &#125;    @Test    public void test1()&#123;        // 选择/切换数据库        String select = jedis.select(3);        System.out.println(&quot;select = &quot; + select);        // 插入一条数据        String result = jedis.set(&quot;name&quot;, &quot;MIKE&quot;);        System.out.println(&quot;result = &quot; + result);        // 获取一条数据        String name = jedis.get(&quot;name&quot;);        System.out.println(&quot;name = &quot; + name);    &#125;    //释放资源    @After    public void after() &#123;        if (null != jedis) &#123;            jedis.close();        &#125;    &#125;&#125;\n\n\n\nJedis 连接池import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;import redis.clients.jedis.JedisPoolConfig;public class JedisPoolConnectRedis &#123;    private static JedisPool jedisPool;    static &#123;        // 创建连接池配置对象        JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();        //设置最大连接数，默认 8        jedisPoolConfig.setMaxTotal(5);       // 设置最大空闲数量，默认 8        jedisPoolConfig.setMaxIdle(5);        //设置最少空闲数量，默认 0        jedisPoolConfig.setMinIdle(5);        //设置等待时间ms        jedisPoolConfig.setMaxWaitMillis(100);        //初始化 JedisPool 对象        jedisPool = new JedisPool(jedisPoolConfig,&quot;117.50.197.120&quot;,6379,100,&quot;redis&quot;);    &#125;    /**     * 获取 Jedis 对象     * @return     */    public static Jedis getJedis() &#123;        return jedisPool.getResource();    &#125;&#125;\n\n\n\nSpringBoot 集成 Redis\n使用脚手架引入相关依赖\n配置Redis\n添加Redis序列化方法\n\nimport com.fasterxml.jackson.annotation.JsonAutoDetect;import com.fasterxml.jackson.annotation.PropertyAccessor;import com.fasterxml.jackson.databind.ObjectMapper;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;@SpringBootApplicationpublic class SpringdataDemoApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(SpringdataDemoApplication.class, args);    &#125;    /**     * 自定义RedisTemplate的bean，不使用默认的RedisTemplate     * redisTemplate 默认序列化使用的jdkSerializeable, 存储二进制字节码, 所以自定义序列化类     * @param redisConnectionFactory     * @return     */    @Bean    public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory)&#123;        RedisTemplate&lt;Object, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;();        redisTemplate.setConnectionFactory(redisConnectionFactory);        // 使用Jackson2JsonRedisSerialize 替换默认序列化        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);        ObjectMapper objectMapper = new ObjectMapper();        objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);        objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);        jackson2JsonRedisSerializer.setObjectMapper(objectMapper);        // 设置value的序列化规则和 key的序列化规则        redisTemplate.setValueSerializer(jackson2JsonRedisSerializer);        redisTemplate.setKeySerializer(new StringRedisSerializer());        redisTemplate.setHashKeySerializer(jackson2JsonRedisSerializer);        redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer);        redisTemplate.afterPropertiesSet();        return redisTemplate;    &#125;&#125;\n\nimport org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.RedisTemplate;@SpringBootTest(classes = &#123;SpringdataDemoApplication.class&#125;)class SpringdataDemoApplicationTests &#123;    @Autowired    protected RedisTemplate redisTemplate;    @Test    void testInit() &#123;        // PING PONG 心跳机制检测是否连接成功        String pong = redisTemplate.getConnectionFactory().getConnection().ping();        System.out.println(&quot;pong = &quot; + pong);    &#125;    @Test    void testString() &#123;        // 测试，插入一条数据        redisTemplate.opsForValue().set(&quot;username&quot;,&quot;zhangsan&quot;);        Object username = redisTemplate.opsForValue().get(&quot;username&quot;);        System.out.println(&quot;username = &quot; + username);    &#125;&#125;\n\n\n\n需求分析与数据库设计项目架构\n基于微服务进行项目开发，微服务是目前比较热门的架构方式，具有以下特点:\n职责单一: 理论上一个微服务只解决一件事 (小)\n隔离性强:服务单独部署，服务之间互相隔离，互不影响，因此一个服务宕机并不影响其他服务运行。 (松)\n开发简单:一个微服务解决一件事情，那么对开发团队的要求相对就减少(不论从人数还是开发语言都可以随心所欲)，能够快速提高开发效率。 (便)\n\n\n\n\n\n\n\n\n本课程以美食社交APP后台API接口设计为例。涉及APP中用户、好友、订单为基础的相关业务，分为用户、好友、排行榜、优惠券/秒杀、订单、附近的人、Feed 等微服务。完成用户登录、交友、发朋友圈以及购买优惠券、下单整个业务流程，并实现积分排行榜以及附近的人等相关功能。\n\n\n\n\n\n数据库设计/* Navicat Premium Data Transfer Source Server         : localhost Source Server Type    : MySQL Source Server Version : 80018 Source Host           : localhost:3306 Source Schema         : db_imooc Target Server Type    : MySQL Target Server Version : 80018 File Encoding         : 65001 Date: 14/11/2020 19:06:41*/SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for t_dictionary-- ----------------------------DROP TABLE IF EXISTS `t_dictionary`;CREATE TABLE `t_dictionary`  (  `id` int(11) NOT NULL AUTO_INCREMENT,  `type` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `data` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `display_order` int(11) NULL DEFAULT 0,  PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 415 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = DYNAMIC;-- ------------------------------ Records of t_dictionary-- ----------------------------INSERT INTO `t_dictionary` VALUES (1, &#x27;TableType           &#x27;, &#x27;Regular|大厅&#x27;, 0);INSERT INTO `t_dictionary` VALUES (2, &#x27;TableType           &#x27;, &#x27;Bar|吧台&#x27;, 0);INSERT INTO `t_dictionary` VALUES (3, &#x27;TableType           &#x27;, &#x27;Window|靠窗&#x27;, 0);INSERT INTO `t_dictionary` VALUES (4, &#x27;TableType           &#x27;, &#x27;Outdoor|户外&#x27;, 0);INSERT INTO `t_dictionary` VALUES (5, &#x27;TableType           &#x27;, &#x27;Private|包间&#x27;, 0);INSERT INTO `t_dictionary` VALUES (7, &#x27;RestaurantTag       &#x27;, &#x27;24|hours|24小时营业&#x27;, 0);INSERT INTO `t_dictionary` VALUES (8, &#x27;RestaurantTag       &#x27;, &#x27;Afternoon|tea|下午茶&#x27;, 0);INSERT INTO `t_dictionary` VALUES (9, &#x27;RestaurantTag       &#x27;, &#x27;All|you|can|eat|自助餐&#x27;, 0);INSERT INTO `t_dictionary` VALUES (10, &#x27;RestaurantTag       &#x27;, &#x27;Bistros|酒馆&#x27;, 0);INSERT INTO `t_dictionary` VALUES (11, &#x27;RestaurantTag       &#x27;, &#x27;Breakfast|早餐&#x27;, 0);INSERT INTO `t_dictionary` VALUES (12, &#x27;RestaurantTag       &#x27;, &#x27;Bund|view|外滩风景&#x27;, 0);INSERT INTO `t_dictionary` VALUES (13, &#x27;RestaurantTag       &#x27;, &#x27;Classic|Shanghai|老上海&#x27;, 0);INSERT INTO `t_dictionary` VALUES (14, &#x27;RestaurantTag       &#x27;, &#x27;Cocktails|鸡尾酒&#x27;, 0);INSERT INTO `t_dictionary` VALUES (15, &#x27;RestaurantTag       &#x27;, &#x27;Credit|cards|accepted|可刷卡&#x27;, 0);INSERT INTO `t_dictionary` VALUES (16, &#x27;RestaurantTag       &#x27;, &#x27;Delivery|可送外卖&#x27;, 0);INSERT INTO `t_dictionary` VALUES (17, &#x27;RestaurantTag       &#x27;, &#x27;Pet|friendly|宠物友好&#x27;, 0);INSERT INTO `t_dictionary` VALUES (18, &#x27;RestaurantTag       &#x27;, &#x27;Kids|friendly||适合小孩&#x27;, 0);INSERT INTO `t_dictionary` VALUES (19, &#x27;RestaurantTag       &#x27;, &#x27;Fine|dining|顶级餐厅&#x27;, 0);INSERT INTO `t_dictionary` VALUES (20, &#x27;RestaurantTag       &#x27;, &#x27;Free|parking|免费停车&#x27;, 0);INSERT INTO `t_dictionary` VALUES (21, &#x27;RestaurantTag       &#x27;, &#x27;Lounge|酒廊&#x27;, 0);INSERT INTO `t_dictionary` VALUES (22, &#x27;RestaurantTag       &#x27;, &#x27;Lunch|set|午市套餐&#x27;, 0);INSERT INTO `t_dictionary` VALUES (23, &#x27;RestaurantTag       &#x27;, &#x27;Group|dining|团体&#x27;, 0);INSERT INTO `t_dictionary` VALUES (24, &#x27;RestaurantTag       &#x27;, &#x27;Healthy|健康&#x27;, 0);INSERT INTO `t_dictionary` VALUES (25, &#x27;RestaurantTag       &#x27;, &#x27;Historic|building|历史建筑&#x27;, 0);INSERT INTO `t_dictionary` VALUES (26, &#x27;RestaurantTag       &#x27;, &#x27;Hotel|restaurant||酒店餐厅&#x27;, 0);INSERT INTO `t_dictionary` VALUES (27, &#x27;RestaurantTag       &#x27;, &#x27;Ice|cream|冰激凌&#x27;, 0);INSERT INTO `t_dictionary` VALUES (28, &#x27;RestaurantTag       &#x27;, &#x27;Late|night|dining|夜宵&#x27;, 0);INSERT INTO `t_dictionary` VALUES (29, &#x27;RestaurantTag       &#x27;, &#x27;Non-smoking|有无烟区&#x27;, 0);INSERT INTO `t_dictionary` VALUES (30, &#x27;RestaurantTag       &#x27;, &#x27;Notable|wine|list|葡萄酒&#x27;, 0);INSERT INTO `t_dictionary` VALUES (32, &#x27;RestaurantTag       &#x27;, &#x27;Outdoor|seating|户外餐桌&#x27;, 0);INSERT INTO `t_dictionary` VALUES (33, &#x27;RestaurantTag       &#x27;, &#x27;Performance|现场表演&#x27;, 0);INSERT INTO `t_dictionary` VALUES (34, &#x27;RestaurantTag       &#x27;, &#x27;Romantic||浪漫&#x27;, 0);INSERT INTO `t_dictionary` VALUES (35, &#x27;RestaurantTag       &#x27;, &#x27;Ramen|日式拉面&#x27;, 0);INSERT INTO `t_dictionary` VALUES (36, &#x27;RestaurantTag       &#x27;, &#x27;Salads|沙拉&#x27;, 0);INSERT INTO `t_dictionary` VALUES (37, &#x27;RestaurantTag       &#x27;, &#x27;Sandwiches &amp; Delis|三明治&amp;熟食&#x27;, 0);INSERT INTO `t_dictionary` VALUES (38, &#x27;RestaurantTag       &#x27;, &#x27;Smoothies|冰沙&#x27;, 0);INSERT INTO `t_dictionary` VALUES (39, &#x27;RestaurantTag       &#x27;, &#x27;Tapas|西班牙小吃&#x27;, 0);INSERT INTO `t_dictionary` VALUES (40, &#x27;RestaurantTag       &#x27;, &#x27;Themed|restaurant|主题餐厅&#x27;, 0);INSERT INTO `t_dictionary` VALUES (41, &#x27;RestaurantTag       &#x27;, &#x27;Villa|别墅&#x27;, 0);INSERT INTO `t_dictionary` VALUES (43, &#x27;Cuisine             &#x27;, &#x27;American|北美菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (45, &#x27;Cuisine             &#x27;, &#x27;Australian|澳洲菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (48, &#x27;Cuisine             &#x27;, &#x27;Barbecue|烧烤&#x27;, 0);INSERT INTO `t_dictionary` VALUES (50, &#x27;Cuisine             &#x27;, &#x27;Beijing|京菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (63, &#x27;Cuisine             &#x27;, &#x27;Dongbei|东北菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (65, &#x27;Cuisine             &#x27;, &#x27;Hunan|湘菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (68, &#x27;Cuisine             &#x27;, &#x27;French|法国菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (70, &#x27;Cuisine             &#x27;, &#x27;Fusion|创意菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (71, &#x27;Cuisine             &#x27;, &#x27;German|德国菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (72, &#x27;Cuisine             &#x27;, &#x27;Grocery|杂货&#x27;, 0);INSERT INTO `t_dictionary` VALUES (73, &#x27;Cuisine             &#x27;, &#x27;Halal|清真&#x27;, 0);INSERT INTO `t_dictionary` VALUES (76, &#x27;Cuisine             &#x27;, &#x27;Hot Pot|火锅&#x27;, 0);INSERT INTO `t_dictionary` VALUES (79, &#x27;Cuisine             &#x27;, &#x27;Indian|印度菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (80, &#x27;Cuisine             &#x27;, &#x27;Indonesian|印尼菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (81, &#x27;Cuisine             &#x27;, &#x27;Italian|意大利菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (82, &#x27;Cuisine             &#x27;, &#x27;Japanese|日本料理&#x27;, 0);INSERT INTO `t_dictionary` VALUES (84, &#x27;Cuisine             &#x27;, &#x27;Jiangxi|赣菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (88, &#x27;Cuisine             &#x27;, &#x27;Malaysian|马来西亚菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (91, &#x27;Cuisine             &#x27;, &#x27;Mediterranean|地中海菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (92, &#x27;Cuisine             &#x27;, &#x27;Mexican / Tex-Mex|墨西哥菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (94, &#x27;Cuisine             &#x27;, &#x27;Other|其他&#x27;, 0);INSERT INTO `t_dictionary` VALUES (102, &#x27;Cuisine             &#x27;, &#x27;Portuguese|葡国菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (103, &#x27;Cuisine             &#x27;, &#x27;Russian|俄国菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (104, &#x27;Cuisine             &#x27;, &#x27;Sandwiches &amp; Delis|三明治&amp;简食&#x27;, 0);INSERT INTO `t_dictionary` VALUES (107, &#x27;Cuisine             &#x27;, &#x27;Shaoxing|绍兴菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (111, &#x27;Cuisine             &#x27;, &#x27;Shanghainese|上海菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (112, &#x27;Cuisine             &#x27;, &#x27;Singaporean|新加坡菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (113, &#x27;Cuisine             &#x27;, &#x27;South American|南美菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (114, &#x27;Cuisine             &#x27;, &#x27;Spanish|西班牙菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (115, &#x27;Cuisine             &#x27;, &#x27;Steakhouse|牛排店&#x27;, 0);INSERT INTO `t_dictionary` VALUES (117, &#x27;Cuisine             &#x27;, &#x27;Taiwanese|台湾菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (118, &#x27;Cuisine             &#x27;, &#x27;Thai|泰国菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (121, &#x27;Cuisine             &#x27;, &#x27;Turkish|土耳其菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (122, &#x27;Cuisine             &#x27;, &#x27;Vegetarian|素食&#x27;, 0);INSERT INTO `t_dictionary` VALUES (123, &#x27;Cuisine             &#x27;, &#x27;Vietnamese|越南菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (124, &#x27;Cuisine             &#x27;, &#x27;Wine Bar|红酒吧&#x27;, 0);INSERT INTO `t_dictionary` VALUES (126, &#x27;Cuisine             &#x27;, &#x27;Yunnan|云南菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (129, &#x27;Cuisine             &#x27;, &#x27;Zhejiang|浙菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (130, &#x27;nations             &#x27;, &#x27;Afghanistan | 阿富汗&#x27;, 0);INSERT INTO `t_dictionary` VALUES (131, &#x27;nations             &#x27;, &#x27;Albania | 阿尔巴尼亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (132, &#x27;nations             &#x27;, &#x27;Algeria | 阿尔及利亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (133, &#x27;nations             &#x27;, &#x27;Andorra | 安道尔&#x27;, 0);INSERT INTO `t_dictionary` VALUES (134, &#x27;nations             &#x27;, &#x27;Angola | 安哥拉&#x27;, 0);INSERT INTO `t_dictionary` VALUES (135, &#x27;nations             &#x27;, &#x27;Argentina | 阿根廷&#x27;, 0);INSERT INTO `t_dictionary` VALUES (136, &#x27;nations             &#x27;, &#x27;Armenia | 亚美尼亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (137, &#x27;nations             &#x27;, &#x27;Australia | 澳大利亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (138, &#x27;nations             &#x27;, &#x27;Austria | 奥地利&#x27;, 0);INSERT INTO `t_dictionary` VALUES (139, &#x27;nations             &#x27;, &#x27;Azerbaijan | 阿塞拜疆&#x27;, 0);INSERT INTO `t_dictionary` VALUES (140, &#x27;nations             &#x27;, &#x27;Bahamas | 巴哈马&#x27;, 0);INSERT INTO `t_dictionary` VALUES (141, &#x27;nations             &#x27;, &#x27;Bahrain | 巴林&#x27;, 0);INSERT INTO `t_dictionary` VALUES (142, &#x27;nations             &#x27;, &#x27;Bangladesh | 孟加拉国&#x27;, 0);INSERT INTO `t_dictionary` VALUES (143, &#x27;nations             &#x27;, &#x27;Barbados | 巴巴多斯&#x27;, 0);INSERT INTO `t_dictionary` VALUES (144, &#x27;nations             &#x27;, &#x27;Belarus | 白俄罗斯&#x27;, 0);INSERT INTO `t_dictionary` VALUES (145, &#x27;nations             &#x27;, &#x27;Belgium | 比利时&#x27;, 0);INSERT INTO `t_dictionary` VALUES (146, &#x27;nations             &#x27;, &#x27;Belize | 伯利兹&#x27;, 0);INSERT INTO `t_dictionary` VALUES (147, &#x27;nations             &#x27;, &#x27;Benin | 柏林&#x27;, 0);INSERT INTO `t_dictionary` VALUES (148, &#x27;nations             &#x27;, &#x27;Bhutan | 不丹&#x27;, 0);INSERT INTO `t_dictionary` VALUES (149, &#x27;nations             &#x27;, &#x27;Bolivia | 玻利维亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (150, &#x27;nations             &#x27;, &#x27;Bosnia-Herzegovina | 波斯尼亚和黑塞哥维那&#x27;, 0);INSERT INTO `t_dictionary` VALUES (151, &#x27;nations             &#x27;, &#x27;Botswana | 博茨瓦纳&#x27;, 0);INSERT INTO `t_dictionary` VALUES (152, &#x27;nations             &#x27;, &#x27;Brazil | 巴西&#x27;, 0);INSERT INTO `t_dictionary` VALUES (154, &#x27;nations             &#x27;, &#x27;Brunei | 文莱&#x27;, 0);INSERT INTO `t_dictionary` VALUES (155, &#x27;nations             &#x27;, &#x27;Bulgaria | 保加利亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (156, &#x27;nations             &#x27;, &#x27;Burkina | 布基纳法索&#x27;, 0);INSERT INTO `t_dictionary` VALUES (157, &#x27;nations             &#x27;, &#x27;Burma (Myanmar) | 缅甸&#x27;, 0);INSERT INTO `t_dictionary` VALUES (158, &#x27;nations             &#x27;, &#x27;Burundi | 布隆迪&#x27;, 0);INSERT INTO `t_dictionary` VALUES (159, &#x27;nations             &#x27;, &#x27;Cambodia | 柬埔寨&#x27;, 0);INSERT INTO `t_dictionary` VALUES (160, &#x27;nations             &#x27;, &#x27;Cameroon | 喀麦隆&#x27;, 0);INSERT INTO `t_dictionary` VALUES (161, &#x27;nations             &#x27;, &#x27;Canada | 加拿大&#x27;, 0);INSERT INTO `t_dictionary` VALUES (162, &#x27;nations             &#x27;, &#x27;Cape Verde Islands | 佛得角群岛&#x27;, 0);INSERT INTO `t_dictionary` VALUES (163, &#x27;nations             &#x27;, &#x27;Chad | 乍得&#x27;, 0);INSERT INTO `t_dictionary` VALUES (164, &#x27;nations             &#x27;, &#x27;Chile | 智利&#x27;, 0);INSERT INTO `t_dictionary` VALUES (166, &#x27;nations             &#x27;, &#x27;Colombia | 哥伦比亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (167, &#x27;nations             &#x27;, &#x27;Congo | 刚果&#x27;, 0);INSERT INTO `t_dictionary` VALUES (168, &#x27;nations             &#x27;, &#x27;Costa Rica | 哥斯达黎加&#x27;, 0);INSERT INTO `t_dictionary` VALUES (169, &#x27;nations             &#x27;, &#x27;Croatia | 克罗地亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (170, &#x27;nations             &#x27;, &#x27;Cuba | 古巴&#x27;, 0);INSERT INTO `t_dictionary` VALUES (171, &#x27;nations             &#x27;, &#x27;Cyprus | 塞浦路斯&#x27;, 0);INSERT INTO `t_dictionary` VALUES (172, &#x27;nations             &#x27;, &#x27;Czech Republic | 捷克共和国&#x27;, 0);INSERT INTO `t_dictionary` VALUES (173, &#x27;nations             &#x27;, &#x27;Denmark | 丹麦&#x27;, 0);INSERT INTO `t_dictionary` VALUES (174, &#x27;nations             &#x27;, &#x27;Djibouti | 吉布提&#x27;, 0);INSERT INTO `t_dictionary` VALUES (175, &#x27;nations             &#x27;, &#x27;Dominica | 多米尼加&#x27;, 0);INSERT INTO `t_dictionary` VALUES (176, &#x27;nations             &#x27;, &#x27;Dominican Republic | 多米尼加国共和国&#x27;, 0);INSERT INTO `t_dictionary` VALUES (177, &#x27;nations             &#x27;, &#x27;Ecuador | 厄瓜多尔&#x27;, 0);INSERT INTO `t_dictionary` VALUES (178, &#x27;nations             &#x27;, &#x27;Egypt | 埃及&#x27;, 0);INSERT INTO `t_dictionary` VALUES (179, &#x27;nations             &#x27;, &#x27;El Salvador | 萨尔瓦多&#x27;, 0);INSERT INTO `t_dictionary` VALUES (180, &#x27;nations             &#x27;, &#x27;England | 英格兰&#x27;, 0);INSERT INTO `t_dictionary` VALUES (181, &#x27;nations             &#x27;, &#x27;Eritrea | 厄立特里亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (182, &#x27;nations             &#x27;, &#x27;Estonia | 爱沙尼亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (183, &#x27;nations             &#x27;, &#x27;Ethiopia | 埃塞俄比亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (184, &#x27;nations             &#x27;, &#x27;Fiji | 斐济&#x27;, 0);INSERT INTO `t_dictionary` VALUES (185, &#x27;nations             &#x27;, &#x27;Finland | 芬兰&#x27;, 0);INSERT INTO `t_dictionary` VALUES (186, &#x27;nations             &#x27;, &#x27;France | 法国&#x27;, 0);INSERT INTO `t_dictionary` VALUES (187, &#x27;nations             &#x27;, &#x27;Gabon | 加蓬&#x27;, 0);INSERT INTO `t_dictionary` VALUES (188, &#x27;nations             &#x27;, &#x27;Gambia | 冈比亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (189, &#x27;nations             &#x27;, &#x27;Georgia | 格鲁吉亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (190, &#x27;nations             &#x27;, &#x27;Germany | 德国&#x27;, 0);INSERT INTO `t_dictionary` VALUES (191, &#x27;nations             &#x27;, &#x27;Ghana | 加纳&#x27;, 0);INSERT INTO `t_dictionary` VALUES (192, &#x27;nations             &#x27;, &#x27;Greece | 希腊&#x27;, 0);INSERT INTO `t_dictionary` VALUES (193, &#x27;nations             &#x27;, &#x27;Grenada | 格林纳达&#x27;, 0);INSERT INTO `t_dictionary` VALUES (194, &#x27;nations             &#x27;, &#x27;Guatemala | 危地马拉&#x27;, 0);INSERT INTO `t_dictionary` VALUES (195, &#x27;nations             &#x27;, &#x27;Guinea | 几内亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (196, &#x27;nations             &#x27;, &#x27;Guyana | 圭亚那&#x27;, 0);INSERT INTO `t_dictionary` VALUES (197, &#x27;nations             &#x27;, &#x27;Haiti | 海地&#x27;, 0);INSERT INTO `t_dictionary` VALUES (198, &#x27;nations             &#x27;, &#x27;Netherlands | 荷兰&#x27;, 0);INSERT INTO `t_dictionary` VALUES (199, &#x27;nations             &#x27;, &#x27;Honduras | 洪都拉斯&#x27;, 0);INSERT INTO `t_dictionary` VALUES (200, &#x27;nations             &#x27;, &#x27;Hungary | 匈牙利&#x27;, 0);INSERT INTO `t_dictionary` VALUES (201, &#x27;nations             &#x27;, &#x27;Iceland | 冰岛&#x27;, 0);INSERT INTO `t_dictionary` VALUES (202, &#x27;nations             &#x27;, &#x27;India | 印度&#x27;, 0);INSERT INTO `t_dictionary` VALUES (203, &#x27;nations             &#x27;, &#x27;Indonesia | 印度尼西亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (204, &#x27;nations             &#x27;, &#x27;Iran | 伊朗&#x27;, 0);INSERT INTO `t_dictionary` VALUES (205, &#x27;nations             &#x27;, &#x27;Iraq | 伊拉克&#x27;, 0);INSERT INTO `t_dictionary` VALUES (206, &#x27;nations             &#x27;, &#x27;Ireland | 爱尔兰&#x27;, 0);INSERT INTO `t_dictionary` VALUES (207, &#x27;nations             &#x27;, &#x27;Italy | 意大利&#x27;, 0);INSERT INTO `t_dictionary` VALUES (208, &#x27;nations             &#x27;, &#x27;Jamaica | 牙买加&#x27;, 0);INSERT INTO `t_dictionary` VALUES (209, &#x27;nations             &#x27;, &#x27;Japan | 日本&#x27;, 0);INSERT INTO `t_dictionary` VALUES (210, &#x27;nations             &#x27;, &#x27;Jordan | 约旦&#x27;, 0);INSERT INTO `t_dictionary` VALUES (211, &#x27;nations             &#x27;, &#x27;Kazakhstan | 哈萨克斯坦&#x27;, 0);INSERT INTO `t_dictionary` VALUES (212, &#x27;nations             &#x27;, &#x27;Kenya | 肯尼亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (213, &#x27;nations             &#x27;, &#x27;Kuwait | 科威特&#x27;, 0);INSERT INTO `t_dictionary` VALUES (214, &#x27;nations             &#x27;, &#x27;Laos | 老挝&#x27;, 0);INSERT INTO `t_dictionary` VALUES (215, &#x27;nations             &#x27;, &#x27;Latvia | 拉脱维亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (216, &#x27;nations             &#x27;, &#x27;Lebanon | 黎巴嫩&#x27;, 0);INSERT INTO `t_dictionary` VALUES (217, &#x27;nations             &#x27;, &#x27;Liberia | 利比里亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (218, &#x27;nations             &#x27;, &#x27;Libya | 利比亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (219, &#x27;nations             &#x27;, &#x27;Liechtenstein | 列支敦士登&#x27;, 0);INSERT INTO `t_dictionary` VALUES (220, &#x27;nations             &#x27;, &#x27;Lithuania | 立陶宛&#x27;, 0);INSERT INTO `t_dictionary` VALUES (221, &#x27;nations             &#x27;, &#x27;Luxembourg | 卢森堡&#x27;, 0);INSERT INTO `t_dictionary` VALUES (222, &#x27;nations             &#x27;, &#x27;Macedonia马其顿&#x27;, 0);INSERT INTO `t_dictionary` VALUES (223, &#x27;nations             &#x27;, &#x27;Madagascar | 马达加斯加&#x27;, 0);INSERT INTO `t_dictionary` VALUES (224, &#x27;nations             &#x27;, &#x27;Malawi | 马拉维&#x27;, 0);INSERT INTO `t_dictionary` VALUES (225, &#x27;nations             &#x27;, &#x27;Malaysia | 马来西亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (226, &#x27;nations             &#x27;, &#x27;Maldives | 马尔代夫&#x27;, 0);INSERT INTO `t_dictionary` VALUES (227, &#x27;nations             &#x27;, &#x27;Mali | 马里&#x27;, 0);INSERT INTO `t_dictionary` VALUES (228, &#x27;nations             &#x27;, &#x27;Malta | 马耳他&#x27;, 0);INSERT INTO `t_dictionary` VALUES (229, &#x27;nations             &#x27;, &#x27;Mauritania | 毛里塔尼亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (230, &#x27;nations             &#x27;, &#x27;Mauritius | 毛里求斯&#x27;, 0);INSERT INTO `t_dictionary` VALUES (231, &#x27;nations             &#x27;, &#x27;Mexico | 墨西哥&#x27;, 0);INSERT INTO `t_dictionary` VALUES (232, &#x27;nations             &#x27;, &#x27;Moldova | 摩尔多瓦&#x27;, 0);INSERT INTO `t_dictionary` VALUES (233, &#x27;nations             &#x27;, &#x27;Monaco | 摩纳哥&#x27;, 0);INSERT INTO `t_dictionary` VALUES (234, &#x27;nations             &#x27;, &#x27;Mongolia | 蒙古&#x27;, 0);INSERT INTO `t_dictionary` VALUES (235, &#x27;nations             &#x27;, &#x27;Montenegro | 黑山&#x27;, 0);INSERT INTO `t_dictionary` VALUES (236, &#x27;nations             &#x27;, &#x27;Morocco | 摩洛哥&#x27;, 0);INSERT INTO `t_dictionary` VALUES (237, &#x27;nations             &#x27;, &#x27;Mozambique | 莫桑比克&#x27;, 0);INSERT INTO `t_dictionary` VALUES (239, &#x27;nations             &#x27;, &#x27;Namibia | 纳米比亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (240, &#x27;nations             &#x27;, &#x27;Nepal | 尼泊尔&#x27;, 0);INSERT INTO `t_dictionary` VALUES (242, &#x27;nations             &#x27;, &#x27;New Zealand | 新西兰&#x27;, 0);INSERT INTO `t_dictionary` VALUES (243, &#x27;nations             &#x27;, &#x27;Nicaragua | 尼加拉瓜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (244, &#x27;nations             &#x27;, &#x27;Niger | 尼日尔&#x27;, 0);INSERT INTO `t_dictionary` VALUES (245, &#x27;nations             &#x27;, &#x27;Nigeria | 尼日利亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (246, &#x27;nations             &#x27;, &#x27;North Korea | 朝鲜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (247, &#x27;nations             &#x27;, &#x27;Norway | 挪威&#x27;, 0);INSERT INTO `t_dictionary` VALUES (248, &#x27;nations             &#x27;, &#x27;Oman | 阿曼&#x27;, 0);INSERT INTO `t_dictionary` VALUES (249, &#x27;nations             &#x27;, &#x27;Pakistan | 巴基斯坦&#x27;, 0);INSERT INTO `t_dictionary` VALUES (250, &#x27;nations             &#x27;, &#x27;Panama | 巴拿马&#x27;, 0);INSERT INTO `t_dictionary` VALUES (251, &#x27;nations             &#x27;, &#x27;Papua New Guinea | 巴布亚新几内亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (252, &#x27;nations             &#x27;, &#x27;Paraguay | 巴拉圭&#x27;, 0);INSERT INTO `t_dictionary` VALUES (253, &#x27;nations             &#x27;, &#x27;Peru | 秘鲁&#x27;, 0);INSERT INTO `t_dictionary` VALUES (254, &#x27;nations             &#x27;, &#x27;Philippines | 菲律宾&#x27;, 0);INSERT INTO `t_dictionary` VALUES (255, &#x27;nations             &#x27;, &#x27;Poland | 波兰&#x27;, 0);INSERT INTO `t_dictionary` VALUES (256, &#x27;nations             &#x27;, &#x27;Portugal | 葡萄牙&#x27;, 0);INSERT INTO `t_dictionary` VALUES (257, &#x27;nations             &#x27;, &#x27;Qatar | 卡塔尔&#x27;, 0);INSERT INTO `t_dictionary` VALUES (258, &#x27;nations             &#x27;, &#x27;Romania | 罗马尼亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (259, &#x27;nations             &#x27;, &#x27;Russia | 俄罗斯&#x27;, 0);INSERT INTO `t_dictionary` VALUES (260, &#x27;nations             &#x27;, &#x27;Rwanda | 卢旺达&#x27;, 0);INSERT INTO `t_dictionary` VALUES (261, &#x27;nations             &#x27;, &#x27;Saudi Arabia | 沙特阿拉伯&#x27;, 0);INSERT INTO `t_dictionary` VALUES (262, &#x27;nations             &#x27;, &#x27;Scotland | 苏格兰&#x27;, 0);INSERT INTO `t_dictionary` VALUES (263, &#x27;nations             &#x27;, &#x27;Senegal | 塞内加尔&#x27;, 0);INSERT INTO `t_dictionary` VALUES (264, &#x27;nations             &#x27;, &#x27;Serbia | 塞尔维亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (265, &#x27;nations             &#x27;, &#x27;Seychelles | 塞舌尔&#x27;, 0);INSERT INTO `t_dictionary` VALUES (266, &#x27;nations             &#x27;, &#x27;Sierra Leone | 塞拉里昂&#x27;, 0);INSERT INTO `t_dictionary` VALUES (267, &#x27;nations             &#x27;, &#x27;Singapore | 新加坡&#x27;, 0);INSERT INTO `t_dictionary` VALUES (268, &#x27;nations             &#x27;, &#x27;Slovakia | 斯洛伐克&#x27;, 0);INSERT INTO `t_dictionary` VALUES (269, &#x27;nations             &#x27;, &#x27;Slovenia | 斯洛伐尼亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (270, &#x27;nations             &#x27;, &#x27;Solomon Islands | 所罗门群岛&#x27;, 0);INSERT INTO `t_dictionary` VALUES (271, &#x27;nations             &#x27;, &#x27;Somalia | 索马里&#x27;, 0);INSERT INTO `t_dictionary` VALUES (272, &#x27;nations             &#x27;, &#x27;South Africa | 南非&#x27;, 0);INSERT INTO `t_dictionary` VALUES (273, &#x27;nations             &#x27;, &#x27;South Korea | 韩国&#x27;, 0);INSERT INTO `t_dictionary` VALUES (274, &#x27;nations             &#x27;, &#x27;Spain | 西班牙&#x27;, 0);INSERT INTO `t_dictionary` VALUES (275, &#x27;nations             &#x27;, &#x27;Sri Lanka | 斯里兰卡&#x27;, 0);INSERT INTO `t_dictionary` VALUES (276, &#x27;nations             &#x27;, &#x27;Sudan | 苏丹&#x27;, 0);INSERT INTO `t_dictionary` VALUES (277, &#x27;nations             &#x27;, &#x27;Suriname | 苏里南&#x27;, 0);INSERT INTO `t_dictionary` VALUES (278, &#x27;nations             &#x27;, &#x27;Swaziland | 斯维士兰&#x27;, 0);INSERT INTO `t_dictionary` VALUES (279, &#x27;nations             &#x27;, &#x27;Sweden | 瑞典&#x27;, 0);INSERT INTO `t_dictionary` VALUES (280, &#x27;nations             &#x27;, &#x27;Switzerland | 瑞士&#x27;, 0);INSERT INTO `t_dictionary` VALUES (281, &#x27;nations             &#x27;, &#x27;Syria | 叙利亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (282, &#x27;nations             &#x27;, &#x27;Taiwan | 台湾&#x27;, 0);INSERT INTO `t_dictionary` VALUES (283, &#x27;nations             &#x27;, &#x27;Tajikistan | 塔吉克斯坦&#x27;, 0);INSERT INTO `t_dictionary` VALUES (284, &#x27;nations             &#x27;, &#x27;Tanzania | 坦桑尼亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (285, &#x27;nations             &#x27;, &#x27;Thailand | 泰国&#x27;, 0);INSERT INTO `t_dictionary` VALUES (286, &#x27;nations             &#x27;, &#x27;Togo | 多哥&#x27;, 0);INSERT INTO `t_dictionary` VALUES (287, &#x27;nations             &#x27;, &#x27;Trinidad and Tobago | 特里尼达和多巴哥&#x27;, 0);INSERT INTO `t_dictionary` VALUES (289, &#x27;nations             &#x27;, &#x27;Tunisia | 突尼斯&#x27;, 0);INSERT INTO `t_dictionary` VALUES (290, &#x27;nations             &#x27;, &#x27;Turkey | 土耳其&#x27;, 0);INSERT INTO `t_dictionary` VALUES (291, &#x27;nations             &#x27;, &#x27;Turkmenistan | 土库曼斯坦&#x27;, 0);INSERT INTO `t_dictionary` VALUES (292, &#x27;nations             &#x27;, &#x27;Tuvalu | 图瓦卢&#x27;, 0);INSERT INTO `t_dictionary` VALUES (293, &#x27;nations             &#x27;, &#x27;Uganda | 乌干达&#x27;, 0);INSERT INTO `t_dictionary` VALUES (294, &#x27;nations             &#x27;, &#x27;Ukraine | 乌克兰&#x27;, 0);INSERT INTO `t_dictionary` VALUES (295, &#x27;nations             &#x27;, &#x27;United Arab Emirates | 阿拉伯联合大公国&#x27;, 0);INSERT INTO `t_dictionary` VALUES (296, &#x27;nations             &#x27;, &#x27;United Kingdom  | 联合王国&#x27;, 0);INSERT INTO `t_dictionary` VALUES (297, &#x27;nations             &#x27;, &#x27;U.S.A. | 美国&#x27;, 0);INSERT INTO `t_dictionary` VALUES (298, &#x27;nations             &#x27;, &#x27;Uruguay | 乌拉圭&#x27;, 0);INSERT INTO `t_dictionary` VALUES (299, &#x27;nations             &#x27;, &#x27;Uzbekistan | 乌兹别克斯坦&#x27;, 0);INSERT INTO `t_dictionary` VALUES (300, &#x27;nations             &#x27;, &#x27;Vanuatu | 瓦努阿图&#x27;, 0);INSERT INTO `t_dictionary` VALUES (301, &#x27;nations             &#x27;, &#x27;Vatican City | 梵蒂冈&#x27;, 0);INSERT INTO `t_dictionary` VALUES (302, &#x27;nations             &#x27;, &#x27;Venezuela | 委内瑞拉&#x27;, 0);INSERT INTO `t_dictionary` VALUES (303, &#x27;nations             &#x27;, &#x27;Vietnam | 越南&#x27;, 0);INSERT INTO `t_dictionary` VALUES (304, &#x27;nations             &#x27;, &#x27;Wales | 威尔士&#x27;, 0);INSERT INTO `t_dictionary` VALUES (305, &#x27;nations             &#x27;, &#x27;Western Samoa | 西萨摩亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (306, &#x27;nations             &#x27;, &#x27;Yemen | 也门&#x27;, 0);INSERT INTO `t_dictionary` VALUES (307, &#x27;nations             &#x27;, &#x27;Yugoslavia | 南斯拉夫&#x27;, 0);INSERT INTO `t_dictionary` VALUES (308, &#x27;nations             &#x27;, &#x27;Zaire | 扎伊尔&#x27;, 0);INSERT INTO `t_dictionary` VALUES (309, &#x27;nations             &#x27;, &#x27;Zambia | 赞比亚&#x27;, 0);INSERT INTO `t_dictionary` VALUES (310, &#x27;nations             &#x27;, &#x27;Zimbabwe | 津巴布韦&#x27;, 0);INSERT INTO `t_dictionary` VALUES (311, &#x27;nations             &#x27;, &#x27;Anhui | 安徽&#x27;, 0);INSERT INTO `t_dictionary` VALUES (312, &#x27;nations             &#x27;, &#x27;Fujian | 福建&#x27;, 0);INSERT INTO `t_dictionary` VALUES (313, &#x27;nations             &#x27;, &#x27;Gansu | 甘肃&#x27;, 0);INSERT INTO `t_dictionary` VALUES (314, &#x27;nations             &#x27;, &#x27;Guangdong | 广东&#x27;, 0);INSERT INTO `t_dictionary` VALUES (315, &#x27;nations             &#x27;, &#x27;Guizhou | 贵州&#x27;, 0);INSERT INTO `t_dictionary` VALUES (316, &#x27;nations             &#x27;, &#x27;Hainan | 海南&#x27;, 0);INSERT INTO `t_dictionary` VALUES (317, &#x27;nations             &#x27;, &#x27;Hebei | 河北&#x27;, 0);INSERT INTO `t_dictionary` VALUES (318, &#x27;nations             &#x27;, &#x27;Heilongjiang | 黑龙江&#x27;, 0);INSERT INTO `t_dictionary` VALUES (319, &#x27;nations             &#x27;, &#x27;Henan | 河南&#x27;, 0);INSERT INTO `t_dictionary` VALUES (320, &#x27;nations             &#x27;, &#x27;Hubei | 湖北&#x27;, 0);INSERT INTO `t_dictionary` VALUES (321, &#x27;nations             &#x27;, &#x27;Hunan | 湖南&#x27;, 0);INSERT INTO `t_dictionary` VALUES (322, &#x27;nations             &#x27;, &#x27;Jiangsu | 江苏&#x27;, 0);INSERT INTO `t_dictionary` VALUES (323, &#x27;nations             &#x27;, &#x27;Jiangxi | 江西&#x27;, 0);INSERT INTO `t_dictionary` VALUES (324, &#x27;nations             &#x27;, &#x27;Jilin | 吉林&#x27;, 0);INSERT INTO `t_dictionary` VALUES (325, &#x27;nations             &#x27;, &#x27;Liaoning | 辽宁&#x27;, 0);INSERT INTO `t_dictionary` VALUES (326, &#x27;nations             &#x27;, &#x27;Qinghai | 青海&#x27;, 0);INSERT INTO `t_dictionary` VALUES (327, &#x27;nations             &#x27;, &#x27;Shaanxi | 陕西&#x27;, 0);INSERT INTO `t_dictionary` VALUES (328, &#x27;nations             &#x27;, &#x27;Shandong | 山东&#x27;, 0);INSERT INTO `t_dictionary` VALUES (329, &#x27;nations             &#x27;, &#x27;Shanxi | 山西&#x27;, 0);INSERT INTO `t_dictionary` VALUES (330, &#x27;nations             &#x27;, &#x27;Sichuan | 四川&#x27;, 0);INSERT INTO `t_dictionary` VALUES (331, &#x27;nations             &#x27;, &#x27;Yunnan | 云南&#x27;, 0);INSERT INTO `t_dictionary` VALUES (332, &#x27;nations             &#x27;, &#x27;Zhejiang | 浙江&#x27;, 0);INSERT INTO `t_dictionary` VALUES (333, &#x27;nations             &#x27;, &#x27;Guangxi | 广西&#x27;, 0);INSERT INTO `t_dictionary` VALUES (334, &#x27;nations             &#x27;, &#x27;Inner Mongolia | 内蒙古&#x27;, 0);INSERT INTO `t_dictionary` VALUES (335, &#x27;nations             &#x27;, &#x27;Ningxia | 宁夏&#x27;, 0);INSERT INTO `t_dictionary` VALUES (336, &#x27;nations             &#x27;, &#x27;Xinjiang | 新疆&#x27;, 0);INSERT INTO `t_dictionary` VALUES (337, &#x27;nations             &#x27;, &#x27;Tibet | 西藏&#x27;, 0);INSERT INTO `t_dictionary` VALUES (338, &#x27;nations             &#x27;, &#x27;Beijing | 北京&#x27;, 0);INSERT INTO `t_dictionary` VALUES (339, &#x27;nations             &#x27;, &#x27;Chongqing | 重庆&#x27;, 0);INSERT INTO `t_dictionary` VALUES (340, &#x27;nations             &#x27;, &#x27;Shanghai | 上海&#x27;, 0);INSERT INTO `t_dictionary` VALUES (341, &#x27;nations             &#x27;, &#x27;Tianjin | 天津&#x27;, 0);INSERT INTO `t_dictionary` VALUES (342, &#x27;nations             &#x27;, &#x27;Hong Kong | 香港&#x27;, 0);INSERT INTO `t_dictionary` VALUES (343, &#x27;nations             &#x27;, &#x27;Macau | 澳门&#x27;, 0);INSERT INTO `t_dictionary` VALUES (346, &#x27;RestaurantTag       &#x27;, &#x27;Wifi|无线上网&#x27;, 0);INSERT INTO `t_dictionary` VALUES (349, &#x27;RestaurantTag       &#x27;, &#x27;Good|View|有景观位&#x27;, 0);INSERT INTO `t_dictionary` VALUES (351, &#x27;RestaurantTag       &#x27;, &#x27;Big|Party|大型宴会&#x27;, 0);INSERT INTO `t_dictionary` VALUES (352, &#x27;RestaurantTag       &#x27;, &#x27;Birthday|Party|生日宴会&#x27;, 0);INSERT INTO `t_dictionary` VALUES (353, &#x27;RestaurantTag       &#x27;, &#x27;BYOB|自带酒水&#x27;, 0);INSERT INTO `t_dictionary` VALUES (354, &#x27;RestaurantStyle     &#x27;, &#x27;朋友聚餐&#x27;, 0);INSERT INTO `t_dictionary` VALUES (355, &#x27;RestaurantStyle     &#x27;, &#x27;家庭聚会&#x27;, 0);INSERT INTO `t_dictionary` VALUES (356, &#x27;RestaurantStyle     &#x27;, &#x27;随便吃吃&#x27;, 0);INSERT INTO `t_dictionary` VALUES (357, &#x27;RestaurantStyle     &#x27;, &#x27;休闲小憩&#x27;, 0);INSERT INTO `t_dictionary` VALUES (358, &#x27;RestaurantStyle     &#x27;, &#x27;情侣约会&#x27;, 0);INSERT INTO `t_dictionary` VALUES (359, &#x27;RestaurantStyle     &#x27;, &#x27;商务宴请&#x27;, 0);INSERT INTO `t_dictionary` VALUES (360, &#x27;InviteStatus        &#x27;, &#x27;即将接洽&#x27;, 0);INSERT INTO `t_dictionary` VALUES (361, &#x27;InviteStatus        &#x27;, &#x27;等待老板决定&#x27;, 0);INSERT INTO `t_dictionary` VALUES (362, &#x27;InviteStatus        &#x27;, &#x27;合同签署中&#x27;, 0);INSERT INTO `t_dictionary` VALUES (363, &#x27;InviteStatus        &#x27;, &#x27;合同已经签订&#x27;, 0);INSERT INTO `t_dictionary` VALUES (370, &#x27;Cuisine&#x27;, &#x27;All-You-Can-Eat|自助餐&#x27;, 0);INSERT INTO `t_dictionary` VALUES (371, &#x27;Cuisine&#x27;, &#x27;Bar|酒吧&#x27;, 0);INSERT INTO `t_dictionary` VALUES (372, &#x27;Cuisine&#x27;, &#x27;Cafe|咖啡厅&#x27;, 0);INSERT INTO `t_dictionary` VALUES (373, &#x27;Cuisine&#x27;, &#x27;Cantonese|粤菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (374, &#x27;Cuisine&#x27;, &#x27;Dessert|甜品&#x27;, 0);INSERT INTO `t_dictionary` VALUES (375, &#x27;Cuisine&#x27;, &#x27;Global Cuisine|环球美食&#x27;, 0);INSERT INTO `t_dictionary` VALUES (376, &#x27;Cuisine&#x27;, &#x27;Middle Eastern|中东菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (377, &#x27;Cuisine&#x27;, &#x27;Southeast Asian|东南亚菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (378, &#x27;Cuisine&#x27;, &#x27;Zhejiang|浙江菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (379, &#x27;Cuisine&#x27;, &#x27;Fast Casual|小吃快餐&#x27;, 0);INSERT INTO `t_dictionary` VALUES (380, &#x27;nations&#x27;, &#x27;Israel&#x27;, 0);INSERT INTO `t_dictionary` VALUES (381, &#x27;nations&#x27;, &#x27;East Timor&#x27;, 0);INSERT INTO `t_dictionary` VALUES (382, &#x27;nations&#x27;, &#x27;Central African Republic&#x27;, 0);INSERT INTO `t_dictionary` VALUES (383, &#x27;nations&#x27;, &#x27;S?o Tomé and Principe&#x27;, 0);INSERT INTO `t_dictionary` VALUES (384, &#x27;nations&#x27;, &#x27;Ivory Coast&#x27;, 0);INSERT INTO `t_dictionary` VALUES (385, &#x27;nations&#x27;, &#x27;Lesotho&#x27;, 0);INSERT INTO `t_dictionary` VALUES (386, &#x27;nations&#x27;, &#x27;Equatorial Guinea&#x27;, 0);INSERT INTO `t_dictionary` VALUES (387, &#x27;nations&#x27;, &#x27;Guinea Bissau&#x27;, 0);INSERT INTO `t_dictionary` VALUES (400, &#x27;Cuisine&#x27;, &#x27;Sushi|寿司&#x27;, 0);INSERT INTO `t_dictionary` VALUES (401, &#x27;Cuisine&#x27;, &#x27;British|英国菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (402, &#x27;Cuisine&#x27;, &#x27;Dim Sum|早茶点心&#x27;, 0);INSERT INTO `t_dictionary` VALUES (403, &#x27;Cuisine&#x27;, &#x27;Xibei / Xinjiang|西北菜/新疆菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (405, &#x27;Cuisine&#x27;, &#x27;Guizhou|黔菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (406, &#x27;Cuisine&#x27;, &#x27;Pizza|披萨&#x27;, 0);INSERT INTO `t_dictionary` VALUES (408, &#x27;Cuisine&#x27;, &#x27;Seafood|海鲜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (409, &#x27;Cuisine&#x27;, &#x27;Anhui|徽菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (411, &#x27;Cuisine&#x27;, &#x27;Sichuan|川菜&#x27;, 0);INSERT INTO `t_dictionary` VALUES (412, &#x27;Cuisine&#x27;, &#x27;Korean|韩国料理&#x27;, 0);INSERT INTO `t_dictionary` VALUES (413, &#x27;Cuisine&#x27;, &#x27;Juice &amp; Beverages|果汁饮料&#x27;, 0);INSERT INTO `t_dictionary` VALUES (414, &#x27;Cuisine&#x27;, &#x27;Bakery &amp; Pastries|面包烘焙&#x27;, 0);-- ------------------------------ Table structure for t_diners-- ----------------------------DROP TABLE IF EXISTS `t_diners`;CREATE TABLE `t_diners`  (  `id` int(11) NOT NULL AUTO_INCREMENT,  `username` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,  `nickname` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT &#x27;昵称&#x27;,  `phone` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,  `email` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,  `password` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,  `avatar_url` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT &#x27;头像&#x27;,  `roles` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT &#x27;&#x27; COMMENT &#x27;角色&#x27;,  `is_valid` tinyint(1) NULL DEFAULT NULL,  `create_date` datetime(0) NULL DEFAULT NULL,  `update_date` datetime(0) NULL DEFAULT NULL,  PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 6 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = DYNAMIC;-- ------------------------------ Records of t_diners-- ----------------------------INSERT INTO `t_diners` VALUES (1, &#x27;abc&#x27;, &#x27;昵称st&#x27;, &#x27;13888888888&#x27;, &#x27;abc@imooc.com&#x27;, &#x27;e10adc3949ba59abbe56e057f20f883e&#x27;, &#x27;/abc&#x27;, &#x27;ROLE_USER&#x27;, 1, &#x27;2020-11-06 16:17:52&#x27;, &#x27;2020-11-06 16:17:55&#x27;);INSERT INTO `t_diners` VALUES (2, &#x27;test&#x27;, &#x27;test&#x27;, &#x27;13666666666&#x27;, NULL, &#x27;e10adc3949ba59abbe56e057f20f883e&#x27;, &#x27;/test&#x27;, &#x27;ROLE_USER&#x27;, 1, &#x27;2020-11-12 12:01:13&#x27;, &#x27;2020-11-12 12:01:13&#x27;);INSERT INTO `t_diners` VALUES (3, &#x27;test2&#x27;, &#x27;test2&#x27;, &#x27;13666666667&#x27;, NULL, &#x27;e10adc3949ba59abbe56e057f20f883e&#x27;, &#x27;/test2&#x27;, &#x27;ROLE_USER&#x27;, 1, &#x27;2020-11-12 17:47:12&#x27;, &#x27;2020-11-12 17:47:12&#x27;);INSERT INTO `t_diners` VALUES (5, &#x27;aaa&#x27;, &#x27;aaa&#x27;, &#x27;12311112222&#x27;, NULL, &#x27;e10adc3949ba59abbe56e057f20f883e&#x27;, &#x27;/aaa&#x27;, &#x27;ROLE_USER&#x27;, 1, &#x27;2020-11-13 12:29:49&#x27;, &#x27;2020-11-13 12:29:49&#x27;);-- ------------------------------ Table structure for t_feed-- ----------------------------DROP TABLE IF EXISTS `t_feed`;CREATE TABLE `t_feed`  (  `id` int(11) NOT NULL AUTO_INCREMENT,  `content` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT &#x27;内容&#x27;,  `fk_diner_id` int(11) NULL DEFAULT NULL,  `praise_amount` int(11) NULL DEFAULT NULL COMMENT &#x27;点赞数量&#x27;,  `comment_amount` int(11) NULL DEFAULT NULL COMMENT &#x27;评论数量&#x27;,  `fk_restaurant_id` int(11) NULL DEFAULT NULL,  `create_date` datetime(0) NULL DEFAULT NULL,  `update_date` datetime(0) NULL DEFAULT NULL,  `is_valid` tinyint(1) NULL DEFAULT NULL,  PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = DYNAMIC;-- ------------------------------ Records of t_feed-- ------------------------------ ------------------------------ Table structure for t_follow-- ----------------------------DROP TABLE IF EXISTS `t_follow`;CREATE TABLE `t_follow`  (  `id` int(11) NOT NULL AUTO_INCREMENT,  `diner_id` int(11) NULL DEFAULT NULL,  `follow_diner_id` int(11) NULL DEFAULT NULL,  `is_valid` tinyint(1) NULL DEFAULT NULL,  `create_date` datetime(0) NULL DEFAULT NULL,  `update_date` datetime(0) NULL DEFAULT NULL,  PRIMARY KEY (`id`) USING BTREE,  INDEX `index_followeddiner_valid`(`follow_diner_id`, `is_valid`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = DYNAMIC;-- ------------------------------ Records of t_follow-- ------------------------------ ------------------------------ Table structure for t_restaurant-- ----------------------------DROP TABLE IF EXISTS `t_restaurant`;CREATE TABLE `t_restaurant`  (  `id` int(11) NOT NULL AUTO_INCREMENT,  `Name` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT &#x27;the En Name of the restaurant&#x27;,  `CnName` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `X` double NULL DEFAULT NULL,  `Y` double NULL DEFAULT NULL,  `Location` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT &#x27;En location of the restaurant&#x27;,  `CnLocation` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `Area` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT &#x27;city.district.neighbourhood\\r\\nExample: Shanghai.Xuhui.Xujiahui&#x27;,  `CnArea` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `Traffic` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT &#x27;the information/descripton of the restaurant&#x27;,  `Telephone` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT &#x27;Phone of the restaurant&#x27;,  `Email` varchar(80) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `Website` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `Cuisine` varchar(80) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `AveragePrice` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `AvgLunchPrice` decimal(19, 0) NULL DEFAULT NULL COMMENT &#x27;Average price of lunch&#x27;,  `Introduction` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT &#x27;Indtroduction of the restaurant&#x27;,  `Status` int(11) NULL DEFAULT 0 COMMENT &#x27;1=Opened 0=Closed&#x27;,  `CreateDT` datetime(0) NULL DEFAULT NULL,  `IsValid` smallint(1) NULL DEFAULT 1 COMMENT &#x27;1=Valid 0=Invalid&#x27;,  `Thumbnail` varchar(120) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT &#x27;pics at the list, value would be:\\r\\nbasepath/original/picname&#x27;,  `OpenHours` varchar(500) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `LikeVotes` int(10) NULL DEFAULT 0 COMMENT &#x27;the percentage of people like it&#x27;,  `DislikeVotes` int(10) NULL DEFAULT 0 COMMENT &#x27;How many people votes&#x27;,  `Amenities` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT &#x27;设备&#x27;,  `Tags` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT &#x27;tags of the restaurant&#x27;,  `OpenDate` datetime(0) NULL DEFAULT NULL,  `closeDate` datetime(0) NULL DEFAULT NULL,  `CityId` int(11) NULL DEFAULT 21 COMMENT &#x27;城市id&#x27;,  PRIMARY KEY (`id`) USING BTREE,  INDEX `index_isvalid`(`IsValid`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 23 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = DYNAMIC;-- ------------------------------ Records of t_restaurant-- ----------------------------INSERT INTO `t_restaurant` VALUES (14, &#x27;1931 Pub&#x27;, &#x27;名古&#x27;, 31.2158508275268, 121.461839852847, &#x27;112 Maoming Nan Lu, near Nanchang Lu&#x27;, &#x27;茂名南路112号, 近南昌路&#x27;, &#x27;Xuhui.Fmr French Concession&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;021 6472 5264&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;Shanghainese, Chinese&#x27;, &#x27;¥¥&#x27;, 0, &#x27;&#x27;, NULL, &#x27;2014-05-04 19:26:28&#x27;, 1, &#x27;&#x27;, &#x27;&#x27;, 1, 0, &#x27;&#x27;, &#x27;&#x27;, &#x27;2016-01-04 11:22:23&#x27;, &#x27;2016-01-04 11:22:23&#x27;, 21);INSERT INTO `t_restaurant` VALUES (15, &#x27;2001 Hong Kong Teahouse&#x27;, &#x27;2001港式茶餐&#x27;, 31.21385, 121.46051, &#x27;55 Shaanxi Nan Lu, near Changle Lu&#x27;, &#x27;陕西南路55号, 近长乐路&#x27;, &#x27;Xuhui.Fmr French Concession&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;021 5467 0205&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;Dim Sum, Chinese&#x27;, &#x27;¥&#x27;, 0, &#x27;&#x27;, NULL, &#x27;2014-05-04 19:26:28&#x27;, 4, &#x27;&#x27;, &#x27;&#x27;, 0, 0, &#x27;&#x27;, &#x27;&#x27;, &#x27;2016-01-04 11:22:23&#x27;, &#x27;2016-01-04 11:22:23&#x27;, 21);INSERT INTO `t_restaurant` VALUES (16, &#x27;2nd floor&#x27;, &#x27;2nd floor&#x27;, 31.2162, 121.447998, &#x27;2/F, 810 Changle Lu,near Changshu Lu&#x27;, &#x27;长乐路810号2楼, 近常熟路&#x27;, &#x27;Xuhui.Fmr French Concession&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;13761133471&#x27;, &#x27;&#x27;, &#x27;http://www.2ndfloor.asia&#x27;, &#x27;Cafe&#x27;, &#x27;¥&#x27;, 0, &#x27;&#x27;, NULL, &#x27;2014-05-04 19:26:28&#x27;, 3, &#x27;&#x27;, &#x27;&#x27;, 1, 0, &#x27;&#x27;, &#x27;&#x27;, &#x27;2016-01-04 11:22:23&#x27;, &#x27;2016-01-04 11:22:23&#x27;, 21);INSERT INTO `t_restaurant` VALUES (17, &#x27;400 Celsius&#x27;, &#x27;400 Celsius&#x27;, 31.19436, 121.43797, &#x27;1 Hongqiao Lu, 1/F, Grand Gateway, near Caoxi Bei Lu, Metro Line 1 Xujiahui Station&#x27;, &#x27;虹桥路1号港汇广场1楼, 近漕溪北路, 地铁1号线徐家汇站&#x27;, &#x27;Xuhui.Xujiahui&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;021 6447 0770&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;Steakhouse&#x27;, &#x27;¥¥¥¥&#x27;, 0, &#x27;&#x27;, NULL, &#x27;2014-05-04 19:26:28&#x27;, 3, &#x27;&#x27;, &#x27;&#x27;, 0, 0, &#x27;&#x27;, &#x27;&#x27;, &#x27;2016-01-04 11:22:23&#x27;, &#x27;2016-01-04 11:22:23&#x27;, 21);INSERT INTO `t_restaurant` VALUES (18, &#x27;5 on the Bund&#x27;, &#x27;5 on the Bund&#x27;, 31.234482, 121.490753, &#x27;Five on the Bund,20 Guangdong Lu, near Zhongshan Dong Yi Lu&#x27;, &#x27;广东路20号, 近中山东一路&#x27;, &#x27;Huangpu.The Bund&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;Global Cuisine&#x27;, &#x27;¥¥¥¥&#x27;, 0, &#x27;&#x27;, NULL, &#x27;2014-05-04 19:26:28&#x27;, 3, &#x27;&#x27;, &#x27;&#x27;, 0, 0, &#x27;&#x27;, &#x27;&#x27;, &#x27;2016-01-04 11:22:23&#x27;, &#x27;2016-01-04 11:22:23&#x27;, 21);INSERT INTO `t_restaurant` VALUES (19, &#x27;5 Tables Bistro&#x27;, &#x27;5桌餐厅&#x27;, 31.2174481541175, 121.47318647082, &#x27;210 Danshui Lu, near Zizhong Lu&#x27;, &#x27;淡水路210号, 近自忠路&#x27;, &#x27;Luwan.Xintiandi&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;021 3304 1205&#x27;, &#x27;&#x27;, &#x27;www.weibo.com/5tables&#x27;, &#x27;European&#x27;, &#x27;¥¥¥¥&#x27;, 0, &#x27;&#x27;, NULL, &#x27;2014-05-04 19:26:28&#x27;, 4, &#x27;&#x27;, &#x27;&#x27;, 0, 0, &#x27;&#x27;, &#x27;&#x27;, &#x27;2016-01-04 11:22:23&#x27;, &#x27;2016-01-04 11:22:23&#x27;, 21);INSERT INTO `t_restaurant` VALUES (20, &#x27;57 Du Xiang&#x27;, &#x27;57度湘&#x27;, 31.2250117063411, 121.47824432639, &#x27;138 Huaihai Zhong Lu, Infinity Plaza, 4/F, Room 401, near Longmen Lu&#x27;, &#x27;淮海路138号无限度广场4楼401室, 近龙门路&#x27;, &#x27;Xuhui.Huaihai Zhong Lu&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;021 3315 0057&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;Hunan, Chinese&#x27;, &#x27;¥&#x27;, 0, &#x27;&#x27;, NULL, &#x27;2014-05-04 19:26:28&#x27;, 1, &#x27;restaurant/20/restaurant/T/160_160/1399622680327.JPG&#x27;, &#x27;Daily 11am-9pm&#x27;, 17, 5, &#x27;&#x27;, &#x27;&#x27;, &#x27;2016-01-04 11:22:23&#x27;, &#x27;2016-01-04 11:22:23&#x27;, 21);INSERT INTO `t_restaurant` VALUES (21, &#x27;609 Pho&#x27;, &#x27;609 Pho&#x27;, 31.237629, 121.438797, &#x27;609 Anyuan Lu, near Jiaozhou Lu&#x27;, &#x27;安源路609号, 近胶州路&#x27;, &#x27;Jing\\&#x27;an&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;18201753996&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;Vietnamese&#x27;, &#x27;¥&#x27;, 0, &#x27;&#x27;, NULL, &#x27;2014-05-04 19:26:28&#x27;, 4, &#x27;&#x27;, &#x27;&#x27;, 0, 0, &#x27;&#x27;, &#x27;&#x27;, &#x27;2016-01-04 11:22:23&#x27;, &#x27;2016-01-04 11:22:23&#x27;, 21);INSERT INTO `t_restaurant` VALUES (22, &#x27;70s Restaurant&#x27;, &#x27;70后饭吧&#x27;, 31.2398228737211, 121.438096413353, &#x27;1217 Changde Lu, near Changshou Lu&#x27;, &#x27;常德路1217号, 近长寿路&#x27;, &#x27;Putuo&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;021 6040 2808&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;Chinese&#x27;, &#x27;¥¥&#x27;, 0, &#x27;&#x27;, NULL, &#x27;2014-05-04 19:26:28&#x27;, 1, &#x27;restaurant/22/restaurant/160_160/14075670693130533.JPG&#x27;, &#x27;&#x27;, 7, 2, &#x27;&#x27;, &#x27;&#x27;, &#x27;2016-01-04 11:22:23&#x27;, &#x27;2016-01-04 11:22:23&#x27;, 21);-- ------------------------------ Table structure for t_seckill_vouchers-- ----------------------------DROP TABLE IF EXISTS `t_seckill_vouchers`;CREATE TABLE `t_seckill_vouchers`  (  `id` int(11) NOT NULL AUTO_INCREMENT,  `fk_voucher_id` int(11) NULL DEFAULT NULL,  `amount` int(11) NULL DEFAULT NULL,  `start_time` datetime(0) NULL DEFAULT NULL,  `end_time` datetime(0) NULL DEFAULT NULL,  `is_valid` int(11) NULL DEFAULT NULL,  `create_date` datetime(0) NULL DEFAULT NULL,  `update_date` datetime(0) NULL DEFAULT NULL,  PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = DYNAMIC;-- ------------------------------ Records of t_seckill_vouchers-- ------------------------------ ------------------------------ Table structure for t_voucher-- ----------------------------DROP TABLE IF EXISTS `t_voucher`;CREATE TABLE `t_voucher`  (  `id` int(10) NOT NULL AUTO_INCREMENT,  `title` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT &#x27;代金券标题&#x27;,  `thumbnail` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT &#x27;缩略图&#x27;,  `amount` int(11) NULL DEFAULT NULL COMMENT &#x27;抵扣金额&#x27;,  `price` decimal(10, 2) NULL DEFAULT NULL COMMENT &#x27;售价&#x27;,  `status` int(10) NULL DEFAULT NULL COMMENT &#x27;-1=过期 0=下架 1=上架&#x27;,  `expire_time` datetime(0) NULL DEFAULT NULL COMMENT &#x27;过期时间&#x27;,  `redeem_restaurant_id` int(10) NULL DEFAULT NULL COMMENT &#x27;验证餐厅&#x27;,  `stock` int(11) NULL DEFAULT 0 COMMENT &#x27;库存&#x27;,  `stock_left` int(11) NULL DEFAULT 0 COMMENT &#x27;剩余数量&#x27;,  `description` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT &#x27;描述信息&#x27;,  `clause` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT &#x27;使用条款&#x27;,  `create_date` datetime(0) NULL DEFAULT NULL,  `update_date` datetime(0) NULL DEFAULT NULL,  `is_valid` tinyint(1) NULL DEFAULT NULL,  PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = DYNAMIC;-- ------------------------------ Records of t_voucher-- ------------------------------ ------------------------------ Table structure for t_voucher_order-- ----------------------------DROP TABLE IF EXISTS `t_voucher_order`;CREATE TABLE `t_voucher_order`  (  `id` int(11) NOT NULL AUTO_INCREMENT,  `order_no` int(11) NULL DEFAULT NULL,  `fk_voucher_id` int(11) NULL DEFAULT NULL,  `fk_diner_id` int(11) NULL DEFAULT NULL,  `qrcode` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT &#x27;图片地址&#x27;,  `payment` tinyint(4) NULL DEFAULT NULL COMMENT &#x27;0=微信支付 1=支付宝支付&#x27;,  `status` tinyint(1) NULL DEFAULT NULL COMMENT &#x27;订单状态：-1=已取消 0=未支付 1=已支付 2=已消费 3=已过期&#x27;,  `fk_seckill_id` int(11) NULL DEFAULT NULL COMMENT &#x27;如果是抢购订单时，抢购订单的id&#x27;,  `order_type` int(11) NULL DEFAULT NULL COMMENT &#x27;订单类型：0=正常订单 1=抢购订单&#x27;,  `create_date` datetime(0) NULL DEFAULT NULL,  `update_date` datetime(0) NULL DEFAULT NULL,  `is_valid` int(11) NULL DEFAULT NULL,  PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = DYNAMIC;-- ------------------------------ Records of t_voucher_order-- ----------------------------SET FOREIGN_KEY_CHECKS = 1;\n\n\n\n项目架构与微服务搭建\n基于Spring Cloud Hoxton.SR8搭建\n第一步:创建Maven的父级工程，添加对应依赖\n\n&lt;!-- 可以集中定义依赖资源的版本信息 --&gt;   &lt;properties&gt;       &lt;spring-boot-version&gt;2.3.5.RELEASE&lt;/spring-boot-version&gt;       &lt;spring-cloud-version&gt;Hoxton.SR8&lt;/spring-cloud-version&gt;       &lt;lombok-version&gt;1.18.16&lt;/lombok-version&gt;       &lt;commons-lang-version&gt;3.11&lt;/commons-lang-version&gt;       &lt;mybatis-starter-version&gt;2.1.3&lt;/mybatis-starter-version&gt;       &lt;mysql-version&gt;8.0.22&lt;/mysql-version&gt;       &lt;swagger-starter-version&gt;2.1.5-RELEASE&lt;/swagger-starter-version&gt;       &lt;hutool-version&gt;5.4.7&lt;/hutool-version&gt;       &lt;guava-version&gt;20.0&lt;/guava-version&gt;       &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;       &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;       &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;   &lt;/properties&gt;   &lt;!-- 集中定义依赖，不引入 --&gt;   &lt;dependencyManagement&gt;       &lt;dependencies&gt;           &lt;!-- spring boot 依赖 --&gt;           &lt;dependency&gt;               &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;               &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;               &lt;version&gt;$&#123;spring-boot-version&#125;&lt;/version&gt;               &lt;type&gt;pom&lt;/type&gt;               &lt;scope&gt;import&lt;/scope&gt;           &lt;/dependency&gt;           &lt;!-- spring cloud 依赖 --&gt;           &lt;dependency&gt;               &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;               &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;               &lt;version&gt;$&#123;spring-cloud-version&#125;&lt;/version&gt;               &lt;type&gt;pom&lt;/type&gt;               &lt;scope&gt;import&lt;/scope&gt;           &lt;/dependency&gt;           &lt;!-- lombok 依赖 --&gt;           &lt;dependency&gt;               &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;               &lt;artifactId&gt;lombok&lt;/artifactId&gt;               &lt;version&gt;$&#123;lombok-version&#125;&lt;/version&gt;           &lt;/dependency&gt;           &lt;!-- common-lang3 依赖 --&gt;           &lt;dependency&gt;               &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;               &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt;               &lt;version&gt;$&#123;commons-lang-version&#125;&lt;/version&gt;           &lt;/dependency&gt;           &lt;!-- mybatis 依赖 --&gt;           &lt;dependency&gt;               &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;               &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;               &lt;version&gt;$&#123;mybatis-starter-version&#125;&lt;/version&gt;           &lt;/dependency&gt;           &lt;!-- swagger 依赖 --&gt;           &lt;dependency&gt;               &lt;groupId&gt;com.battcn&lt;/groupId&gt;               &lt;artifactId&gt;swagger-spring-boot-starter&lt;/artifactId&gt;               &lt;version&gt;$&#123;swagger-starter-version&#125;&lt;/version&gt;           &lt;/dependency&gt;           &lt;!-- mysql 依赖 --&gt;           &lt;dependency&gt;               &lt;groupId&gt;mysql&lt;/groupId&gt;               &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;               &lt;version&gt;$&#123;mysql-version&#125;&lt;/version&gt;           &lt;/dependency&gt;           &lt;!-- hutool 依赖 --&gt;           &lt;dependency&gt;               &lt;groupId&gt;cn.hutool&lt;/groupId&gt;               &lt;artifactId&gt;hutool-all&lt;/artifactId&gt;               &lt;version&gt;$&#123;hutool-version&#125;&lt;/version&gt;           &lt;/dependency&gt;           &lt;!-- guava 依赖 --&gt;           &lt;dependency&gt;               &lt;groupId&gt;com.google.guava&lt;/groupId&gt;               &lt;artifactId&gt;guava&lt;/artifactId&gt;               &lt;version&gt;$&#123;guava-version&#125;&lt;/version&gt;           &lt;/dependency&gt;       &lt;/dependencies&gt;   &lt;/dependencyManagement&gt;   &lt;!-- 集中定义项目所需插件 --&gt;   &lt;build&gt;       &lt;pluginManagement&gt;           &lt;plugins&gt;               &lt;!-- spring boot maven 项目打包插件 --&gt;               &lt;plugin&gt;                   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                   &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;               &lt;/plugin&gt;           &lt;/plugins&gt;       &lt;/pluginManagement&gt;   &lt;/build&gt;\n\n\n第二步:创建基于Eureka的注册中心微服务\n第三步:配置注册中心(单机版)\n\nserver:  port: 8080spring:  application:    name: ms-registry# 配置 Eureka Server 注册中心eureka:  client:    register-with-eureka: false    fetch-registry: false    service-url:      defaultZone: http://localhost:8080/eureka/logging:  pattern:    console: &#x27;%d&#123;HH:mm:ss&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&#x27;\n\n\n第四步:启动注册中心并验证\n第五步:添加网关微服务，并注册到注册中心，启动并测试\n第六步:添加用户微服务，并注册到注册中心，启动并测试\n同理创建其他微服务\n\n\n\n\n\n\n\n第3章 Redis基础数据类型与基本使用字符串 (strings)类型介绍\n字符串是Redis最简单的储存类型，它存储的值可以是字符串、整数或者浮点数，对整个字符串或者字符串的其中一部分执行操作;对整数或者浮点数执行自增 (increment)或者自减(decrement)操作\nRedis的字符串是一个由字节组成的序列，跟java里面的ArayList有点类似，采用预分配几余空间的方式来减少内存的频繁分配，内部为当前字符串实际分配的空间 capacity 一般要高于实际字符串长度len。当字符串长度小于 1M 时，扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是字符串最大长度为 512M。\n\n应用场景\n字符串类型在工作中使用广泛，主要用于缓存数据，提高查询性能。比如存储登录用户信息、电商中存储商品信息、可以做计数器 (想知道什么时候封锁一个IP地址(访问超过几次))等等\n\n操作指令set key value: 添加一条String类型数据get key:获取一条String类型数据mset key1 value1 key2 value2: 添加多条String类型数据mget key1 key2:获取多条String类型数据incr kev:白增(+1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["Database","Redis"],"tags":["Redis","Cache","Database"]},{"title":"《线程八大核心+Java并发原理及企业级并发解决方案》Study Notes","url":"/%E3%80%8A%E7%BA%BF%E7%A8%8B%E5%85%AB%E5%A4%A7%E6%A0%B8%E5%BF%83-Java%E5%B9%B6%E5%8F%91%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%B9%B6%E5%8F%91%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E3%80%8BStudy-Notes/","content":"\n\n第1章 开宗明义为什么要学习并发编程\n源于JD（job description）的硬性要求，尤其是大厂\n\n并发痛点：（面试中高频出现、内容繁杂、做归纳整理耗时、网上文章水平参差不齐难辨真伪）\n\n并发学习，是成为高级工程师的必经之路\n①几乎所有的程序或多或少都需要并发和多线程；\n②线上服务用户量过大，并发上万，如果不使用并发编程，性能很快成为瓶颈；\n③我们在职场打怪升级的过程中，并发编程是绕不过去的内容\n\n并发是众多框架的的原理和基础，学好后可以做到一通百通\n①Spring中对线程池、单例的应用；\n②数据库中的乐观锁思想；\n③Log4j2对阻塞队列的应用\n\n\n\n\n配套资料\nhttps://docs.qq.com/doc/DSVNyZ2FNWWFkeFpO\nhttps://naotu.baidu.com/file/07f437ff6bc3fa7939e171b00f133e17?token=6744a1c6ca6860a0\nhttps://naotu.baidu.com/file/60a0bdcaca7c6b92fcc5f796fe6f6bc9?token=bcdbae34bb3b0533\nhttps://coding.imooc.com/class/chapter/362.html#Anchor\nhttps://shimo.im/docs/zdkyBdQb94H255A6\n\n\n\n\n\n\n\n第2章 线程八大核心纵观全貌\n\n\n\n线程八大核心基础\n实现多线程的方法到底有1种还是2种还是4种 ?\n怎样才是正确的线程启动方式?\n上山容易下山难，如何正确停止线程 ?( 难点）\n线程的一生6个状态(生命周期）\nThread和Obiect类中的重要方法详解\n线程的各个属性\n未捕获异常如何处理 ?\n双刃剑: 多线程会导致的问题\n\n\n\n\n\n\n\n第3章 核心1：实现多线程的正确姿势【解读官方文档】创建（实现）新线程的正确方法\noracle官方文档：\n方法一：继承Thread类\n方法二：实现Runnable接口\n\n\n\n\n\n\n\n总结：创建新线程的方法-精确描述\n通常我们可以分为两类，官网也是这么说的\n准确的讲，创建线程只有一种方式那就是构造Thread类，而实现线程的执行单元有两种方式：\n方法一：重写Thread的run方法(继承Thread类)\n方法二：实现Runnable接口的run 方法，并把Runnable实例传给Thread类\n\n\n\n\n\n两种创建线程方法的本质对比\n“实现Runnable接口并传入Thread类”和“继承Thread类然后重写run()方法”在实现多线程的本质上，并没有区别，都是最终调用了start()方法来新建线程。这两个方法的最主要区别在于run()方法的内容来源:\n\n@Override   public void run() &#123;       if (target != null) &#123;           target.run();       &#125;   &#125;\n\n\n实现Runnable接口方式: 最终调用target.run ();\n继承Thread类方式: run()整个都被重写\n\n\n\n典型错误观点分析\n“线程池创建线程也算是一种新建线程的方式”\n“通过Callable和FutureTask创建线程，也算是一种新建线程的方式”\n“无返回值是实现runnable接口，有返回值是实现callable接口，所以callable是新的实现线程的方式”\n定时器\n匿名内部类\nLambda表达式\n\n多线程的实现方式，在代码中写法千变万化，但其本质万变不离其宗\n思考题同时用两种方法会怎么样public class BothRunnableThread &#123;    public static void main(String[] args) &#123;        new Thread(new Runnable() &#123;            @Override            public void run() &#123;                System.out.println(&quot;我来自Runnable&quot;);            &#125;        &#125;)&#123;            @Override            public void run() &#123;                System.out.println(&quot;我来自Thread&quot;);            &#125;        &#125;.start();    &#125;&#125;\n\n\n最终会执行 Thread 类的run方法，因为 run方法已被重写\n\n\n\n实现多线程—常见面试问题有多少种实现线程的方法？\n从不同的角度（代码实现方法，本质实现方法）看，会有不同的答案\n典型答案是两种，分别是实现Runnable接口和继承Thread类，然后具体展开说;各自的优势，劣势\n但是，我们看原理，其实Thread类实现了Runnable接口，并且看Thread类的run方法，会发现其实那两种本质都是一样的\n\n\n“实现Runnable接口并传入Thread类”和“继承Thread类然后重写run0”在实现多线程的本质上，并没有区别，都是最终调用了start (方法来新建线程。这两个方法的最主要区别在于run0方法的内容来源:\n\n方法一: 最终调用target.run ();\n方法二:run()整个都被重写\n\n\n\n然后具体展开说其他方式:还有其他的实现线程的方法，例如线程池、定时器，它们也能新建线程，但是细看源码，从没有逃出过本质，也就是实现Runnable接口和继承Thread类。\n结论:我们只能通过新建Thread类这一种方式来创建线程，但是类里面的run方法有两种方式来实现，第一种是重写run方法，第二种实现Runnable接口的run方法，然后再把该runnable实例传给Thread类。除此之外，从表面上看线程池、定时器等工具类也可以创建线程，但是它们的本质都逃不出刚才所说的范围。\n\n\n以上这种描述比直接回答一种、两种、多种都更准确。\n\n\n\n实现Runnable接口和继承Thread类哪种方式更好?\n实现Runnable接口更好\n\n\n从代码架构角度，具体的任务 (run方法)应该和“创建和运行线程的机制(Thread类)”解耦。\n使用继承Thread的方式的话，那么每次想新建一个任务，只能新建一个独立的线程，而这样做的损耗会比较大。如果使用Runnable和线程池，就可以大大减小这样的损耗。\n继承Thread类以后，由于Java语言不支持双继承，这样就无法再继承其他的类，限制了可扩展性。\n\n\n\n\n\n\n\n第4章 核心2：开启多线程启动的世界start()方法含义\n启动新线程\n准备工作\n不能重复调用start()\n\n\n\nstart()源码解析\n启动新线程检查线程状态\n加入线程组\n调用start0()方法\n\n\n\n启动线程—常见面试题问题一个线程两次调用start()方法会出现什么情况? 为什么?\n从start()源码可以看出，start的时候会先检查线程状态，只有NEW状态下的线程才能继续执行，否则会抛IllegalThreadStateException(在运行中或者已结束的线程，都不能再次启动)。\n\n\n\n既然 start()方法会调用 run()方法，为什么我们选择调用 start() 方法而不是直接调用 run()方法呢?\nstart()才是真正启动一个线程，而如果直接调用run()，那么run()只是一个普通的方法而已，和线程的生命周期没有任何关系\n\n\n\n\n\n\n\n第5章 核心3：线程停止、中断之最佳实践【填“坑”式教学，从错误到正确】如何正确停止线程概述\n原理介绍：使用interrupt来通知，而不是强制\n\n使用interrupt优点：被中断的线程其自身拥有如何响应中断的权利（因为：有些线程的某些代码是非常重要的，我们必须要等待这些线程处理完之后或者其准备好之后，再由它们自己去主动终止或做其它处理。这样更加安全，完成了清理工作，数据的完整性也得到了保障）\n\n\n线程通常在什么情况下停止：\n\nrun方法运行完毕\n有异常出现，且方法没有捕获\n\n\n线程的正确停止方法：interrupt\n\n通常情况下如何停止线程\n线程可能阻塞\n如果线程在每次迭代后都阻塞\n\n\n\n通常情况下中断（停止）线程/** * 描述：一般情况（ run方法内没有sleep或wait方法时），正确停止线程的方式 * 需要判断 Interrupt 标志 */public class RightWayStopThreadWithoutSleep implements Runnable&#123;    @Override    public void run() &#123;        int num=0;        while (!Thread.currentThread().isInterrupted() &amp;&amp; num &lt; Integer.MAX_VALUE/2)&#123;            if (num % 10000 == 0)&#123;                System.out.println(num+&quot; 是10000的倍数&quot;);            &#125;            num++;        &#125;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        Thread thread = new Thread(new RightWayStopThreadWithoutSleep());        thread.start();        Thread.sleep(1000);        thread.interrupt();    &#125;&#125;\n\n\n\n线程可能被阻塞情况下，正确停止线程\n正确中断线程，但也抛出错误\n不需要判断Interrupt\n\n/** * 描述：     带有sleep的中断线程的写法 */public class RightWayStopThreadWithSleep &#123;    public static void main(String[] args) throws InterruptedException &#123;        Runnable runnable = () -&gt; &#123;            int num = 0;            try &#123;                Thread.sleep(1000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;;        Thread thread = new Thread(runnable);        thread.start();        Thread.sleep(100);        thread.interrupt();    &#125;&#125;\n\n\n\n线程在每次迭代后都阻塞，正确停止线程\n正确中断线程，但也抛出错误\n不需要每次迭代都检查线程是否已中断\n\n/** * 描述：   如果在执行过程中，每次循环都会调用sleep或wait等方法，那么不需要每次迭代都检查是否已中断，因为中断过程中就会检测到该异常 */public class RightWayStopThreadWithSleepEveryLoop &#123;    public static void main(String[] args) throws InterruptedException &#123;        Runnable runnable = ()-&gt;&#123;            int num = 0;            try &#123;                while (num &lt; Integer.MAX_VALUE / 2 ) &#123;                    if (num % 100 == 0) &#123;                        System.out.println(num + &quot;是100的倍数&quot;);                    &#125;                    num++;                    Thread.sleep(1);                &#125;            &#125;catch (InterruptedException e)&#123;                e.printStackTrace();            &#125;        &#125;;        Thread thread = new Thread(runnable);        thread.start();        Thread.sleep(2000);        thread.interrupt();    &#125;&#125;\n\n\n\nwhile内try/catch的问题\n如果while里面放try/catch，会导致中断失效\n中断失效原因： Java语言的sleep设计中，一旦响应中断，便会把线程的interrupt标记给清除\n\n/** * 描述：     如果while里面放try/catch，会导致中断失效 * 中断失效原因： Java语言的sleep设计中，一旦响应中断，便会把线程的interrupt标记给清除 */public class CantInterrupt &#123;    public static void main(String[] args) throws InterruptedException &#123;        Runnable runnable = ()-&gt;&#123;            int num =0;            while (num &lt; Integer.MAX_VALUE/2 &amp;&amp; !Thread.currentThread().isInterrupted())&#123;                if (num %100 == 0)&#123;                    System.out.println(num + &quot;是100的倍数&quot;);                &#125;                num++;                try &#123;                    Thread.sleep(1);                &#125; catch (InterruptedException e) &#123;                    //这里响应中断，会打印出异常，但是线程中断失效                    //中断失效原因：Java语言的sleep设计中，一旦响应中断，便会把线程的interrupt标记给清除                    e.printStackTrace();                &#125;            &#125;        &#125;;        Thread thread = new Thread(runnable);        thread.start();        Thread.sleep(1000);        thread.interrupt();    &#125;&#125;\n\n\n\n实际开发中 - 两种（中断线程）最佳实践\n优先选择：传递中断\n不想或无法传递中断：恢复中断\n不应屏蔽中断\n\n优先选择：传递该中断/** * 描述：     最佳实践：catch了InterruptedExcetion之后的优先选择：在方法签名中抛出异常 ,那么在run()就会强制try/catch */public class RightWayStopThreadInProd implements Runnable&#123;        /**     * run 方法无法再抛出异常     */    @Override    public void run() &#123;        while (true &amp;&amp; !Thread.currentThread().isInterrupted())&#123;            System.out.println(&quot;go&quot;);            try &#123;                useOtherMethod();            &#125; catch (InterruptedException e) &#123;                //保存日志、或中断程序                e.printStackTrace();            &#125;        &#125;    &#125;    /**     * 描述：应该上报异常，让run函数决定如何处理异常     * @throws InterruptedException     */    private void useOtherMethod() throws InterruptedException &#123;        Thread.sleep(100);    &#125;    /**     * 错误方式：     * 把异常处理在比较低级的层次，虽然响应中断，打印错误，但对上层方法无感知。相当于屏蔽了中断。结果线程中断失败     *///    private void useOtherMethod() &#123;//        try &#123;//            Thread.sleep(100);//        &#125; catch (InterruptedException e) &#123;//            e.printStackTrace();//        &#125;//    &#125;    public static void main(String[] args) throws InterruptedException &#123;        Thread thread = new Thread(new RightWayStopThreadInProd());        thread.start();        Thread.sleep(1000);        thread.start();        thread.interrupt();    &#125;&#125;\n\n\n\n恢复中断/** * 描述：最佳实践2：在catch子语句中调用Thread.currentThread().interrupt()来恢复设置中断状态，以便于在后续的执行中，依然能够检查到刚才发生了中断 * 回到刚才RightWayStopThreadInProd补上中断，让它跳出 */public class RightWayStopThreadInProd2 implements Runnable &#123;    @Override    public void run() &#123;        while (true) &#123;            if (Thread.currentThread().isInterrupted()) &#123;                System.out.println(&quot;Interrupted，程序运行结束&quot;);                break;            &#125;            reInterrupt();        &#125;    &#125;    private void reInterrupt() &#123;        try &#123;            Thread.sleep(2000);        &#125; catch (InterruptedException e) &#123;            //恢复中断请求标志            Thread.currentThread().interrupt();            e.printStackTrace();        &#125;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        Thread thread = new Thread(new RightWayStopThreadInProd2());        thread.start();        Thread.sleep(1000);        thread.interrupt();    &#125;&#125;\n\n\n\n响应中断的方法总结列表\n响应中断是指：当中断信号到达的时候，是可以感知到响应中断信号的\n\nObject. wait()/ wait long)/ wait( long, int)\n\nThread. sleep( long) /sleep( long, int)\n\nThread. join0/ join( long)/join( long, int)\n\njava. util. concurrent. BlockingQueue. take() /put( E)\n\njava. util. concurrent. locks. Lock.lockInterruptibly()\n\njava. util. concurrent. CountDownLatch. await()\n\njava. util. concurrent. CyclicBarrier. await()\n\njava.util. concurrent. Exchanger. exchange(V)\n\njava.nio.channels.InterruptibleChannel相关方法\n\njava.nio.channels.Selector的相关方法\n\n\n错误停止线程的方法\n被弃用的stop,suspend和resume方法\nstop 它本版上是不安全的。停止线程会导致它解锁已锁定的所有监视器\nsuspend和resume：带着锁休息，会造成死锁\n\n\n用volatile设置boolean标记位\n\nstop停止线程演示（错误方式）\n无法完成基本单位操作\n\n/** * 描述：     错误的停止方法：用stop()来停止线程，会导致线程运行一半突然停止， * 没办法完成一个基本单位的操作（一个连队），会造成脏数据（有的连队少领取装备）。 */public class StopThread implements Runnable&#123;    @Override    public void run() &#123;        //i表示连队编号 ，j表示人员编号        for (int i = 0; i &lt; 10; i++) &#123;            System.out.println(&quot;连队 &quot;+i +&quot; 开始领取武器&quot;);            for (int j = 0; j &lt; 100; j++) &#123;                try &#123;                    Thread.sleep(1);                &#125; catch (InterruptedException e) &#123;                    throw new RuntimeException(e);                &#125;                System.out.println(&quot;连队 &quot;+i+&quot;的人员 &quot;+j+&quot; 号领取了武器&quot;);            &#125;            System.out.println(&quot;连队 &quot;+i +&quot; 领取武器完毕&quot;);        &#125;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        Thread thread = new Thread(new StopThread());        thread.start();        Thread.sleep(1000);        thread.stop();    &#125;&#125;\n\n\n\n用volatile设置boolean标记位 - 停止线程演示（错误方式）volatile：开上去可行/** * 描述：     演示用volatile的局限：part1 看似可行 */public class WrongWayVolatile implements Runnable&#123;    private volatile boolean canceled = false;        @Override    public void run() &#123;        int num = 0;        while (num &lt; Integer.MAX_VALUE/2 &amp;&amp; !canceled)&#123;            if (num %10 == 0)&#123;                System.out.println(num + &quot; 是 10 的倍数&quot;);            &#125;            num++;            try &#123;                Thread.sleep(10);            &#125; catch (InterruptedException e) &#123;                throw new RuntimeException(e);            &#125;        &#125;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        WrongWayVolatile wrongWayVolatile = new WrongWayVolatile();        Thread thread = new Thread(wrongWayVolatile);        thread.start();        Thread.sleep(2000);        wrongWayVolatile.canceled=true;    &#125;&#125;\n\n\n\nvolatile不能正确停止线程的情况演示\n错误原因：实际阻塞位置在blockingQueue.put(num);。并未经过while ( num &lt; 1000000 &amp;&amp; !canceled)这个判断，所以能停止线程\n所以我们应该使用interrupt来正确停止线程。即便遇到了上述情况，其也可以响应\n修复：换成interrupt来中断线程\n\n/** * 描述：     演示用volatile的局限part2 陷入阻塞时，volatile是无法线程的 * 此例中，生产者的生产速度很快，消费者消费速度慢， * 所以阻塞队列满了以后，生产者会阻塞，等待消费者进一步消费 */public class WrongWayVolatileCantStop &#123;    public static void main(String[] args) throws InterruptedException &#123;        ArrayBlockingQueue storage = new ArrayBlockingQueue(10);        Producer producer = new Producer(storage);        Thread producerThread = new Thread(producer);        producerThread.start();        Thread.sleep(1000);        Consumer consumer = new Consumer(storage);        while (consumer.needMoreNums()) &#123;            System.out.println(consumer.blockingQueue.take()+&quot;被消费了&quot;);            Thread.sleep(100);        &#125;        System.out.println(&quot;消费者不需要更多数据了。&quot;);        //一旦消费不需要更多数据了，我们应该让生产者也停下来，但是实际情况        producer.canceled=true;        System.out.println(producer.canceled);    &#125;&#125;class Producer implements Runnable&#123;    BlockingQueue blockingQueue;     volatile boolean canceled = false;    public Producer(BlockingQueue blockingQueue) &#123;        this.blockingQueue = blockingQueue;    &#125;    @Override    public void run() &#123;        int num=0;        try &#123;            //生产者在这里做检查            while ( num &lt; 1000000 &amp;&amp; !canceled)&#123;                if (num % 100 == 0)&#123;                    System.out.println(num +&quot;是100的倍数&quot;);                        //实际阻塞位置是这里                        blockingQueue.put(num);                &#125;                num++;            &#125;        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;finally &#123;            System.out.println(&quot;生产者结束运行&quot;);        &#125;    &#125;&#125;class Consumer&#123;    BlockingQueue blockingQueue;    public Consumer(BlockingQueue blockingQueue) &#123;        this.blockingQueue = blockingQueue;    &#125;    public boolean needMoreNums() &#123;        if (Math.random() &gt; 0.95) &#123;            return false;        &#125;        return true;    &#125;&#125;\n\n\n\n停止线程相关重要函数解析判断是否已被中断相关方法\nstatic boolean interrupted()\n判断线程是否中断，返回后会把线程的中断状态设置为false（唯一能清除线程状态的办法）\ninterrupted()方法的目标对象是“当前线程”（执行该方法的线程），而不管本方法来自于哪个对象\n\n\nboolean isInterrupted()\n判断线程是否中断。但是不会做线程状态清除\n\n\n\n/** * 描述：     注意Thread.interrupted()方法的目标对象是“当前线程”（执行该方法的线程），而不管本方法来自于哪个对象 */public class RightWayInterrupted &#123;    public static void main(String[] args) throws InterruptedException &#123;        Thread threadOne = new Thread(new Runnable() &#123;            @Override            public void run() &#123;                for (; ; ) &#123;                &#125;            &#125;        &#125;);        // 启动线程        threadOne.start();        //设置中断标志        threadOne.interrupt();        //获取中断标志        System.out.println(&quot;isInterrupted: &quot; + threadOne.isInterrupted());//true        //获取中断标志并重置        System.out.println(&quot;isInterrupted: &quot; + threadOne.interrupted());//fasle        //获取中断标志并重直        System.out.println(&quot;isInterrupted: &quot; + Thread.interrupted());//false        //获取中断标志        System.out.println(&quot;isInterrupted: &quot; + threadOne.isInterrupted());//true        threadOne.join();        System.out.println(&quot;Main thread is over.&quot;);    &#125;&#125;\n\n\n\n停止线程 — 面试常见问题如何停止线程\n回答思路：\n原理:用interrupt来请求、好处\n想停止线程，要请求方、被停止方、子方法被调用方相互配合\n最后再说错误的方法:stop/suspend已废弃，volatile的boolean无法处理长时间阻塞的情况\n\n\n\n\n我们要用interrupt来请求中断（停止）线程，而那些stop或者是volatile。好处是可以保证数据安全和数据完整性。我们要把主动权交给被中断的线程\n要想达到这样的效果，不仅让我们调用interrupt方法去中断它，还要被中断的线程配合，而且配合一共有三方配合，分别是请求方、被停止方、被调用方这三方。\n首先作为请求方，我们非常简单发出一个请求信号，而被停止方案，它必须在每次循环中或者适当的时候去检查中断信号，并且在可能抛出interrupted exception的时候去处理这个信号。每一个县城他都应该去做这样的事情，以便于自己可以被停止。如果我们是去写子方法的，这个子方法是会被我们先生所调用的，那么我们有两点最佳实践，优先是在方法层抛出这个exception，以便于其他人去做进一步的处理，或者我们在收到中断信号之后，把它再次设为中断状态，这两种方法都可以，如果这三方配合合适配合默契的话，我们就可以利用我们的interrupt来非常完美来达到一个线程停止的效果。\nstop/suspend的缺点，volatile的错误。它无法处理长时间阻塞的状态，而这种状态在生产环境很有可能发生，尤其是这一点一定会成为我们的一个亮点。因为这一点可能包括一些面试官在内都不知道它是一个错误的方法，我们可以用刚才代码给他演示一下，我相信如果这样解释一下如何正确停止线程是一个非常不错的答案。\n\n如何处理不可中断的阻塞\n视频多看两遍\n\n\n关于这个问题的描述是这样的，我们刚才讲过我们使用了interrupt方法，它不是万能的，之所以它能让我们及时的响应中断，那是由于我们的wait或者是sleep，我们也分析过源码，它是可以被我们所唤醒，但是有很多方法它不一定能够及时被我们唤醒。比如说在执行socket io操作的时候，我们即便给他发出interrupt信号，他也无法及时的响应的，或者是reaction的loc方法的时候，他也无法响应，总有各种各样的方法它是无法及时响应的，这种叫做不可中断阻塞。那么这种阻塞我们如何去正确的处理答案是这样的。首先我们要给一个结论叫做很遗憾，并没有一个通用的解决方案，通用的是不存在的，我们要针对某一些所或者某一些io给出不同的解决方案。在这边我们给出一个例子，比如说关于engined loc，这个是可重入锁，如果我们真的使用了它的lock方法，并且在lock过程中把它阻塞，那么是没有办法让它及时响应的。但是与此同时类提供了一个lock interrupt这个方法，这个方法是可以响应中断的，所以这就要求我们在编写代码的过程中去使用那些可以响应中断的方法，这是一种解决方案。针对于io的情况，普通的io或许没有办法及时响应，但是有一些io操作它是可以响应我们中断的，那么我们就用这些特定的方法，所以如果我们被面试官问到这个问题的话，我们的答案就是针对特定的情况，我们使用特定的方法，尽可能的让他做到能够响应中断，没有一个万能药。\n\n\n\n\n\n\n\n第6章 核心4：图解线程生命周期【适用于面试】线程的生命周期（6个状态）\nNew\nRunnable\nBlocked\nWaiting\nTimed Waiting\nTerminated\n\n\n\n\n\n线程生命周期6种状态演示/** * 描述：     展示线程的NEW、RUNNABLE、Terminated状态。即使是正在运行，也是Runnable状态，而不是Running。 */public class NewRunnableTerminated implements Runnable &#123;    public static void main(String[] args) &#123;        Thread thread = new Thread(new NewRunnableTerminated());        //打印出NEW的状态        System.out.println(thread.getState());        thread.start();        System.out.println(thread.getState());        try &#123;            Thread.sleep(10);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        //打印出RUNNABLE的状态，即使是正在运行，也是RUNNABLE，而不是RUNNING        System.out.println(thread.getState());        try &#123;            Thread.sleep(100);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        //打印出TERMINATED状态        System.out.println(thread.getState());    &#125;    @Override    public void run() &#123;        for (int i = 0; i &lt; 1000; i++) &#123;            System.out.println(i);        &#125;    &#125;&#125;\n\n\n\n/** * 描述：     展示Blocked, Waiting, TimedWaiting */public class BlockedWaitingTimedWaiting implements Runnable&#123;    public static void main(String[] args) &#123;        BlockedWaitingTimedWaiting runnable = new BlockedWaitingTimedWaiting();        Thread thread1 = new Thread(runnable);        thread1.start();        Thread thread2 = new Thread(runnable);        thread2.start();        try &#123;            Thread.sleep(5);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        //打印出Timed_Waiting状态，因为正在执行Thread.sleep(1000);        System.out.println(thread1.getState());        //打印出BLOCKED状态，因为thread2想拿得到sync()的锁却拿不到        System.out.println(thread2.getState());        try &#123;            Thread.sleep(1300);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        //打印出WAITING状态，因为执行了wait()        System.out.println(thread1.getState());    &#125;    @Override    public void run() &#123;        syn();    &#125;    private synchronized void syn() &#123;        try &#123;            Thread.sleep(1000);            wait();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\n\n\n\n阻塞状态\n一般习惯而言，把Blocked(被阻塞)、Waiting(等待 )、Timed_waiting(计时等待)都称为阻塞状态\n\n线程生命周期 - 常见面试问题\n线程有哪几种状态？生命周期是什么？\n\n\n\n\n\n\n\n第7章 核心5：趣解Thread和Object类中线程相关方法\n\n\n\n\n\n第8章 核心6：一网打尽线程属性\n\n\n\n\n\n第9章 核心7：线程异常处理知多少？面试/思考题\n画出Java异常体系图\n实际工作中，如何全局处理异常？为什么要全局处理？不处理行不行？\nrun方法是否可以抛出异常?如果抛出异常，线程的状态会怎么样?\n线程中如何处理某个未处理异常？\n\n线程的未捕获异常（UncaughtException）应该如何处理 ?为什么需要UncaughtExceptionHandler ?\n主线程可以轻松发现异常，子线程却不行\n即使子线程在运行过程中抛出了异常，但在茫茫日志中，却难以发现该异常\n\n\n子线程异常无法用传统方法捕获\n原因：传统的异常处理（try catch）只能捕获其代码块所在的线程内的异常\n\n\n不能直接捕获的后果、提高健壮性\n\n两种解决方案方案一(不推荐):手动在每个run方法里进行try catch\n在每一个线程的run方法中使用 （try catch）捕获异常 这样做，而我们不知道抛出的异常类型，且样太累了\n\n方案二(推荐):利用UncaughtExceptionHandler\n是Thread类提供的api，可以检测出线程因为异常而终止的情况，并且对此进行处理\nUncaughtExceptionHandler接口：void uncaughtException(Thread t, Throwable e)\n\n\n异常处理器的调用策略\n\n\n\n\n\n\n\n\n\n\n自己实现\n给程序统一设置\n给每个线程单独设置\n给线程池设置\n\n\n\n\n\n\n\n\n\n第10章 核心8：追寻并发的崇高理想-线程安全【工作常用】什么是线程安全\n《Java Concurrency In Practice》的作者Brian Goetz对“线程安全有一个比较恰当的定义:“当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那这个对象是线程安全的。\n\n\n我的翻译:不管业务中遇到怎样的多个线程访问某对象或某方法的情况而在编程这个业务逻辑的时候，都不需要额外做任何额外的处理(是可以像单线程编程一样)，程序也可以正常运行(不会因为多线程而出错)，就可以称为线程安全\n\n线程不安全\nget同时set、额外同步\n\n全都线程安全?: 运行速度、设计成本、trade off\n\n完全不用于多线程:不过度设计\n\n\n什么情况下会出现线程安全问题，怎么避免 ?\n数据争用\n\n\n\n\n\n\n\n\n学习延伸学习编程知识的优质途径宏观上\n并不是靠工作年限，有的人工作了5年技术却还是只懂皮毛\n要有强大的责任心，不放过任何bug，找到原因并去解决，这就是提高\n主动:永远不会觉得自己的时间多余，重构、优化、学习、总结等。\n敢于承担:虽然这个技术难题以前没碰到过，但是在一定的了解调研后，敢于承担技术难题，让工作充满挑战，这一次次攻克难关的过程中，进步是飞速的\n关心产品，关心业务，而不只是写代码\n\n\n\n微观上（系统性学习）\n看经典书籍(指外国人写的经典的中国译本，比如说Java并发编程实战、自页向下计算机网络)\n看官方文档\n英文搜google和stackoverflow\n自己动手写，实践写demo，尝试用到项目里\n不理解的参考该领域的多个书本，综合判断\n学习开源项目，分析源码(学习synchronized原理，反编译看cpp代码)\n\n\n\n如何了解技术领域的最新动态\n高质量固定途径:ohmyrss.com(信息源筛选，为我所用)\n订阅技术网址的邮件 :InfoQ(每周都看 )\n公众号不推荐作为技术知识来源，质量无法保证\n\n\n\n如何在业务开发中成长\n偏业务方向\n偏技术方向\n两个25%理论\n\nJava 异常体系\n\n\n\n\n\n学习备注\n\n线程停止的面试题，还可以作为延伸和扩展去找相关资料继续学习\n\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n学习备注\n1\n\n&lt;font color=red&gt;&lt;/font&gt;&amp;emsp;&amp;emsp;\n\n\n\n","categories":["Java","Concurrency"],"tags":["Java","Concurrency"]}]